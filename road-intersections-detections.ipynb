{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"road.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"IRvWbq5mgng8","colab_type":"code","outputId":"3fd53432-be4f-4df3-9030-44b7f6a3ec8f","executionInfo":{"status":"error","timestamp":1552583665602,"user_tz":-180,"elapsed":96286,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":1570}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!wget https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n","!dpkg -i google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n","!apt-get install -f\n","!apt-get -y install -qq fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":1,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","--2019-03-14 17:12:55--  https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n","Resolving launchpad.net (launchpad.net)... 91.189.89.222, 91.189.89.223, 2001:67c:1560:8003::8003, ...\n","Connecting to launchpad.net (launchpad.net)|91.189.89.222|:443... connected.\n","HTTP request sent, awaiting response... 404 Not Found\n","2019-03-14 17:12:56 ERROR 404: Not Found.\n","\n","\u001b[1mdpkg:\u001b[0m \u001b[1;31merror:\u001b[0m cannot access archive 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb': No such file or directory\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-410\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 10 not upgraded.\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7d3a6017178e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'apt-get -y install -qq fuse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_application_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporary\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mclear_output\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_noop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m       \u001b[0m_gcloud_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0m_install_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mcolab_tpu_addr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36m_gcloud_login\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# https://github.com/jupyter/notebook/issues/3159\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n\\nEnter verification code: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mgcloud_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"koD35_YfTCyA","colab_type":"code","colab":{}},"cell_type":"code","source":["!kill -9 -1 #sıfırlama"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jHAnSVr1g0DU","colab_type":"code","outputId":"b53aa7c7-02e4-4f94-e08b-befca0e542ad","executionInfo":{"status":"ok","timestamp":1543349150247,"user_tz":-180,"elapsed":16624,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":641}},"cell_type":"code","source":["#Title\n","\n","!pip install keras\n","!pip install tensorboardcolab\n","!pip install tensorflow\n","import numpy as np\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.optimizers import Adam\n","from keras.utils import np_utils\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils.vis_utils import plot_model\n","from keras.callbacks import ModelCheckpoint, TensorBoard\n","from keras import optimizers\n","import os\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n","\n","import matplotlib.pyplot as plt\n","from tensorboardcolab import *\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.5)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.6)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n","Collecting tensorboardcolab\n","  Downloading https://files.pythonhosted.org/packages/73/3d/eaf745e162e471c5bb2737a407d8626fb8684a88cf085045456aeb841d3c/tensorboardcolab-0.0.19.tar.gz\n","Building wheels for collected packages: tensorboardcolab\n","  Running setup.py bdist_wheel for tensorboardcolab ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ab/74/02/cda602d1dc28b2f12eab313c49b9bfa14d6371326bc2590e06\n","Successfully built tensorboardcolab\n","Installing collected packages: tensorboardcolab\n","Successfully installed tensorboardcolab-0.0.19\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.12.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.6.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.5)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.6.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.32.3)\n","Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.6)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.6.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (3.0.1)\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (0.14.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"u0CC3P3RjtI0","colab_type":"code","colab":{}},"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Wed Oct 10 14:12:56 2018\n","\n","@author: ozal\n","\"\"\"\n","\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Jun 29 11:43:44 2018\n","\n","@author: ozal\n","\"\"\"\n","\n","import numpy\n","import matplotlib.pyplot as plt\n","from pandas import read_csv\n","import math\n","import keras\n","from keras.utils import np_utils\n","from sklearn.preprocessing import LabelEncoder\n","from keras.models import Sequential\n","from keras.layers import Dense,LocallyConnected1D\n","from keras.layers import LSTM, Dropout, Embedding, Bidirectional, Merge, Flatten\n","from sklearn.preprocessing import MinMaxScaler,StandardScaler\n","from sklearn import preprocessing\n","from sklearn.metrics import mean_squared_error\n","from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n","from keras import optimizers\n","from keras.layers.normalization import BatchNormalization\n","from sklearn.cross_validation import train_test_split\n","from keras.callbacks import ModelCheckpoint\n","from keras.models import load_model\n","from sklearn.model_selection import StratifiedKFold\n","\n","# convert an array of values into a dataset matrix\n","\n","# fix random seed for reproducibility\n","import scipy.io as sio\n","# load the dataset\n","\n","    \n","Tra=sio.loadmat('SEDFX(EOG)5.mat');\n","X1=Tra['data1'];\n","X2=Tra['data2'];\n","X=numpy.concatenate([X1,X2]);\n","Y=Tra['label'];\n","nb_class=5;\n","#X1=X1.reshape(-1,1);\n","Y=numpy.array(Y);\n","Y=Y.reshape(-1,);\n","encoder = LabelEncoder()\n","encoder.fit(Y);\n","encoded_Y = encoder.transform(Y)\n","# convert integers to dummy variables (i.e. one hot encoded)\n","Y = np_utils.to_categorical(encoded_Y,num_classes=nb_class)\n","\n","    \n","\n","\n","#scaler = MinMaxScaler(feature_range=(0, 1))\n","#scalers={}\n","#for i in range(X.shape[2]):\n","#    scalers[i] = scaler\n","#    X[:, :, i] = scalers[i].fit_transform(X[:, :, i])\n","#\n","#scalers={}\n","#for i in range(X.shape[2]):\n","#    scalers[i] = StandardScaler().fit(X[:,:,i])\n","#    X[:, :, i] = scalers[i].transform(X[:, :, i])\n","    \n","\n","\n","\n","\n","\n","\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","X = scaler.fit_transform(X)\n","\n","scaler = StandardScaler().fit(X)\n","X = scaler.transform(X)\n","\n","X = numpy.reshape(X, (127512,3000,1))\n","\n","seed = 3\n","numpy.random.seed(seed)\n","\n","x_train, x_test1, y_train, y_test1 = train_test_split(X, Y, test_size=0.3, random_state=seed)\n","\n","x_val, x_test, y_val, y_test = train_test_split(x_test1, y_test1, test_size=0.5, random_state=seed)\n","\n","#x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=seed)\n","\n","foldername=\"model\"\n","filename=\"/epoch-{epoch:02d}-val-acc-{val_acc:.4f}.hdf5\"\n","\n","checkpoints = []\n","\n","\n","#keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n","\n","checkpoints.append(ModelCheckpoint(foldername+filename, \n","                                   monitor='val_acc', \n","                                   verbose=1, \n","                                   save_best_only=True, \n","                                   save_weights_only=True, \n","                                   mode='max', \n","                                   period=1))\n","\n","\n","\n","from keras import regularizers\n","sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.6, nesterov=True)\n","adam=optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-4, amsgrad=False)\n","\n","#kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n","#cvscores = []\n","#for train, test in kfold.split(X, Y):\n","\n","model = Sequential()\n","\n","\n","model.add(Conv1D(64,5, strides=3, input_shape = (3000, 1), activation = 'relu'))\n","model.add(Conv1D(128,3, strides=1,activation = 'relu'))\n","model.add(MaxPooling1D(pool_size=2,strides=2))\n","model.add(Dropout(0.2))\n","model.add(Conv1D(128,13, strides=1,activation = 'relu'))\n","model.add(Conv1D(256,7, strides=1,activation = 'relu'))\n","model.add(MaxPooling1D(pool_size=2,strides=2))\n","model.add(Conv1D(128,8, strides=1,activation = 'relu'))\n","model.add(Conv1D(64,4, strides=1,activation = 'relu'))\n","model.add(MaxPooling1D(pool_size=2,strides=2))\n","model.add(Conv1D(32,3, strides=1,activation = 'relu'))\n","model.add(Conv1D(64,6, strides=1,activation = 'relu'))\n","model.add(MaxPooling1D(pool_size=2,strides=2))\n","model.add(Conv1D(8,5, strides=1,activation = 'relu'))\n","model.add(Conv1D(8,2, strides=1,activation = 'relu'))\n","model.add(MaxPooling1D(pool_size=2,strides=2))\n","\n","\n","#model.add(Conv1D(128,3, strides=1,activation = 'relu'))\n","#model.add(MaxPooling1D(pool_size=2,strides=2))\n","#model.add(Conv1D(128,3, strides=1,activation = 'relu'))\n","#model.add(Conv1D(256,3, strides=1,activation = 'relu'))\n","#model.add(Conv1D(64,3, strides=1,activation = 'relu'))\n","#model.add(MaxPooling1D(pool_size=2,strides=2))\n","#model.add(Conv1D(32,3, strides=1,activation = 'relu'))\n","#model.add(Conv1D(32,3, strides=1,activation = 'relu'))\n","#model.add(MaxPooling1D(pool_size=2,strides=2))\n","#model.add(Conv1D(16,3, strides=1,activation = 'relu'))\n","\n","model.add(Flatten())\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(nb_class, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n","        \n","#        model.fit(X[train], Y[train],validation_data=(X[test], Y[test]), epochs=50, batch_size=64, verbose=1)\n","#        scores,acc = model.evaluate(X[test], Y[test], verbose=1)\n","#        #print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","#        #scores.append(scores[1] * 100)\n","#        #cvscores.append(scores[1] * 100)\n","#\n","#print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))        \n","        \n","\n","history=model.fit(x_train, y_train,\n","                  batch_size=64,\n","                  epochs=100,\n","                  validation_data=(x_val, y_val),shuffle=False) #callbacks=checkpoints\n","score, acc = model.evaluate(x_val, y_val,\n","                                   batch_size=64)\n","\n","print(history.history.keys())\n","# summarize history for accuracy\n","plt.plot(history.history['acc'])\n","plt.hold\n","plt.plot(history.history['val_acc'])\n","\n","\n","\n","model.save_weights(\"model/SFX6.hdf5\")\n","from sklearn.metrics import classification_report,confusion_matrix\n","#model.load_weights(\"model/Best.hdf5\")\n","\n","y_pred = model.predict(x_test)\n","y_pred = numpy.argmax(y_pred, axis=1)\n","print(y_pred)\n","testPredict = model.predict(x_test)\n","\n","p=model.predict_proba(x_test) # to predict probability\n","\n","target_names = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4', 'class 1', 'class 2', 'class 3', 'class 4', 'class 1', 'class 2', 'class 3', 'class 4', 'class 1', 'class 2', 'class 3', 'class 4']\n","print(classification_report(numpy.argmax(y_test,axis=1), y_pred,target_names=target_names))\n","print(confusion_matrix(numpy.argmax(y_test,axis=1), y_pred))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yxM2vrbhmhdJ","colab_type":"code","outputId":"68e186f0-2016-4073-d0e0-6586f55e474d","executionInfo":{"status":"ok","timestamp":1539809496364,"user_tz":-180,"elapsed":35445,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":73}},"cell_type":"code","source":["tbc=TensorBoardColab()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Wait for 8 seconds...\n","TensorBoard link:\n","http://d893754a.ngrok.io\n"],"name":"stdout"}]},{"metadata":{"id":"jwL1lOjlzqvY","colab_type":"code","outputId":"02e728b2-a3a8-4923-ec2a-906c8242ca62","executionInfo":{"status":"ok","timestamp":1539809702348,"user_tz":-180,"elapsed":11220,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["!ls 'drive'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ls: cannot access 'drive': No such file or directory\n"],"name":"stdout"}]},{"metadata":{"id":"ovueFXOD0MQS","colab_type":"code","outputId":"25a0d614-c202-4b29-a82b-11dd04aeaa11","executionInfo":{"status":"ok","timestamp":1539855308546,"user_tz":-180,"elapsed":9918,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","\n","import os\n","os.chdir('drive')\n","!ls 'drive'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["'Adsız klasör'\t drive\n"],"name":"stdout"}]},{"metadata":{"id":"xeqW2E3I0jUL","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls 'drive'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qlS4aJ-emsRS","colab_type":"code","outputId":"c74f7c14-b2a3-4b28-d274-3da29d66ca23","executionInfo":{"status":"ok","timestamp":1539809628190,"user_tz":-180,"elapsed":19566,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":73}},"cell_type":"code","source":["tbc=TensorBoardColab(6006,\"result/intersection/OUR6-60/TensorBoardLogs\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Wait for 8 seconds...\n","TensorBoard link:\n","http://d893754a.ngrok.io\n"],"name":"stdout"}]},{"metadata":{"id":"sTojhQf1z-5w","colab_type":"code","colab":{}},"cell_type":"code","source":["tensorboard = TensorBoard(log_dir=LOG_DIR, histogram_freq=0, write_graph=True, write_images=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PzW2Q_Bs0Jes","colab_type":"code","colab":{}},"cell_type":"code","source":["model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'])\n","history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, callbacks=[tensorboard], verbose=VERBOSE)\n","\n","print('Testing...')\n","score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n","\n","print(\"Test score:\", score[0])\n","print('Test accuracy:', score[1])\n","\n","model_json = model.to_json()\n","open('cifar10_architecture.json', 'w').write(model_json)\n","model.save_weights('cifar10_weights.h5', overwrite=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lf3Ota6waxpQ","colab_type":"code","outputId":"828aaa9b-2e3b-4ade-f307-97e20a3c3e88","executionInfo":{"status":"ok","timestamp":1543349162858,"user_tz":-180,"elapsed":10505,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":146}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","!ls drive\n","\n","import os\n","os.chdir(\"drive\")\n","root='datasets/'\n","\n","typ='intersection/'\n","\n","#@title\n","#@title\n","\n","#import tensorflow as tf\n","#tf.nn.sigmoid_cross_entropy_with_logits?\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" 70_15_15\t\t\t\t\t   intersection.ipynb\n"," belgeler\t\t\t\t\t   Intersections_16_11.docx\n","'Colab Notebooks'\t\t\t\t   log1\n"," datasets\t\t\t\t\t   __pycache__\n"," depo\t\t\t\t\t\t   result\n"," drive\t\t\t\t\t\t   road.ipynb\n"," google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n"],"name":"stdout"}]},{"metadata":{"id":"0XsavWj6uWMY","colab_type":"code","outputId":"fc7bd70f-24a3-4026-80fb-685b9dd471c3","executionInfo":{"status":"ok","timestamp":1539855427029,"user_tz":-180,"elapsed":3889,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["drive\n"],"name":"stdout"}]},{"metadata":{"id":"kvRkPwWiu2w-","colab_type":"code","colab":{}},"cell_type":"code","source":["os.chdir(\"drive\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CPlsQo85St91","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title\n","foldername='result/intersection/OUR6-36'\n","log_dir2=foldername+'/TensorBoardLogs'\n","LOG_DIR = log_dir2\n","\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip\n","\n","import os\n","if not os.path.exists(LOG_DIR):\n","  os.makedirs(LOG_DIR)\n","  \n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR))\n","\n","get_ipython().system_raw('./ngrok http 6006 &')\n","\n","!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"lTnuqBUKg-XC","colab_type":"code","colab":{}},"cell_type":"code","source":["####  80-20 ### RGB ### 192-72  ##################\n","typ='all2/dataset_2/'\n","X_train=np.load(root+typ+'x_train.npy')\n","X_test=np.load(root+typ+'x_test.npy')\n","X_val=np.load(root+typ+'x_val.npy')\n","\n","Y_train=np.load(root+typ+'y_train.npy')\n","Y_test=np.load(root+typ+'y_test.npy')\n","Y_val=np.load(root+typ+'y_val.npy')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vFDbDps-CHS5","colab_type":"code","outputId":"2727e938-9772-486a-954e-d410b4cb2380","executionInfo":{"status":"ok","timestamp":1543349175052,"user_tz":-180,"elapsed":10789,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"cell_type":"code","source":["print('Train= ', X_train.shape, '\\n Test= ',X_test.shape ,'\\n Val',X_val.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train=  (516, 64, 128, 3) \n"," Test=  (107, 64, 128, 3) \n"," Val (113, 64, 128, 3)\n"],"name":"stdout"}]},{"metadata":{"id":"_dbh3Sj8BSm6","colab_type":"code","outputId":"bcd34c19-095d-48b1-8083-2ddd0f9a21fe","executionInfo":{"status":"error","timestamp":1540232740632,"user_tz":-180,"elapsed":1046,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":172}},"cell_type":"code","source":["size(Y_val)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-a2f439f3680f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'size' is not defined"]}]},{"metadata":{"id":"toQYOZ3GqdOU","colab_type":"code","outputId":"a0af1a51-ea5b-4191-ed88-2c7f7065961c","executionInfo":{"status":"ok","timestamp":1538985238256,"user_tz":-180,"elapsed":1503,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["ImageDataGenerator(featurewise_center=False, \n","                   samplewise_center=False, \n","                   featurewise_std_normalization=False, \n","                   samplewise_std_normalization=False, \n","                   zca_whitening=False, \n","                   zca_epsilon=1e-06, \n","                   rotation_range=15, \n","                   width_shift_range=0.2, \n","                   height_shift_range=0.2, \n","                   brightness_range=None, \n","                   shear_range=0.2, \n","                   zoom_range=0.1, \n","                   channel_shift_range=0.2, \n","                   fill_mode='nearest', \n","                   cval=0.1, \n","                   horizontal_flip=False, \n","                   vertical_flip=False, \n","                   rescale=None, \n","                   preprocessing_function=None, \n","                   data_format=None, \n","                   validation_split=0.0)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.preprocessing.image.ImageDataGenerator at 0x7f1c7462dcf8>"]},"metadata":{"tags":[]},"execution_count":27}]},{"metadata":{"id":"go5r80GjsJMu","colab_type":"code","colab":{}},"cell_type":"code","source":["datagen = ImageDataGenerator(\n","    featurewise_center=True,\n","    featurewise_std_normalization=True,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uN4jtUJdi_Ts","colab_type":"code","colab":{}},"cell_type":"code","source":["datagen.fit(X_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"c_Dlb3OH65z3","colab_type":"code","outputId":"f694fceb-58cc-466c-c687-b6d4ef25123e","executionInfo":{"status":"ok","timestamp":1539078563657,"user_tz":-180,"elapsed":1173,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["X_train.shape[1]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["64"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"FwcuSVG6APgq","colab_type":"code","colab":{}},"cell_type":"code","source":["img_h = X_train.shape[1]\n","img_w = X_train.shape[2]\n","\n","for X_batch, Y_batch in datagen.flow(X_train, Y_train, batch_size=9):\n","    # Show 9 images\n","    for i in range(0, 9):\n","        plt.subplot(330 + 1 + i)\n","        plt.imshow(X_batch[i].reshape(img_h, img_w, 3))\n","    # show the plot\n","    plt.show()\n","    break"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Dnj6qoqNCZFG","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# Plot images\n","from keras.datasets import mnist\n","from matplotlib import pyplot\n","# load data\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# create a grid of 3x3 images\n","for i in range(0, 9):\n","\tpyplot.subplot(330 + 1 + i)\n","\tpyplot.imshow(X_train[i], cmap=pyplot.get_cmap('gray'))\n","# show the plot\n","pyplot.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xlm9OWhFvvRV","colab_type":"code","outputId":"39c2a647-a534-4916-87fa-e5ebe2ab6987","executionInfo":{"status":"ok","timestamp":1543349177013,"user_tz":-180,"elapsed":3969,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":172}},"cell_type":"code","source":["img_h = X_train.shape[1]\n","img_w = X_train.shape[2]\n","channel_size = X_train.shape[3] # 1: Grayscale, 3: RGB\n","\n","print('Dataset shape:', X_train.shape)\n","print(X_train.shape[0], 'sample,',X_train.shape[1] ,'x',X_train.shape[2], 'x', channel_size, ' size color image.\\n')\n","\n","print('Examples:')\n","n = 10\n","plt.figure(figsize=(20, 2))\n","for i in range(1, n+1):\n","    # Display data:\n","    ax = plt.subplot(1, n, i)\n","    plt.imshow(X_train[np.random.randint(0, X_train.shape[0], 1)].reshape(img_h, img_w,channel_size))\n","    plt.imshow(X_test[np.random.randint(0, X_test.shape[0], 1)].reshape(img_h, img_w,channel_size))\n","\n","    plt.axis('off')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Dataset shape: (516, 64, 128, 3)\n","516 sample, 64 x 128 x 3  size color image.\n","\n","Examples:\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAABHwAAABSCAYAAAAmYcN6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n","text/plain":["<matplotlib.figure.Figure at 0x7f0395e0c8d0>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"19bDltde4dlf","colab_type":"code","outputId":"103e5690-6cef-4a5a-c998-a9cdf9aa948a","executionInfo":{"status":"ok","timestamp":1541534670195,"user_tz":-180,"elapsed":591,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["Y_test.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(45, 3)"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"NlfvV5vLHUsy","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title\n","img_h = X_train.shape[1]\n","img_w = X_train.shape[2]\n","channel_size = X_train.shape[3] # 1: Grayscale, 3: RGB\n","\n","print('Dataset shape:', X_train.shape)\n","print(X_train.shape[0], 'sample,',X_train.shape[1] ,'x',X_train.shape[2], 'x', channel_size, ' size color image.\\n')\n","\n","print('Examples:')\n","n = 10\n","plt.figure(figsize=(10, 2))\n","for i in range(1, n+1):\n","    # Display data:\n","    ax = plt.subplot(1, n, i)\n","    plt.imshow(X_train[np.random.randint(0, X_train.shape[0], 1)].reshape(img_h, img_w))\n","    plt.axis('off')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E_D6jc4fLZsX","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title\n","img_h = X_test.shape[1]\n","img_w = X_test.shape[2]\n","channel_size = X_test.shape[3] # 1: Grayscale, 3: RGB\n","\n","print('Dataset shape:', X_test.shape)\n","print(X_test.shape[0], 'sample,',X_test.shape[1] ,'x',X_test.shape[2], 'x', channel_size, ' size color image.\\n')\n","\n","print('Examples:')\n","n = 10\n","plt.figure(figsize=(20, 2))\n","for i in range(1, n+1):\n","    # Display data:\n","    ax = plt.subplot(1, n, i)\n","    plt.imshow(X_test[np.random.randint(0, X_test.shape[0], 1)].reshape(img_h, img_w,channel_size))\n","    plt.axis('off')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LEze8ljqb6Jm","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","!ls drive\n","\n","import os\n","os.chdir(\"drive\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C182fB72n5cM","colab_type":"code","colab":{}},"cell_type":"code","source":["from Model_class4_128_64_1_stride2 import our_1_drp\n","model = our_1_drp()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jcNoRBAWEFCq","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"jCAQHP3pA90O","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Default title text 75.62 k33 , (192, 72, 3) 8-20 F:5 S:5\n","    model = Sequential()\n","\n","    model.add(Conv2D(32, (5, 5), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(32, (5, 5), strides=(5,5), padding='SAME'))\n","    model.add(Activation('relu'))\n","\n","\n","    model.add(Conv2D(32, (5, 5), padding='SAME'))\n","    model.add(Activation('relu'))\n","\n","\n","    model.add(Conv2D(64, (5, 5), padding='SAME'))\n","    model.add(Activation('relu'))\n","\n","    model.add(Conv2D(64, (5, 5), strides=(5,5), padding='SAME'))\n","    model.add(Activation('relu'))\n","\n","\n","    model.add(Conv2D(64, (5, 5), padding='SAME'))\n","    model.add(Activation('relu'))\n","\n","    model.add(Conv2D(128, (5, 5), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Flatten())\n","\n","    # Fully connected layer\n","    model.add(Dense(2048))\n","    model.add(Dense(2048))\n","    model.add(Dense(2))\n","\n","    model.add(Activation('softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_c7FihMQ3vtw","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Default title text k30 75.82, (192, 72, 3) 8,-20 F:3 S:7\n","    model = Sequential()\n","\n","    model.add(Conv2D(32, (3, 3), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(32, (3, 3), strides=(7,7), padding='SAME'))\n","    model.add(Activation('relu'))\n","\n","\n","    model.add(Conv2D(32, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","\n","\n","    model.add(Conv2D(64, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(64, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","\n","\n","    model.add(Conv2D(64, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(128, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Flatten())\n","\n","    # Fully connected layer\n","    model.add(Dense(2048))\n","    model.add(Dense(2048))\n","    model.add(Dense(4))\n","\n","    model.add(Activation('softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"g705PYtol9DU","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Default title text 85.71 OUR 1 model k28 80-20 input_shape=(192, 72, 3)\n","\n","name='OUR-1-'\n","from keras import optimizers\n","model=\"\"\n","model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(32, (3, 3), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(32, (3, 3), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(64, (3, 3), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(64, (3, 3), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(64, (3, 3), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(128, (3, 3), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Flatten())\n","\n","# Fully connected layer\n","\n","model.add(Dense(2048))\n","model.add(Dense(2048))\n","model.add(Dense(4))\n","\n","model.add(Activation('softmax'))\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EI_d-8ib1eba","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Default title text our F:5, 82.42, our, input_shape=(192, 72, 3) 80-20 C-4\n","\n","    model = Sequential()\n","\n","    model.add(Conv2D(32, (5, 5), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(32, (5, 5), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(32, (5, 5), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(64, (5, 5), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(64, (5, 5), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(64, (5, 5), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(128, (5, 5), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Flatten())\n","\n","    # Fully connected layer\n","    model.add(Dense(2048))\n","    model.add(Dense(2048))\n","    model.add(Dense(4))\n","\n","    model.add(Activation('softmax'))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"r5-5eAi6WLci","colab_type":"code","cellView":"both","colab":{}},"cell_type":"code","source":["#@title Default title text 84,61 ourbb OUR 2 input_shape=(192, 72, 3), 80-20 C-4\n","name='OUR-2-'\n","model=\"\"\n","model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","BatchNormalization(axis=-1)\n","model.add(Activation('relu'))\n","\n","model.add(Conv2D(32, (3, 3), padding='SAME'))\n","BatchNormalization(axis=-1)\n","model.add(Activation('relu'))\n","\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(64, (5, 5), padding='SAME'))\n","BatchNormalization(axis=-1)\n","model.add(Activation('relu'))\n","\n","model.add(Conv2D(128, (5, 5), padding='SAME'))\n","BatchNormalization(axis=-1)\n","model.add(Activation('relu'))\n","\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Flatten())\n","\n","# Fully connected layer\n","model.add(Dense(2048))\n","BatchNormalization()\n","model.add(Activation('relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(4))\n","\n","model.add(Activation('softmax'))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"szMp08At2Y-R","colab_type":"code","colab":{}},"cell_type":"code","source":["name='OUR-3-'\n","model=\"\"\n","model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(32, (3, 3), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(3, 3), padding='SAME'))\n","\n","model.add(Conv2D(64, (3, 3), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(3, 3), padding='SAME'))\n","\n","model.add(Conv2D(64, (3, 3), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(128, (3, 3), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Flatten())\n","\n","# Fully connected layer\n","\n","model.add(Dense(4048))\n","model.add(Dense(2048))\n","model.add(Dense(4))\n","\n","model.add(Activation('softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Eu_ofhshkhY6","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Default title text LENET 82,42\n","\n","name='LENET-'\n","model=\"\"\n","model = Sequential()\n","\n","model.add(Conv2D(6, (5, 5), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","BatchNormalization(axis=-1)\n","model.add(Activation('relu'))\n","\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(16, (5, 5), padding='SAME'))\n","BatchNormalization(axis=-1)\n","model.add(Activation('relu'))\n","\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(120, (5, 5), padding='SAME'))\n","BatchNormalization(axis=-1)\n","model.add(Activation('relu'))\n","\n","model.add(Flatten())\n","\n","# Fully connected layer\n","model.add(Dense(84))\n","BatchNormalization()\n","model.add(Activation('relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(4))\n","\n","model.add(Activation('softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nbdhviPMLHcE","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Default title text VGG5 modeli 85.71 32 batch, 16 batch 83.52\n","\n","name='VGG5-'\n","model=\"\"\n","model = Sequential()\n","\n","model.add(Conv2D(16, (3, 3), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","BatchNormalization(axis=-1)\n","model.add(Activation('relu'))\n","\n","model.add(Conv2D(16, (3, 3), padding='SAME'))\n","BatchNormalization(axis=-1)\n","model.add(Activation('relu'))\n","\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(48, (3, 3), padding='SAME'))\n","BatchNormalization(axis=-1)\n","model.add(Activation('relu'))\n","\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Flatten())\n","\n","# Fully connected layer\n","model.add(Dense(128))\n","BatchNormalization()\n","model.add(Activation('relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(4))\n","\n","model.add(Activation('softmax'))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"goCDQjW_cR9P","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Default title text VGG5 modeli 85.71 32 batch, 16 batch 83.52\n","\n","name='VGG16-'\n","model=\"\"\n","\n","model = Sequential()\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(img_h,img_w, channel_size)))\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(4, activation='softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EMXdboOJIc3r","colab_type":"code","colab":{}},"cell_type":"code","source":["#Alex Net\n","name=\"Alex\"\n","model=\"\"\n","model = Sequential()\n","model.add(Conv2D(96, (11, 11), activation='relu', input_shape=(img_h,img_w, channel_size),strides=4))\n","model.add(MaxPooling2D((3, 3),strides=2))\n","\n","model.add(Conv2D(256, (5, 5), activation='relu',strides=1,padding=\"same\"))\n","model.add(MaxPooling2D((3, 3),strides=2))\n","\n","model.add(Conv2D(384, (3, 3), activation='relu',strides=1,padding=\"same\"))\n","model.add(Conv2D(384, (3, 3), activation='relu',strides=1,padding=\"same\"))\n","model.add(Conv2D(256, (3, 3), activation='relu',strides=1,padding=\"same\"))\n","model.add(MaxPooling2D((3, 3),strides=2))\n","\n","model.add(Dense(4096, activation='relu'))\n","\n","model.add(Dense(4096, activation='relu'))\n","\n","\n","model.add(Flatten())\n","model.add(Dense(2))\n","model.add(Activation('softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C6vARBs1JN4C","colab_type":"code","colab":{}},"cell_type":"code","source":["#Alex net\n","name=\"Alex_drop\"\n","model=\"\"\n","\n","model = Sequential()\n","model.add(Conv2D(96, (11, 11), activation='relu', input_shape=(img_h,img_w, 3),strides=4))\n","model.add(MaxPooling2D((3, 3),strides=2))\n","model.add(BatchNormalization())\n","model.add(Conv2D(256, (5, 5), activation='relu',strides=1,padding=\"same\"))\n","model.add(BatchNormalization())\n","model.add(Conv2D(384, (3, 3), activation='relu',strides=1,padding=\"same\"))\n","model.add(Conv2D(384, (3, 3), activation='relu',strides=1,padding=\"same\"))\n","model.add(Conv2D(256, (3, 3), activation='relu',strides=1,padding=\"same\"))\n","model.add(MaxPooling2D((3, 3),strides=2))\n","model.add(Dense(4096, activation='relu'))\n","model.add(Dropout(0,5))\n","model.add(Dense(4096, activation='relu'))\n","model.add(Dropout(0,5))\n","\n","model.add(Flatten())\n","model.add(Dense(4, activation='softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qotWBe5UqhTA","colab_type":"code","cellView":"both","colab":{}},"cell_type":"code","source":["#@title Default title text 85.71 our model k28 80-20 input_shape=(192, 72, 3)\n","#@title Default title text 85.71 our model k28 70-0 input_shape=(192, 72, 3)\n","#@title Default title text 85.71 our model o4-3 77.78\n","name='OUR4-'\n","model=\"\"\n","model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(32, (3, 3), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(32, (3, 3), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(64, (3, 3), padding='SAME'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Flatten())\n","\n","# Fully connected layer\n","model.add(Dense(2048))\n","model.add(Dense(2048))\n","model.add(Dense(4))\n","\n","model.add(Activation('softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rNiICeRVEBXN","colab_type":"code","colab":{}},"cell_type":"code","source":["name='OUR5-' #stride left-right\n","model=\"\"\n","model = Sequential()\n","\n","model.add(Conv2D(6, (7, 7), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","BatchNormalization(axis=-1)\n","model.add(Activation('relu'))\n","\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(16, (5, 5), strides=(2,2), padding='SAME'))\n","BatchNormalization(axis=-1)\n","model.add(Activation('relu'))\n","\n","model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","model.add(Conv2D(120, (3, 3), padding='SAME'))\n","BatchNormalization(axis=-1)\n","model.add(Activation('relu'))\n","\n","model.add(Flatten())\n","\n","# Fully connected layer\n","model.add(Dense(84))\n","BatchNormalization()\n","model.add(Activation('relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(4))\n","\n","model.add(Activation('softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pQoOVDa0JqVK","colab_type":"code","colab":{}},"cell_type":"code","source":["name='OUR6-'\n","model=\"\"\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(32, (3, 3), strides=(2,2)))\n","model.add(Conv2D(32, (3, 3), strides=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Dropout(0.25))\n","\n","# Fully connected layer\n","model.add(Dense(84))\n","BatchNormalization()\n","model.add(Activation('relu'))\n","model.add(Dense(4))\n","\n","model.add(Activation('softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KZZLJMADmIMG","colab_type":"code","colab":{}},"cell_type":"code","source":["name='OUR6-' #intersection 94.915\n","model=\"\"\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(32, (3, 3), strides=(2,2)))\n","model.add(Conv2D(32, (3, 3), strides=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3)))\n","\n","model.add(Conv2D(32, (3, 3), strides=(2,2)))##\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Dropout(0.25))\n","\n","# Fully connected layer\n","model.add(Dense(84))\n","BatchNormalization()\n","model.add(Activation('relu'))\n","model.add(Dense(4))\n","\n","model.add(Activation('softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bkkAH2jtiUf8","colab_type":"code","colab":{}},"cell_type":"code","source":["#our 6-60 93.20 model\n","\n","name='OUR6-' #intersection 94.915\n","model=\"\"\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(32, (3, 3), strides=(2,2)))\n","model.add(Conv2D(32, (3, 3), strides=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3)))\n","\n","model.add(Conv2D(32, (3, 3), strides=(2,2)))##\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Dropout(0.25))\n","\n","# Fully connected layer\n","model.add(Dense(84))\n","BatchNormalization()\n","model.add(Activation('relu'))\n","model.add(Dense(4))\n","\n","model.add(Activation('softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G-w0gjoLakUo","colab_type":"code","colab":{}},"cell_type":"code","source":["name='OUR6-'#for crosswalk\n","\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(32, (3, 3), strides=(2,2)))\n","model.add(Dropout(0.10))\n","\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.10))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Dropout(0.25))\n","\n","# Fully connected layer\n","model.add(Dense(84))\n","BatchNormalization()\n","model.add(Activation('relu'))\n","model.add(Dense(4))\n","\n","model.add(Activation('softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fm34aDFI4nEb","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","model = Sequential()\n","\n","\n","model.add(Conv2D(64,5, strides=(2,2), input_shape=(img_h, img_w, channel_size), activation = 'relu'))\n","model.add(Conv2D(128,3, strides=(1,1),activation = 'relu'))\n","model.add(MaxPooling2D(pool_size=2,strides=2))\n","model.add(Dropout(0.2))\n","model.add(Conv2D(128,13, strides=(1,1),activation = 'relu'))\n","model.add(Conv2D(256,7, strides=(1,1),activation = 'relu'))\n","model.add(MaxPooling2D(pool_size=2,strides=2))\n","model.add(Conv2D(128,8, strides=(1,1),activation = 'relu'))\n","model.add(Conv2D(64,4, strides=(1,1),activation = 'relu'))\n","model.add(MaxPooling2D(pool_size=2,strides=2))\n","model.add(Conv2D(32,3, strides=(1,1),activation = 'relu'))\n","model.add(Conv2D(64,6, strides=(1,1),activation = 'relu'))\n","model.add(MaxPooling2D(pool_size=2,strides=2))\n","model.add(Conv2D(8,5, strides=(1,1),activation = 'relu'))\n","model.add(Conv2D(8,2, strides=(1,1),activation = 'relu'))\n","model.add(MaxPooling2D(pool_size=2,strides=2))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4vzZrurArYxs","colab_type":"code","outputId":"5aec6b39-1c62-4a74-c0ed-a3417d16c8d6","executionInfo":{"status":"ok","timestamp":1541753981885,"user_tz":-180,"elapsed":1037,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["#x_val[0:29].shape\n","print(typ)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["crosswalk/cn/\n"],"name":"stdout"}]},{"metadata":{"id":"3m30OeFuT54f","colab_type":"code","outputId":"2ae3e52f-4138-42ef-f85f-01570e33e0f8","executionInfo":{"status":"ok","timestamp":1542569733386,"user_tz":-180,"elapsed":1155,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["x_train[201:308].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(107, 64, 128, 3)"]},"metadata":{"tags":[]},"execution_count":27}]},{"metadata":{"id":"HGzO0ZoBMxe4","colab_type":"code","outputId":"87c769dc-01b6-4e38-bd1c-0289e1db06cf","executionInfo":{"status":"ok","timestamp":1543349281172,"user_tz":-180,"elapsed":15870,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":568}},"cell_type":"code","source":["#Load Data\n","import numpy\n","data='datasets/'+typ\n","result='result/all2/dataset_2/OUR6-8/'\n","model.load_weights(result+\"epoch-65-val-acc-0.7699.hdf5\")\n","\n","x_train=np.load(data+'x_train.npy')\n","y_train=np.load(data+'y_train.npy')\n","\n","x_test=np.load(data+'x_test.npy')\n","y_test=np.load(data+'y_test.npy')\n","\n","x_val=np.load(data+'x_val.npy')\n","y_val=np.load(data+'y_val.npy')\n","\n","print('Data:\\n Train data num: ', x_train.shape, ' sample \\n', 'Test data num: ', x_test.shape, \n","      ' sample \\n', 'Validation data num: ', x_val.shape, ' sample\\n')\n","print('========================================================\\n', result, 'Results: \\n')\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","#x_train[201:307]\n","#y_train[201:307]\n","\n","y_pred = model.predict(x_test)\n","y_pred = np.argmax(y_pred, axis=1)\n","\n","testPredict = model.predict(x_test)\n","\n","p=model.predict_proba(x_test) # to predict probability\n","\n","print('Confusion matrix result:\\n', confusion_matrix(np.argmax(y_test,axis=1), y_pred),'\\n')\n","\n","score = model.evaluate(x_test, y_test, batch_size=32, verbose=1)\n","print('\\n', 'Test accuracy:', score[1])\n","\n","target_names = ['Intersection', 'Left Seprt.', 'Right Seprt.', 'Crosswalk']\n","print(classification_report(numpy.argmax(y_test,axis=1), y_pred,target_names=target_names))\n","print(confusion_matrix(numpy.argmax(y_test,axis=1), y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Data:\n"," Train data num:  (516, 64, 128, 3)  sample \n"," Test data num:  (107, 64, 128, 3)  sample \n"," Validation data num:  (113, 64, 128, 3)  sample\n","\n","========================================================\n"," result/all2/dataset_2/OUR6-8/ Results: \n","\n","Confusion matrix result:\n"," [[23  2  3  0]\n"," [ 3  9  4  0]\n"," [ 3  4 25  2]\n"," [ 0  0  2 27]] \n","\n","107/107 [==============================] - 0s 1ms/step\n","\n"," Test accuracy: 0.7850467312001737\n","              precision    recall  f1-score   support\n","\n","Intersection       0.79      0.82      0.81        28\n"," Left Seprt.       0.60      0.56      0.58        16\n","Right Seprt.       0.74      0.74      0.74        34\n","   Crosswalk       0.93      0.93      0.93        29\n","\n"," avg / total       0.78      0.79      0.78       107\n","\n","[[23  2  3  0]\n"," [ 3  9  4  0]\n"," [ 3  4 25  2]\n"," [ 0  0  2 27]]\n"],"name":"stdout"}]},{"metadata":{"id":"dgmiZTKlI2id","colab_type":"code","colab":{}},"cell_type":"code","source":["all-data2 \n","\n","\n","Data:\n"," Train data num:  (516, 64, 128, 3)  sample \n"," Test data num:  (107, 64, 128, 3)  sample \n"," Validation data num:  (113, 64, 128, 3)  sample\n","\n","========================================================\n"," result/all2/dataset_2/OUR6-8/ Results: \n","\n","Confusion matrix result:\n"," [[23  2  3  0]\n"," [ 3  9  4  0]\n"," [ 3  4 25  2]\n"," [ 0  0  2 27]] \n","\n","107/107 [==============================] - 0s 1ms/step\n","\n"," Test accuracy: 0.7850467312001737\n","              precision    recall  f1-score   support\n","\n","Intersection       0.79      0.82      0.81        28\n"," Left Seprt.       0.60      0.56      0.58        16\n","Right Seprt.       0.74      0.74      0.74        34\n","   Crosswalk       0.93      0.93      0.93        29\n","\n"," avg / total       0.78      0.79      0.78       107\n","\n","[[23  2  3  0]\n"," [ 3  9  4  0]\n"," [ 3  4 25  2]\n"," [ 0  0  2 27]]\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JL3DTP8L2ouR","colab_type":"code","colab":{}},"cell_type":"code","source":["all2-dataset2\n","\n","Data:\n"," Train data num:  (516, 64, 128, 3)  sample \n"," Test data num:  (107, 64, 128, 3)  sample \n"," Validation data num:  (113, 64, 128, 3)  sample\n","\n","========================================================\n"," result/all2/dataset_2/OUR6-8/ Results: \n","\n","Confusion matrix result:\n"," [[25  1  1  1]\n"," [ 2 12  2  0]\n"," [ 4  3 25  2]\n"," [ 1  0  1 27]] \n","\n","107/107 [==============================] - 0s 422us/step\n","\n"," Test accuracy: 0.831775699820474\n","              precision    recall  f1-score   support\n","\n","Intersection       0.78      0.89      0.83        28\n"," Left Seprt.       0.75      0.75      0.75        16\n","Right Seprt.       0.86      0.74      0.79        34\n","   Crosswalk       0.90      0.93      0.92        29\n","\n"," avg / total       0.83      0.83      0.83       107\n","\n","[[25  1  1  1]\n"," [ 2 12  2  0]\n"," [ 4  3 25  2]\n"," [ 1  0  1 27]]\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5_xE6UWesbop","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","\n","Data:\n"," Train data num:  (588, 64, 128, 3)  sample \n"," Test data num:  (72, 64, 128, 3)  sample \n"," Validation data num:  (76, 64, 128, 3)  sample\n","\n","========================================================\n"," result/all2/dataset_1/OUR6-3/ Results: \n","\n","Confusion matrix result:\n"," [[17  1  1  0]\n"," [ 2  6  3  0]\n"," [ 1  2 19  1]\n"," [ 1  0  1 17]] \n","\n","72/72 [==============================] - 0s 447us/step\n","\n"," Test accuracy: 0.8194444444444444\n","              precision    recall  f1-score   support\n","\n","Intersection       0.81      0.89      0.85        19\n"," Left Seprt.       0.67      0.55      0.60        11\n","Right Seprt.       0.79      0.83      0.81        23\n","   Crosswalk       0.94      0.89      0.92        19\n","\n"," avg / total       0.82      0.82      0.82        72\n","\n","[[17  1  1  0]\n"," [ 2  6  3  0]\n"," [ 1  2 19  1]\n"," [ 1  0  1 17]]\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"R_jLQHpBiRBc","colab_type":"code","colab":{}},"cell_type":"code","source":["Data:\n"," Train data num:  (588, 64, 128, 3)  sample \n"," Test data num:  (72, 64, 128, 3)  sample \n"," Validation data num:  (76, 64, 128, 3)  sample\n","\n","========================================================\n"," result/all2/dataset_1/OUR6-3/ Results: \n","\n","Confusion matrix result:\n"," [[15  1  1  2]\n"," [ 1  7  2  1]\n"," [ 1  3 19  0]\n"," [ 1  0  1 17]] \n","\n","72/72 [==============================] - 0s 457us/step\n","\n"," Test accuracy: 0.8055555555555556\n","              precision    recall  f1-score   support\n","\n","Intersection       0.83      0.79      0.81        19\n"," Left Seprt.       0.64      0.64      0.64        11\n","Right Seprt.       0.83      0.83      0.83        23\n","   Crosswalk       0.85      0.89      0.87        19\n","\n"," avg / total       0.81      0.81      0.81        72\n","\n","[[15  1  1  2]\n"," [ 1  7  2  1]\n"," [ 1  3 19  0]\n"," [ 1  0  1 17]]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9j4FENdkiNZ4","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"3z92Q7VzhGvj","colab_type":"code","colab":{}},"cell_type":"code","source":["Data: INTERSECTIN RESULT\n","  \n"," Train data num:  (235, 64, 128, 3)  sample \n"," Test data num:  (29, 64, 128, 3)  sample \n"," Validation data num:  (30, 64, 128, 3)  sample\n","\n","========================================================\n"," result/intersection/OUR6-141/ Results: \n","\n","Confusion matrix result:\n"," [[ 9  1]\n"," [ 0 19]] \n","\n","29/29 [==============================] - 0s 378us/step\n","\n"," Test accuracy: 0.9655172228813171\n","             precision    recall  f1-score   support\n","\n","    class 0       1.00      0.90      0.95        10\n","    class 1       0.95      1.00      0.97        19\n","\n","avg / total       0.97      0.97      0.97        29\n","\n","[[ 9  1]\n"," [ 0 19]]\n","\n","\n","\n","100%\n","\n","Data:\n"," Train data num:  (234, 64, 128, 3)  sample \n"," Test data num:  (29, 64, 128, 3)  sample \n"," Validation data num:  (30, 64, 128, 3)  sample\n","\n","========================================================\n"," result/intersection/int/OUR6-391/ Results: \n","\n","Confusion matrix result:\n"," [[19  0]\n"," [ 0 10]] \n","\n","29/29 [==============================] - 0s 375us/step\n","\n"," Test accuracy: 1.0\n","             precision    recall  f1-score   support\n","\n","    class 0       1.00      1.00      1.00        19\n","    class 1       1.00      1.00      1.00        10\n","\n","avg / total       1.00      1.00      1.00        29\n","\n","[[19  0]\n"," [ 0 10]]\n","\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 2, does not match size of target_names, 3\n","  .format(len(labels), len(target_names))\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sYVt7PqNmUz9","colab_type":"code","colab":{}},"cell_type":"code","source":["Y_test"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SgdvKYkba4V6","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Default title text 85.71 our model k28 80-20 input_shape=(192, 72, 3)\n","#@title Default title text 85.71 our model k28 70-0 input_shape=(192, 72, 3)\n","    model = Sequential()\n","\n","    model.add(Conv2D(32, (3, 3), input_shape=(96, 36, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","\n","    model.add(Conv2D(32, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","    \n","    model.add(Conv2D(32, (3, 3), strides=(5,5), padding='SAME', ))\n","    model.add(Activation('relu'))\n","\n","    model.add(Conv2D(64, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(64, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(128, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Flatten())\n","\n","    # Fully connected layer\n","    model.add(Dense(2048))\n","    model.add(Dense(2048))\n","    model.add(Dense(4))\n","\n","    model.add(Activation('softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D0qEDyh_0uWE","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Default title text 85.71 our model k28 80-20 input_shape=(192, 72, 3)\n","    model = Sequential()\n","\n","    model.add(Conv2D(32, (3, 3), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(32, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(32, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(64, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(64, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(64, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(128, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Flatten())\n","\n","    # Fully connected layer\n","    model.add(Dense(2048))\n","    model.add(Dense(2048))\n","    model.add(Dense(4))\n","\n","    model.add(Activation('softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dQ47UEEivhWC","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Default title text 85.71 our model k28 80-20 input_shape=(192, 72, 3)\n","#@title Default title text 85.71 our model k28 70-30 input_shape=(192, 72, 3)\n","    model = Sequential()\n","\n","    model.add(Conv2D(32, (3, 3), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(32, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(32, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(64, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(64, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Conv2D(64, (3, 3), padding='SAME'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding='SAME'))\n","\n","    model.add(Flatten())\n","\n","    # Fully connected layer\n","    model.add(Dense(2048))\n","    model.add(Dense(2048))\n","    model.add(Dense(4))\n","\n","    model.add(Activation('softmax'))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JO8om-fQgzVW","colab_type":"code","colab":{}},"cell_type":"code","source":["model.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7DMchdad8Xtp","colab_type":"code","colab":{}},"cell_type":"code","source":["y_test"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kt-nrnFUz4Mk","colab_type":"code","colab":{}},"cell_type":"code","source":["k=20"],"execution_count":0,"outputs":[]},{"metadata":{"id":"a4nW5RBThisi","colab_type":"code","colab":{}},"cell_type":"code","source":["#from keras.callbacks import EarlyStopping\n","#earlystop = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=5, \\\n","#                          verbose=1, mode='auto')\n","#callbacks_list = [earlystop]\n","#start = time.start()\n","#end = time.end\n","\n","root='datasets/'\n","root2='result/'\n","k=k+1\n","\n","from keras import regularizers\n","sgd = optimizers.SGD(lr=0.00001, decay=1e-5, momentum=0.5, nesterov=True)\n","adam=optimizers.Adam(lr=0.0001, epsilon=None, decay=1e-5, amsgrad=False)# beta_1=0.9, beta_2=0.999,\n","\n","#adam=optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n","\n","#sgd = optimizers.SGD(lr=0.00001, decay=1e-3, momentum=0.5, nesterov=True)\n","\n","#model.compile(loss='mean_squared_error', optimizer=sgd)\n","\n","model.compile(loss='categorical_crossentropy', \n","              optimizer=adam, \n","              metrics=['accuracy'])\n","datagen = ImageDataGenerator(width_shift_range=0,vertical_flip=False)\n","\n","train_generator = datagen.flow(X_train, Y_train, batch_size=32)\n","foldername=root2+typ+name+str(k)\n","filename=\"/epoch-{epoch:02d}-val-acc-{val_acc:.4f}.hdf5\"\n","\n","checkpoints = []\n","\n","if not os.path.exists(foldername):\n","    os.makedirs(foldername)\n","\n","checkpoints.append(ModelCheckpoint(foldername+filename, \n","                                   monitor='val_acc', \n","                                   verbose=1, \n","                                   save_best_only=True, \n","                                   save_weights_only=True, \n","                                   mode='auto',\n","                                   period=1))\n","\n","log_dir2=foldername+'/TensorBoardLogs'\n","\n","checkpoints.append(TensorBoard(log_dir2, \n","                               histogram_freq=0, \n","                               write_graph=True, \n","                               write_images=False, \n","                               embeddings_freq=0, \n","                               embeddings_layer_names=None, \n","                               embeddings_metadata=None))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NTSQVSm9o6uA","colab_type":"code","outputId":"23b3f294-2850-48cc-f5b4-7cfd43174a85","executionInfo":{"status":"ok","timestamp":1543266373635,"user_tz":-180,"elapsed":119289,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":7382}},"cell_type":"code","source":["#@title Default title text\n","# TRAINING THE MODEL\n","model.fit_generator(train_generator, \n","                    steps_per_epoch=32, \n","                    epochs=100, \n","                    validation_data=(X_val, Y_val),\n","                    validation_steps=32,\n","                    callbacks=checkpoints)#callbacks_list yerine checkpoints"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","32/32 [==============================] - 4s 118ms/step - loss: 1.3711 - acc: 0.3024 - val_loss: 1.3570 - val_acc: 0.3041\n","\n","Epoch 00001: val_acc improved from -inf to 0.30405, saving model to result/all2/dataset_3/LENET-21/epoch-01-val-acc-0.3041.hdf5\n","Epoch 2/100\n","32/32 [==============================] - 1s 27ms/step - loss: 1.3400 - acc: 0.3439 - val_loss: 1.3286 - val_acc: 0.3041\n","\n","Epoch 00002: val_acc did not improve from 0.30405\n","Epoch 3/100\n","32/32 [==============================] - 1s 27ms/step - loss: 1.2972 - acc: 0.4105 - val_loss: 1.2632 - val_acc: 0.3581\n","\n","Epoch 00003: val_acc improved from 0.30405 to 0.35811, saving model to result/all2/dataset_3/LENET-21/epoch-03-val-acc-0.3581.hdf5\n","Epoch 4/100\n","32/32 [==============================] - 1s 27ms/step - loss: 1.2206 - acc: 0.4763 - val_loss: 1.1102 - val_acc: 0.6149\n","\n","Epoch 00004: val_acc improved from 0.35811 to 0.61486, saving model to result/all2/dataset_3/LENET-21/epoch-04-val-acc-0.6149.hdf5\n","Epoch 5/100\n","32/32 [==============================] - 1s 27ms/step - loss: 1.0712 - acc: 0.5843 - val_loss: 1.0255 - val_acc: 0.5541\n","\n","Epoch 00005: val_acc did not improve from 0.61486\n","Epoch 6/100\n","32/32 [==============================] - 1s 27ms/step - loss: 1.0476 - acc: 0.5674 - val_loss: 0.9983 - val_acc: 0.6014\n","\n","Epoch 00006: val_acc did not improve from 0.61486\n","Epoch 7/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.9853 - acc: 0.6105 - val_loss: 0.9305 - val_acc: 0.6757\n","\n","Epoch 00007: val_acc improved from 0.61486 to 0.67568, saving model to result/all2/dataset_3/LENET-21/epoch-07-val-acc-0.6757.hdf5\n","Epoch 8/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.8979 - acc: 0.6590 - val_loss: 0.8717 - val_acc: 0.6554\n","\n","Epoch 00008: val_acc did not improve from 0.67568\n","Epoch 9/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.8373 - acc: 0.6847 - val_loss: 0.8821 - val_acc: 0.6284\n","\n","Epoch 00009: val_acc did not improve from 0.67568\n","Epoch 10/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.8100 - acc: 0.6998 - val_loss: 0.8733 - val_acc: 0.6216\n","\n","Epoch 00010: val_acc did not improve from 0.67568\n","Epoch 11/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.7670 - acc: 0.7110 - val_loss: 0.8384 - val_acc: 0.6486\n","\n","Epoch 00011: val_acc did not improve from 0.67568\n","Epoch 12/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.7093 - acc: 0.7460 - val_loss: 0.8168 - val_acc: 0.6419\n","\n","Epoch 00012: val_acc did not improve from 0.67568\n","Epoch 13/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.6432 - acc: 0.7673 - val_loss: 0.8144 - val_acc: 0.6216\n","\n","Epoch 00013: val_acc did not improve from 0.67568\n","Epoch 14/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.6057 - acc: 0.7934 - val_loss: 0.8244 - val_acc: 0.6419\n","\n","Epoch 00014: val_acc did not improve from 0.67568\n","Epoch 15/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.5843 - acc: 0.7842 - val_loss: 0.8737 - val_acc: 0.6284\n","\n","Epoch 00015: val_acc did not improve from 0.67568\n","Epoch 16/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.5663 - acc: 0.8023 - val_loss: 0.8425 - val_acc: 0.6419\n","\n","Epoch 00016: val_acc did not improve from 0.67568\n","Epoch 17/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.5249 - acc: 0.8066 - val_loss: 0.8602 - val_acc: 0.6622\n","\n","Epoch 00017: val_acc did not improve from 0.67568\n","Epoch 18/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.4864 - acc: 0.8306 - val_loss: 0.8825 - val_acc: 0.6554\n","\n","Epoch 00018: val_acc did not improve from 0.67568\n","Epoch 19/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.4603 - acc: 0.8428 - val_loss: 0.8438 - val_acc: 0.6486\n","\n","Epoch 00019: val_acc did not improve from 0.67568\n","Epoch 20/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.4392 - acc: 0.8366 - val_loss: 0.9137 - val_acc: 0.6014\n","\n","Epoch 00020: val_acc did not improve from 0.67568\n","Epoch 21/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.4118 - acc: 0.8496 - val_loss: 0.9221 - val_acc: 0.6284\n","\n","Epoch 00021: val_acc did not improve from 0.67568\n","Epoch 22/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.3793 - acc: 0.8805 - val_loss: 0.8661 - val_acc: 0.6554\n","\n","Epoch 00022: val_acc did not improve from 0.67568\n","Epoch 23/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.3712 - acc: 0.8814 - val_loss: 0.9026 - val_acc: 0.6486\n","\n","Epoch 00023: val_acc did not improve from 0.67568\n","Epoch 24/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.3381 - acc: 0.8885 - val_loss: 0.9352 - val_acc: 0.6351\n","\n","Epoch 00024: val_acc did not improve from 0.67568\n","Epoch 25/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.3206 - acc: 0.8935 - val_loss: 0.9156 - val_acc: 0.6622\n","\n","Epoch 00025: val_acc did not improve from 0.67568\n","Epoch 26/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.3152 - acc: 0.9051 - val_loss: 0.9534 - val_acc: 0.6419\n","\n","Epoch 00026: val_acc did not improve from 0.67568\n","Epoch 27/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.2980 - acc: 0.9053 - val_loss: 0.9233 - val_acc: 0.6757\n","\n","Epoch 00027: val_acc did not improve from 0.67568\n","Epoch 28/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.2718 - acc: 0.9129 - val_loss: 1.0258 - val_acc: 0.6419\n","\n","Epoch 00028: val_acc did not improve from 0.67568\n","Epoch 29/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.2575 - acc: 0.9282 - val_loss: 0.9561 - val_acc: 0.6622\n","\n","Epoch 00029: val_acc did not improve from 0.67568\n","Epoch 30/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.2457 - acc: 0.9328 - val_loss: 0.9618 - val_acc: 0.6351\n","\n","Epoch 00030: val_acc did not improve from 0.67568\n","Epoch 31/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.2251 - acc: 0.9314 - val_loss: 1.0094 - val_acc: 0.6689\n","\n","Epoch 00031: val_acc did not improve from 0.67568\n","Epoch 32/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.2256 - acc: 0.9339 - val_loss: 1.0411 - val_acc: 0.6622\n","\n","Epoch 00032: val_acc did not improve from 0.67568\n","Epoch 33/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.2308 - acc: 0.9275 - val_loss: 1.0126 - val_acc: 0.6689\n","\n","Epoch 00033: val_acc did not improve from 0.67568\n","Epoch 34/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.2178 - acc: 0.9362 - val_loss: 1.0251 - val_acc: 0.6689\n","\n","Epoch 00034: val_acc did not improve from 0.67568\n","Epoch 35/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1887 - acc: 0.9487 - val_loss: 1.0322 - val_acc: 0.6824\n","\n","Epoch 00035: val_acc improved from 0.67568 to 0.68243, saving model to result/all2/dataset_3/LENET-21/epoch-35-val-acc-0.6824.hdf5\n","Epoch 36/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1771 - acc: 0.9498 - val_loss: 1.0637 - val_acc: 0.6824\n","\n","Epoch 00036: val_acc improved from 0.68243 to 0.68243, saving model to result/all2/dataset_3/LENET-21/epoch-36-val-acc-0.6824.hdf5\n","Epoch 37/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1905 - acc: 0.9418 - val_loss: 1.0880 - val_acc: 0.6757\n","\n","Epoch 00037: val_acc did not improve from 0.68243\n","Epoch 38/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1701 - acc: 0.9510 - val_loss: 1.0537 - val_acc: 0.6757\n","\n","Epoch 00038: val_acc did not improve from 0.68243\n","Epoch 39/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1463 - acc: 0.9597 - val_loss: 1.0827 - val_acc: 0.6824\n","\n","Epoch 00039: val_acc did not improve from 0.68243\n","Epoch 40/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1439 - acc: 0.9580 - val_loss: 1.2572 - val_acc: 0.6419\n","\n","Epoch 00040: val_acc did not improve from 0.68243\n","Epoch 41/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1623 - acc: 0.9530 - val_loss: 1.1342 - val_acc: 0.6892\n","\n","Epoch 00041: val_acc improved from 0.68243 to 0.68919, saving model to result/all2/dataset_3/LENET-21/epoch-41-val-acc-0.6892.hdf5\n","Epoch 42/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1262 - acc: 0.9681 - val_loss: 1.1628 - val_acc: 0.6689\n","\n","Epoch 00042: val_acc did not improve from 0.68919\n","Epoch 43/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1389 - acc: 0.9579 - val_loss: 1.2213 - val_acc: 0.6757\n","\n","Epoch 00043: val_acc did not improve from 0.68919\n","Epoch 44/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1370 - acc: 0.9547 - val_loss: 1.2226 - val_acc: 0.6622\n","\n","Epoch 00044: val_acc did not improve from 0.68919\n","Epoch 45/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1329 - acc: 0.9608 - val_loss: 1.1804 - val_acc: 0.6622\n","\n","Epoch 00045: val_acc did not improve from 0.68919\n","Epoch 46/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0960 - acc: 0.9792 - val_loss: 1.2826 - val_acc: 0.6554\n","\n","Epoch 00046: val_acc did not improve from 0.68919\n","Epoch 47/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.1107 - acc: 0.9675 - val_loss: 1.2614 - val_acc: 0.6757\n","\n","Epoch 00047: val_acc did not improve from 0.68919\n","Epoch 48/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0977 - acc: 0.9763 - val_loss: 1.2968 - val_acc: 0.6622\n","\n","Epoch 00048: val_acc did not improve from 0.68919\n","Epoch 49/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1066 - acc: 0.9713 - val_loss: 1.2402 - val_acc: 0.6689\n","\n","Epoch 00049: val_acc did not improve from 0.68919\n","Epoch 50/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.1025 - acc: 0.9734 - val_loss: 1.3471 - val_acc: 0.6554\n","\n","Epoch 00050: val_acc did not improve from 0.68919\n","Epoch 51/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0903 - acc: 0.9746 - val_loss: 1.2935 - val_acc: 0.6757\n","\n","Epoch 00051: val_acc did not improve from 0.68919\n","Epoch 52/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0835 - acc: 0.9784 - val_loss: 1.2970 - val_acc: 0.6689\n","\n","Epoch 00052: val_acc did not improve from 0.68919\n","Epoch 53/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0847 - acc: 0.9761 - val_loss: 1.3381 - val_acc: 0.6554\n","\n","Epoch 00053: val_acc did not improve from 0.68919\n","Epoch 54/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0927 - acc: 0.9686 - val_loss: 1.4150 - val_acc: 0.6284\n","\n","Epoch 00054: val_acc did not improve from 0.68919\n","Epoch 55/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0918 - acc: 0.9665 - val_loss: 1.3917 - val_acc: 0.6622\n","\n","Epoch 00055: val_acc did not improve from 0.68919\n","Epoch 56/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0762 - acc: 0.9802 - val_loss: 1.4926 - val_acc: 0.6689\n","\n","Epoch 00056: val_acc did not improve from 0.68919\n","Epoch 57/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0749 - acc: 0.9834 - val_loss: 1.4722 - val_acc: 0.6554\n","\n","Epoch 00057: val_acc did not improve from 0.68919\n","Epoch 58/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0829 - acc: 0.9784 - val_loss: 1.4925 - val_acc: 0.6014\n","\n","Epoch 00058: val_acc did not improve from 0.68919\n","Epoch 59/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0852 - acc: 0.9735 - val_loss: 1.4459 - val_acc: 0.6216\n","\n","Epoch 00059: val_acc did not improve from 0.68919\n","Epoch 60/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0836 - acc: 0.9750 - val_loss: 1.3842 - val_acc: 0.6622\n","\n","Epoch 00060: val_acc did not improve from 0.68919\n","Epoch 61/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0765 - acc: 0.9813 - val_loss: 1.3888 - val_acc: 0.6554\n","\n","Epoch 00061: val_acc did not improve from 0.68919\n","Epoch 62/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0859 - acc: 0.9724 - val_loss: 1.3299 - val_acc: 0.6689\n","\n","Epoch 00062: val_acc did not improve from 0.68919\n","Epoch 63/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0688 - acc: 0.9833 - val_loss: 1.3779 - val_acc: 0.6824\n","\n","Epoch 00063: val_acc did not improve from 0.68919\n","Epoch 64/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0684 - acc: 0.9782 - val_loss: 1.5748 - val_acc: 0.6486\n","\n","Epoch 00064: val_acc did not improve from 0.68919\n","Epoch 65/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0708 - acc: 0.9802 - val_loss: 1.4830 - val_acc: 0.6757\n","\n","Epoch 00065: val_acc did not improve from 0.68919\n","Epoch 66/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0645 - acc: 0.9852 - val_loss: 1.4271 - val_acc: 0.6622\n","\n","Epoch 00066: val_acc did not improve from 0.68919\n","Epoch 67/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0612 - acc: 0.9823 - val_loss: 1.5921 - val_acc: 0.6689\n","\n","Epoch 00067: val_acc did not improve from 0.68919\n","Epoch 68/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0633 - acc: 0.9834 - val_loss: 1.4424 - val_acc: 0.6892\n","\n","Epoch 00068: val_acc improved from 0.68919 to 0.68919, saving model to result/all2/dataset_3/LENET-21/epoch-68-val-acc-0.6892.hdf5\n","Epoch 69/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0623 - acc: 0.9873 - val_loss: 1.5228 - val_acc: 0.6757\n","\n","Epoch 00069: val_acc did not improve from 0.68919\n","Epoch 70/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0600 - acc: 0.9766 - val_loss: 1.5939 - val_acc: 0.6689\n","\n","Epoch 00070: val_acc did not improve from 0.68919\n","Epoch 71/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0588 - acc: 0.9813 - val_loss: 1.6173 - val_acc: 0.6419\n","\n","Epoch 00071: val_acc did not improve from 0.68919\n","Epoch 72/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0591 - acc: 0.9803 - val_loss: 1.6356 - val_acc: 0.6622\n","\n","Epoch 00072: val_acc did not improve from 0.68919\n","Epoch 73/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0465 - acc: 0.9930 - val_loss: 1.6669 - val_acc: 0.6757\n","\n","Epoch 00073: val_acc did not improve from 0.68919\n","Epoch 74/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0528 - acc: 0.9851 - val_loss: 1.6188 - val_acc: 0.6554\n","\n","Epoch 00074: val_acc did not improve from 0.68919\n","Epoch 75/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0526 - acc: 0.9833 - val_loss: 1.6257 - val_acc: 0.6554\n","\n","Epoch 00075: val_acc did not improve from 0.68919\n","Epoch 76/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0585 - acc: 0.9859 - val_loss: 1.5829 - val_acc: 0.6689\n","\n","Epoch 00076: val_acc did not improve from 0.68919\n","Epoch 77/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0584 - acc: 0.9841 - val_loss: 1.5672 - val_acc: 0.6622\n","\n","Epoch 00077: val_acc did not improve from 0.68919\n","Epoch 78/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0535 - acc: 0.9863 - val_loss: 1.7699 - val_acc: 0.6757\n","\n","Epoch 00078: val_acc did not improve from 0.68919\n","Epoch 79/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0526 - acc: 0.9841 - val_loss: 1.6283 - val_acc: 0.6554\n","\n","Epoch 00079: val_acc did not improve from 0.68919\n","Epoch 80/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0468 - acc: 0.9851 - val_loss: 1.7284 - val_acc: 0.6689\n","\n","Epoch 00080: val_acc did not improve from 0.68919\n","Epoch 81/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0415 - acc: 0.9883 - val_loss: 1.7127 - val_acc: 0.6689\n","\n","Epoch 00081: val_acc did not improve from 0.68919\n","Epoch 82/100\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0471 - acc: 0.9833 - val_loss: 1.6107 - val_acc: 0.6757\n","\n","Epoch 00082: val_acc did not improve from 0.68919\n","Epoch 83/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0572 - acc: 0.9844 - val_loss: 1.4866 - val_acc: 0.6824\n","\n","Epoch 00083: val_acc did not improve from 0.68919\n","Epoch 84/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0473 - acc: 0.9881 - val_loss: 1.6375 - val_acc: 0.6824\n","\n","Epoch 00084: val_acc did not improve from 0.68919\n","Epoch 85/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0454 - acc: 0.9883 - val_loss: 1.6514 - val_acc: 0.6486\n","\n","Epoch 00085: val_acc did not improve from 0.68919\n","Epoch 86/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0471 - acc: 0.9853 - val_loss: 1.5916 - val_acc: 0.6757\n","\n","Epoch 00086: val_acc did not improve from 0.68919\n","Epoch 87/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0405 - acc: 0.9861 - val_loss: 1.6341 - val_acc: 0.6824\n","\n","Epoch 00087: val_acc did not improve from 0.68919\n","Epoch 88/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0440 - acc: 0.9902 - val_loss: 1.5869 - val_acc: 0.6824\n","\n","Epoch 00088: val_acc did not improve from 0.68919\n","Epoch 89/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0439 - acc: 0.9890 - val_loss: 1.7764 - val_acc: 0.6892\n","\n","Epoch 00089: val_acc did not improve from 0.68919\n","Epoch 90/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0481 - acc: 0.9869 - val_loss: 1.7028 - val_acc: 0.6419\n","\n","Epoch 00090: val_acc did not improve from 0.68919\n","Epoch 91/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0529 - acc: 0.9802 - val_loss: 1.6008 - val_acc: 0.6824\n","\n","Epoch 00091: val_acc did not improve from 0.68919\n","Epoch 92/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0359 - acc: 0.9922 - val_loss: 1.8173 - val_acc: 0.6554\n","\n","Epoch 00092: val_acc did not improve from 0.68919\n","Epoch 93/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0508 - acc: 0.9842 - val_loss: 1.7424 - val_acc: 0.6824\n","\n","Epoch 00093: val_acc did not improve from 0.68919\n","Epoch 94/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0390 - acc: 0.9883 - val_loss: 1.8328 - val_acc: 0.6622\n","\n","Epoch 00094: val_acc did not improve from 0.68919\n","Epoch 95/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0367 - acc: 0.9902 - val_loss: 1.8143 - val_acc: 0.6824\n","\n","Epoch 00095: val_acc did not improve from 0.68919\n","Epoch 96/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0390 - acc: 0.9873 - val_loss: 1.8833 - val_acc: 0.6486\n","\n","Epoch 00096: val_acc did not improve from 0.68919\n","Epoch 97/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0320 - acc: 0.9922 - val_loss: 1.8886 - val_acc: 0.6757\n","\n","Epoch 00097: val_acc did not improve from 0.68919\n","Epoch 98/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0282 - acc: 0.9920 - val_loss: 1.7705 - val_acc: 0.6486\n","\n","Epoch 00098: val_acc did not improve from 0.68919\n","Epoch 99/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0266 - acc: 0.9941 - val_loss: 1.7748 - val_acc: 0.6689\n","\n","Epoch 00099: val_acc did not improve from 0.68919\n","Epoch 100/100\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0266 - acc: 0.9940 - val_loss: 1.8974 - val_acc: 0.6554\n","\n","Epoch 00100: val_acc did not improve from 0.68919\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fd017ece2b0>"]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"id":"UiPXDQJJPNfk","colab_type":"code","colab":{}},"cell_type":"code","source":["ALL dataset 2 77 our6-7\n","\n","\n","\n","Epoch 1/100\n","32/32 [==============================] - 2s 47ms/step - loss: 1.3776 - acc: 0.2774 - val_loss: 1.3644 - val_acc: 0.3009\n","\n","Epoch 00001: val_acc improved from -inf to 0.30088, saving model to result/all2/dataset_2/OUR6-7/epoch-01-val-acc-0.3009.hdf5\n","Epoch 2/100\n","32/32 [==============================] - 1s 29ms/step - loss: 1.3609 - acc: 0.3366 - val_loss: 1.3614 - val_acc: 0.3009\n","\n","Epoch 00002: val_acc did not improve from 0.30088\n","Epoch 3/100\n","32/32 [==============================] - 1s 31ms/step - loss: 1.3519 - acc: 0.3083 - val_loss: 1.3589 - val_acc: 0.3009\n","\n","Epoch 00003: val_acc did not improve from 0.30088\n","Epoch 4/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.3584 - acc: 0.3347 - val_loss: 1.3660 - val_acc: 0.3009\n","\n","Epoch 00004: val_acc did not improve from 0.30088\n","Epoch 5/100\n","32/32 [==============================] - 1s 31ms/step - loss: 1.3526 - acc: 0.3312 - val_loss: 1.3550 - val_acc: 0.3009\n","\n","Epoch 00005: val_acc did not improve from 0.30088\n","Epoch 6/100\n","32/32 [==============================] - 1s 29ms/step - loss: 1.3348 - acc: 0.3587 - val_loss: 1.3578 - val_acc: 0.3009\n","\n","Epoch 00006: val_acc did not improve from 0.30088\n","Epoch 7/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.3451 - acc: 0.3329 - val_loss: 1.3442 - val_acc: 0.3097\n","\n","Epoch 00007: val_acc improved from 0.30088 to 0.30973, saving model to result/all2/dataset_2/OUR6-7/epoch-07-val-acc-0.3097.hdf5\n","Epoch 8/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.3461 - acc: 0.3505 - val_loss: 1.3597 - val_acc: 0.3009\n","\n","Epoch 00008: val_acc did not improve from 0.30973\n","Epoch 9/100\n","32/32 [==============================] - 1s 31ms/step - loss: 1.3461 - acc: 0.3399 - val_loss: 1.3324 - val_acc: 0.3097\n","\n","Epoch 00009: val_acc did not improve from 0.30973\n","Epoch 10/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.3296 - acc: 0.3846 - val_loss: 1.3240 - val_acc: 0.3717\n","\n","Epoch 00010: val_acc improved from 0.30973 to 0.37168, saving model to result/all2/dataset_2/OUR6-7/epoch-10-val-acc-0.3717.hdf5\n","Epoch 11/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.3389 - acc: 0.3669 - val_loss: 1.2976 - val_acc: 0.4248\n","\n","Epoch 00011: val_acc improved from 0.37168 to 0.42478, saving model to result/all2/dataset_2/OUR6-7/epoch-11-val-acc-0.4248.hdf5\n","Epoch 12/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.3115 - acc: 0.3858 - val_loss: 1.2714 - val_acc: 0.4425\n","\n","Epoch 00012: val_acc improved from 0.42478 to 0.44248, saving model to result/all2/dataset_2/OUR6-7/epoch-12-val-acc-0.4425.hdf5\n","Epoch 13/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.2794 - acc: 0.4310 - val_loss: 1.2589 - val_acc: 0.4071\n","\n","Epoch 00013: val_acc did not improve from 0.44248\n","Epoch 14/100\n","32/32 [==============================] - 1s 29ms/step - loss: 1.2639 - acc: 0.4222 - val_loss: 1.2219 - val_acc: 0.4956\n","\n","Epoch 00014: val_acc improved from 0.44248 to 0.49558, saving model to result/all2/dataset_2/OUR6-7/epoch-14-val-acc-0.4956.hdf5\n","Epoch 15/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.1970 - acc: 0.4873 - val_loss: 1.1804 - val_acc: 0.4425\n","\n","Epoch 00015: val_acc did not improve from 0.49558\n","Epoch 16/100\n","32/32 [==============================] - 1s 29ms/step - loss: 1.1518 - acc: 0.5377 - val_loss: 1.1165 - val_acc: 0.5752\n","\n","Epoch 00016: val_acc improved from 0.49558 to 0.57522, saving model to result/all2/dataset_2/OUR6-7/epoch-16-val-acc-0.5752.hdf5\n","Epoch 17/100\n","32/32 [==============================] - 1s 32ms/step - loss: 1.1440 - acc: 0.5276 - val_loss: 1.0640 - val_acc: 0.5487\n","\n","Epoch 00017: val_acc did not improve from 0.57522\n","Epoch 18/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.0735 - acc: 0.5611 - val_loss: 1.1056 - val_acc: 0.5221\n","\n","Epoch 00018: val_acc did not improve from 0.57522\n","Epoch 19/100\n","32/32 [==============================] - 1s 29ms/step - loss: 1.0975 - acc: 0.5259 - val_loss: 1.0405 - val_acc: 0.6018\n","\n","Epoch 00019: val_acc improved from 0.57522 to 0.60177, saving model to result/all2/dataset_2/OUR6-7/epoch-19-val-acc-0.6018.hdf5\n","Epoch 20/100\n","32/32 [==============================] - 1s 29ms/step - loss: 1.0392 - acc: 0.6030 - val_loss: 0.9872 - val_acc: 0.5752\n","\n","Epoch 00020: val_acc did not improve from 0.60177\n","Epoch 21/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.0247 - acc: 0.5699 - val_loss: 0.9608 - val_acc: 0.5841\n","\n","Epoch 00021: val_acc did not improve from 0.60177\n","Epoch 22/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.0174 - acc: 0.5898 - val_loss: 1.0502 - val_acc: 0.5398\n","\n","Epoch 00022: val_acc did not improve from 0.60177\n","Epoch 23/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.9432 - acc: 0.6211 - val_loss: 1.0276 - val_acc: 0.5398\n","\n","Epoch 00023: val_acc did not improve from 0.60177\n","Epoch 24/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.9565 - acc: 0.6113 - val_loss: 0.9492 - val_acc: 0.5487\n","\n","Epoch 00024: val_acc did not improve from 0.60177\n","Epoch 25/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.8909 - acc: 0.6522 - val_loss: 0.9707 - val_acc: 0.6106\n","\n","Epoch 00025: val_acc improved from 0.60177 to 0.61062, saving model to result/all2/dataset_2/OUR6-7/epoch-25-val-acc-0.6106.hdf5\n","Epoch 26/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.8857 - acc: 0.6349 - val_loss: 0.9300 - val_acc: 0.5664\n","\n","Epoch 00026: val_acc did not improve from 0.61062\n","Epoch 27/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.8970 - acc: 0.6608 - val_loss: 0.9389 - val_acc: 0.5752\n","\n","Epoch 00027: val_acc did not improve from 0.61062\n","Epoch 28/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.8224 - acc: 0.6825 - val_loss: 0.8813 - val_acc: 0.5929\n","\n","Epoch 00028: val_acc did not improve from 0.61062\n","Epoch 29/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.8411 - acc: 0.6455 - val_loss: 0.8639 - val_acc: 0.5841\n","\n","Epoch 00029: val_acc did not improve from 0.61062\n","Epoch 30/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.8611 - acc: 0.6458 - val_loss: 0.9079 - val_acc: 0.5841\n","\n","Epoch 00030: val_acc did not improve from 0.61062\n","Epoch 31/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.8291 - acc: 0.6634 - val_loss: 0.8768 - val_acc: 0.5664\n","\n","Epoch 00031: val_acc did not improve from 0.61062\n","Epoch 32/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.8306 - acc: 0.6528 - val_loss: 0.8429 - val_acc: 0.6195\n","\n","Epoch 00032: val_acc improved from 0.61062 to 0.61947, saving model to result/all2/dataset_2/OUR6-7/epoch-32-val-acc-0.6195.hdf5\n","Epoch 33/100\n","32/32 [==============================] - 1s 33ms/step - loss: 0.8335 - acc: 0.6567 - val_loss: 0.8853 - val_acc: 0.6283\n","\n","Epoch 00033: val_acc improved from 0.61947 to 0.62832, saving model to result/all2/dataset_2/OUR6-7/epoch-33-val-acc-0.6283.hdf5\n","Epoch 34/100\n","32/32 [==============================] - 1s 32ms/step - loss: 0.8240 - acc: 0.6644 - val_loss: 0.8397 - val_acc: 0.6195\n","\n","Epoch 00034: val_acc did not improve from 0.62832\n","Epoch 35/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.7486 - acc: 0.7187 - val_loss: 0.8252 - val_acc: 0.6018\n","\n","Epoch 00035: val_acc did not improve from 0.62832\n","Epoch 36/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.7311 - acc: 0.7067 - val_loss: 0.8168 - val_acc: 0.5929\n","\n","Epoch 00036: val_acc did not improve from 0.62832\n","Epoch 37/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.6987 - acc: 0.7343 - val_loss: 0.8206 - val_acc: 0.6018\n","\n","Epoch 00037: val_acc did not improve from 0.62832\n","Epoch 38/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.7115 - acc: 0.7231 - val_loss: 0.8022 - val_acc: 0.6106\n","\n","Epoch 00038: val_acc did not improve from 0.62832\n","Epoch 39/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6777 - acc: 0.7152 - val_loss: 0.8613 - val_acc: 0.6283\n","\n","Epoch 00039: val_acc improved from 0.62832 to 0.62832, saving model to result/all2/dataset_2/OUR6-7/epoch-39-val-acc-0.6283.hdf5\n","Epoch 40/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.7078 - acc: 0.7150 - val_loss: 0.7934 - val_acc: 0.6372\n","\n","Epoch 00040: val_acc improved from 0.62832 to 0.63717, saving model to result/all2/dataset_2/OUR6-7/epoch-40-val-acc-0.6372.hdf5\n","Epoch 41/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6611 - acc: 0.7437 - val_loss: 0.7919 - val_acc: 0.6106\n","\n","Epoch 00041: val_acc did not improve from 0.63717\n","Epoch 42/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6782 - acc: 0.7223 - val_loss: 0.7517 - val_acc: 0.6726\n","\n","Epoch 00042: val_acc improved from 0.63717 to 0.67257, saving model to result/all2/dataset_2/OUR6-7/epoch-42-val-acc-0.6726.hdf5\n","Epoch 43/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6469 - acc: 0.7439 - val_loss: 0.7533 - val_acc: 0.6814\n","\n","Epoch 00043: val_acc improved from 0.67257 to 0.68142, saving model to result/all2/dataset_2/OUR6-7/epoch-43-val-acc-0.6814.hdf5\n","Epoch 44/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6343 - acc: 0.7453 - val_loss: 0.7231 - val_acc: 0.6549\n","\n","Epoch 00044: val_acc did not improve from 0.68142\n","Epoch 45/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6280 - acc: 0.7383 - val_loss: 0.7384 - val_acc: 0.6283\n","\n","Epoch 00045: val_acc did not improve from 0.68142\n","Epoch 46/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6535 - acc: 0.7277 - val_loss: 0.7386 - val_acc: 0.6814\n","\n","Epoch 00046: val_acc did not improve from 0.68142\n","Epoch 47/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6465 - acc: 0.7463 - val_loss: 0.7405 - val_acc: 0.6814\n","\n","Epoch 00047: val_acc did not improve from 0.68142\n","Epoch 48/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6534 - acc: 0.7600 - val_loss: 0.7286 - val_acc: 0.6991\n","\n","Epoch 00048: val_acc improved from 0.68142 to 0.69912, saving model to result/all2/dataset_2/OUR6-7/epoch-48-val-acc-0.6991.hdf5\n","Epoch 49/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6098 - acc: 0.7416 - val_loss: 0.7443 - val_acc: 0.6637\n","\n","Epoch 00049: val_acc did not improve from 0.69912\n","Epoch 50/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.5663 - acc: 0.7752 - val_loss: 0.7499 - val_acc: 0.6726\n","\n","Epoch 00050: val_acc did not improve from 0.69912\n","Epoch 51/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.5844 - acc: 0.7615 - val_loss: 0.7140 - val_acc: 0.6726\n","\n","Epoch 00051: val_acc did not improve from 0.69912\n","Epoch 52/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.5448 - acc: 0.7987 - val_loss: 0.6958 - val_acc: 0.7168\n","\n","Epoch 00052: val_acc improved from 0.69912 to 0.71681, saving model to result/all2/dataset_2/OUR6-7/epoch-52-val-acc-0.7168.hdf5\n","Epoch 53/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.5481 - acc: 0.7759 - val_loss: 0.6963 - val_acc: 0.6903\n","\n","Epoch 00053: val_acc did not improve from 0.71681\n","Epoch 54/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6098 - acc: 0.7639 - val_loss: 0.7115 - val_acc: 0.7080\n","\n","Epoch 00054: val_acc did not improve from 0.71681\n","Epoch 55/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.5431 - acc: 0.8038 - val_loss: 0.6908 - val_acc: 0.6903\n","\n","Epoch 00055: val_acc did not improve from 0.71681\n","Epoch 56/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.5337 - acc: 0.7870 - val_loss: 0.6987 - val_acc: 0.7257\n","\n","Epoch 00056: val_acc improved from 0.71681 to 0.72566, saving model to result/all2/dataset_2/OUR6-7/epoch-56-val-acc-0.7257.hdf5\n","Epoch 57/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4651 - acc: 0.8268 - val_loss: 0.6731 - val_acc: 0.7080\n","\n","Epoch 00057: val_acc did not improve from 0.72566\n","Epoch 58/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.5170 - acc: 0.7911 - val_loss: 0.6579 - val_acc: 0.7168\n","\n","Epoch 00058: val_acc did not improve from 0.72566\n","Epoch 59/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.4876 - acc: 0.8251 - val_loss: 0.6762 - val_acc: 0.7345\n","\n","Epoch 00059: val_acc improved from 0.72566 to 0.73451, saving model to result/all2/dataset_2/OUR6-7/epoch-59-val-acc-0.7345.hdf5\n","Epoch 60/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.5142 - acc: 0.8035 - val_loss: 0.6876 - val_acc: 0.7080\n","\n","Epoch 00060: val_acc did not improve from 0.73451\n","Epoch 61/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4931 - acc: 0.8097 - val_loss: 0.6710 - val_acc: 0.7257\n","\n","Epoch 00061: val_acc did not improve from 0.73451\n","Epoch 62/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.5020 - acc: 0.8126 - val_loss: 0.6631 - val_acc: 0.7168\n","\n","Epoch 00062: val_acc did not improve from 0.73451\n","Epoch 63/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4515 - acc: 0.8317 - val_loss: 0.6631 - val_acc: 0.7434\n","\n","Epoch 00063: val_acc improved from 0.73451 to 0.74336, saving model to result/all2/dataset_2/OUR6-7/epoch-63-val-acc-0.7434.hdf5\n","Epoch 64/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.4368 - acc: 0.8259 - val_loss: 0.6572 - val_acc: 0.7611\n","\n","Epoch 00064: val_acc improved from 0.74336 to 0.76106, saving model to result/all2/dataset_2/OUR6-7/epoch-64-val-acc-0.7611.hdf5\n","Epoch 65/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4804 - acc: 0.8077 - val_loss: 0.6381 - val_acc: 0.7522\n","\n","Epoch 00065: val_acc did not improve from 0.76106\n","Epoch 66/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.4105 - acc: 0.8496 - val_loss: 0.6451 - val_acc: 0.7611\n","\n","Epoch 00066: val_acc improved from 0.76106 to 0.76106, saving model to result/all2/dataset_2/OUR6-7/epoch-66-val-acc-0.7611.hdf5\n","Epoch 67/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.4332 - acc: 0.8427 - val_loss: 0.6367 - val_acc: 0.7522\n","\n","Epoch 00067: val_acc did not improve from 0.76106\n","Epoch 68/100\n","32/32 [==============================] - 1s 32ms/step - loss: 0.4070 - acc: 0.8591 - val_loss: 0.6401 - val_acc: 0.7699\n","\n","Epoch 00068: val_acc improved from 0.76106 to 0.76991, saving model to result/all2/dataset_2/OUR6-7/epoch-68-val-acc-0.7699.hdf5\n","Epoch 69/100\n","32/32 [==============================] - 1s 33ms/step - loss: 0.4341 - acc: 0.8417 - val_loss: 0.6244 - val_acc: 0.7522\n","\n","Epoch 00069: val_acc did not improve from 0.76991\n","Epoch 70/100\n","32/32 [==============================] - 1s 32ms/step - loss: 0.4344 - acc: 0.8273 - val_loss: 0.6292 - val_acc: 0.7699\n","\n","Epoch 00070: val_acc improved from 0.76991 to 0.76991, saving model to result/all2/dataset_2/OUR6-7/epoch-70-val-acc-0.7699.hdf5\n","Epoch 71/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3640 - acc: 0.8660 - val_loss: 0.6327 - val_acc: 0.7788\n","\n","Epoch 00071: val_acc improved from 0.76991 to 0.77876, saving model to result/all2/dataset_2/OUR6-7/epoch-71-val-acc-0.7788.hdf5\n","Epoch 72/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.3984 - acc: 0.8535 - val_loss: 0.6710 - val_acc: 0.7257\n","\n","Epoch 00072: val_acc did not improve from 0.77876\n","Epoch 73/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4180 - acc: 0.8312 - val_loss: 0.6869 - val_acc: 0.7522\n","\n","Epoch 00073: val_acc did not improve from 0.77876\n","Epoch 74/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3963 - acc: 0.8457 - val_loss: 0.6630 - val_acc: 0.7699\n","\n","Epoch 00074: val_acc did not improve from 0.77876\n","Epoch 75/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3788 - acc: 0.8662 - val_loss: 0.6927 - val_acc: 0.7522\n","\n","Epoch 00075: val_acc did not improve from 0.77876\n","Epoch 76/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3632 - acc: 0.8582 - val_loss: 0.6705 - val_acc: 0.7611\n","\n","Epoch 00076: val_acc did not improve from 0.77876\n","Epoch 77/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.3734 - acc: 0.8729 - val_loss: 0.6692 - val_acc: 0.7257\n","\n","Epoch 00077: val_acc did not improve from 0.77876\n","Epoch 78/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3511 - acc: 0.8642 - val_loss: 0.6410 - val_acc: 0.7522\n","\n","Epoch 00078: val_acc did not improve from 0.77876\n","Epoch 79/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3416 - acc: 0.8787 - val_loss: 0.6481 - val_acc: 0.7699\n","\n","Epoch 00079: val_acc did not improve from 0.77876\n","Epoch 80/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3294 - acc: 0.8748 - val_loss: 0.6471 - val_acc: 0.7434\n","\n","Epoch 00080: val_acc did not improve from 0.77876\n","Epoch 81/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3873 - acc: 0.8471 - val_loss: 0.6615 - val_acc: 0.7611\n","\n","Epoch 00081: val_acc did not improve from 0.77876\n","Epoch 82/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3754 - acc: 0.8605 - val_loss: 0.7571 - val_acc: 0.7345\n","\n","Epoch 00082: val_acc did not improve from 0.77876\n","Epoch 83/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3323 - acc: 0.8630 - val_loss: 0.6544 - val_acc: 0.7699\n","\n","Epoch 00083: val_acc did not improve from 0.77876\n","Epoch 84/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.4153 - acc: 0.8510 - val_loss: 0.7745 - val_acc: 0.7345\n","\n","Epoch 00084: val_acc did not improve from 0.77876\n","Epoch 85/100\n","32/32 [==============================] - 1s 32ms/step - loss: 0.3440 - acc: 0.8807 - val_loss: 0.7175 - val_acc: 0.7611\n","\n","Epoch 00085: val_acc did not improve from 0.77876\n","Epoch 86/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.3199 - acc: 0.8759 - val_loss: 0.6890 - val_acc: 0.7434\n","\n","Epoch 00086: val_acc did not improve from 0.77876\n","Epoch 87/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2975 - acc: 0.8963 - val_loss: 0.6773 - val_acc: 0.7611\n","\n","Epoch 00087: val_acc did not improve from 0.77876\n","Epoch 88/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3562 - acc: 0.8693 - val_loss: 0.6459 - val_acc: 0.7611\n","\n","Epoch 00088: val_acc did not improve from 0.77876\n","Epoch 89/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.3013 - acc: 0.8807 - val_loss: 0.6494 - val_acc: 0.7522\n","\n","Epoch 00089: val_acc did not improve from 0.77876\n","Epoch 90/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3042 - acc: 0.8904 - val_loss: 0.6785 - val_acc: 0.7611\n","\n","Epoch 00090: val_acc did not improve from 0.77876\n","Epoch 91/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.3484 - acc: 0.8691 - val_loss: 0.6770 - val_acc: 0.7434\n","\n","Epoch 00091: val_acc did not improve from 0.77876\n","Epoch 92/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.3106 - acc: 0.8733 - val_loss: 0.6733 - val_acc: 0.7699\n","\n","Epoch 00092: val_acc did not improve from 0.77876\n","Epoch 93/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2853 - acc: 0.8946 - val_loss: 0.6731 - val_acc: 0.7434\n","\n","Epoch 00093: val_acc did not improve from 0.77876\n","Epoch 94/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.2794 - acc: 0.8984 - val_loss: 0.6890 - val_acc: 0.7434\n","\n","Epoch 00094: val_acc did not improve from 0.77876\n","Epoch 95/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2870 - acc: 0.8877 - val_loss: 0.6656 - val_acc: 0.7434\n","\n","Epoch 00095: val_acc did not improve from 0.77876\n","Epoch 96/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2440 - acc: 0.9159 - val_loss: 0.7179 - val_acc: 0.7168\n","\n","Epoch 00096: val_acc did not improve from 0.77876\n","Epoch 97/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2477 - acc: 0.9247 - val_loss: 0.7021 - val_acc: 0.7434\n","\n","Epoch 00097: val_acc did not improve from 0.77876\n","Epoch 98/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3012 - acc: 0.9004 - val_loss: 0.7491 - val_acc: 0.7699\n","\n","Epoch 00098: val_acc did not improve from 0.77876\n","Epoch 99/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.2502 - acc: 0.9063 - val_loss: 0.7352 - val_acc: 0.7434\n","\n","Epoch 00099: val_acc did not improve from 0.77876\n","Epoch 100/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.2488 - acc: 0.9061 - val_loss: 0.7532 - val_acc: 0.7434\n","\n","Epoch 00100: val_acc did not improve from 0.77876\n","\n","<keras.callbacks.History at 0x7f2aa97f4e10>\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cpbkRfSPg-qk","colab_type":"code","colab":{}},"cell_type":"code","source":["All dataset 1 OUR 6-3 84.21 new\n","\n","\n","\n","Epoch 1/100\n","32/32 [==============================] - 1s 46ms/step - loss: 1.3774 - acc: 0.2936 - val_loss: 1.3634 - val_acc: 0.3026\n","\n","Epoch 00001: val_acc improved from -inf to 0.30263, saving model to result/all2/dataset_1/OUR6-3/epoch-01-val-acc-0.3026.hdf5\n","Epoch 2/100\n","32/32 [==============================] - 1s 32ms/step - loss: 1.3715 - acc: 0.2781 - val_loss: 1.3612 - val_acc: 0.3026\n","\n","Epoch 00002: val_acc did not improve from 0.30263\n","Epoch 3/100\n","32/32 [==============================] - 1s 29ms/step - loss: 1.3610 - acc: 0.2960 - val_loss: 1.3585 - val_acc: 0.3026\n","\n","Epoch 00003: val_acc did not improve from 0.30263\n","Epoch 4/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.3567 - acc: 0.3204 - val_loss: 1.3605 - val_acc: 0.3026\n","\n","Epoch 00004: val_acc did not improve from 0.30263\n","Epoch 5/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.3587 - acc: 0.3387 - val_loss: 1.3582 - val_acc: 0.3026\n","\n","Epoch 00005: val_acc did not improve from 0.30263\n","Epoch 6/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.3643 - acc: 0.3083 - val_loss: 1.3553 - val_acc: 0.3026\n","\n","Epoch 00006: val_acc did not improve from 0.30263\n","Epoch 7/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.3562 - acc: 0.3295 - val_loss: 1.3534 - val_acc: 0.3026\n","\n","Epoch 00007: val_acc did not improve from 0.30263\n","Epoch 8/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.3561 - acc: 0.3265 - val_loss: 1.3515 - val_acc: 0.3026\n","\n","Epoch 00008: val_acc did not improve from 0.30263\n","Epoch 9/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.3393 - acc: 0.3457 - val_loss: 1.3322 - val_acc: 0.3026\n","\n","Epoch 00009: val_acc did not improve from 0.30263\n","Epoch 10/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.3512 - acc: 0.3311 - val_loss: 1.3437 - val_acc: 0.3026\n","\n","Epoch 00010: val_acc did not improve from 0.30263\n","Epoch 11/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.3161 - acc: 0.3801 - val_loss: 1.2809 - val_acc: 0.4079\n","\n","Epoch 00011: val_acc improved from 0.30263 to 0.40789, saving model to result/all2/dataset_1/OUR6-3/epoch-11-val-acc-0.4079.hdf5\n","Epoch 12/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.2766 - acc: 0.4284 - val_loss: 1.2113 - val_acc: 0.4079\n","\n","Epoch 00012: val_acc did not improve from 0.40789\n","Epoch 13/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.3115 - acc: 0.3661 - val_loss: 1.3518 - val_acc: 0.3026\n","\n","Epoch 00013: val_acc did not improve from 0.40789\n","Epoch 14/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.2700 - acc: 0.4237 - val_loss: 1.2067 - val_acc: 0.4605\n","\n","Epoch 00014: val_acc improved from 0.40789 to 0.46053, saving model to result/all2/dataset_1/OUR6-3/epoch-14-val-acc-0.4605.hdf5\n","Epoch 15/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.2121 - acc: 0.4666 - val_loss: 1.1522 - val_acc: 0.4211\n","\n","Epoch 00015: val_acc did not improve from 0.46053\n","Epoch 16/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.1996 - acc: 0.4668 - val_loss: 1.1546 - val_acc: 0.4474\n","\n","Epoch 00016: val_acc did not improve from 0.46053\n","Epoch 17/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.1355 - acc: 0.5173 - val_loss: 1.2357 - val_acc: 0.5000\n","\n","Epoch 00017: val_acc improved from 0.46053 to 0.50000, saving model to result/all2/dataset_1/OUR6-3/epoch-17-val-acc-0.5000.hdf5\n","Epoch 18/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.1286 - acc: 0.5221 - val_loss: 1.0794 - val_acc: 0.5000\n","\n","Epoch 00018: val_acc improved from 0.50000 to 0.50000, saving model to result/all2/dataset_1/OUR6-3/epoch-18-val-acc-0.5000.hdf5\n","Epoch 19/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.0999 - acc: 0.5205 - val_loss: 1.0744 - val_acc: 0.4605\n","\n","Epoch 00019: val_acc did not improve from 0.50000\n","Epoch 20/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.0644 - acc: 0.5430 - val_loss: 1.0295 - val_acc: 0.5000\n","\n","Epoch 00020: val_acc did not improve from 0.50000\n","Epoch 21/100\n","32/32 [==============================] - 1s 30ms/step - loss: 1.0234 - acc: 0.5766 - val_loss: 0.9885 - val_acc: 0.5395\n","\n","Epoch 00021: val_acc improved from 0.50000 to 0.53947, saving model to result/all2/dataset_1/OUR6-3/epoch-21-val-acc-0.5395.hdf5\n","Epoch 22/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.9793 - acc: 0.5970 - val_loss: 0.9639 - val_acc: 0.5526\n","\n","Epoch 00022: val_acc improved from 0.53947 to 0.55263, saving model to result/all2/dataset_1/OUR6-3/epoch-22-val-acc-0.5526.hdf5\n","Epoch 23/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.9705 - acc: 0.5870 - val_loss: 0.9106 - val_acc: 0.5526\n","\n","Epoch 00023: val_acc improved from 0.55263 to 0.55263, saving model to result/all2/dataset_1/OUR6-3/epoch-23-val-acc-0.5526.hdf5\n","Epoch 24/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.9554 - acc: 0.5923 - val_loss: 0.9026 - val_acc: 0.6316\n","\n","Epoch 00024: val_acc improved from 0.55263 to 0.63158, saving model to result/all2/dataset_1/OUR6-3/epoch-24-val-acc-0.6316.hdf5\n","Epoch 25/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.8943 - acc: 0.6373 - val_loss: 0.8854 - val_acc: 0.5263\n","\n","Epoch 00025: val_acc did not improve from 0.63158\n","Epoch 26/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.8883 - acc: 0.6445 - val_loss: 0.8664 - val_acc: 0.5921\n","\n","Epoch 00026: val_acc did not improve from 0.63158\n","Epoch 27/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.8414 - acc: 0.6514 - val_loss: 0.7672 - val_acc: 0.6711\n","\n","Epoch 00027: val_acc improved from 0.63158 to 0.67105, saving model to result/all2/dataset_1/OUR6-3/epoch-27-val-acc-0.6711.hdf5\n","Epoch 28/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.8398 - acc: 0.6794 - val_loss: 0.7724 - val_acc: 0.6711\n","\n","Epoch 00028: val_acc did not improve from 0.67105\n","Epoch 29/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.8062 - acc: 0.6794 - val_loss: 0.7502 - val_acc: 0.6579\n","\n","Epoch 00029: val_acc did not improve from 0.67105\n","Epoch 30/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.7687 - acc: 0.6882 - val_loss: 0.7147 - val_acc: 0.6974\n","\n","Epoch 00030: val_acc improved from 0.67105 to 0.69737, saving model to result/all2/dataset_1/OUR6-3/epoch-30-val-acc-0.6974.hdf5\n","Epoch 31/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.7846 - acc: 0.6864 - val_loss: 0.8778 - val_acc: 0.6447\n","\n","Epoch 00031: val_acc did not improve from 0.69737\n","Epoch 32/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.7850 - acc: 0.6808 - val_loss: 0.6840 - val_acc: 0.7105\n","\n","Epoch 00032: val_acc improved from 0.69737 to 0.71053, saving model to result/all2/dataset_1/OUR6-3/epoch-32-val-acc-0.7105.hdf5\n","Epoch 33/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.7338 - acc: 0.7005 - val_loss: 0.6897 - val_acc: 0.6711\n","\n","Epoch 00033: val_acc did not improve from 0.71053\n","Epoch 34/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.7497 - acc: 0.6919 - val_loss: 0.6638 - val_acc: 0.6842\n","\n","Epoch 00034: val_acc did not improve from 0.71053\n","Epoch 35/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.7086 - acc: 0.7193 - val_loss: 0.6547 - val_acc: 0.6842\n","\n","Epoch 00035: val_acc did not improve from 0.71053\n","Epoch 36/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.7137 - acc: 0.7177 - val_loss: 0.6483 - val_acc: 0.7500\n","\n","Epoch 00036: val_acc improved from 0.71053 to 0.75000, saving model to result/all2/dataset_1/OUR6-3/epoch-36-val-acc-0.7500.hdf5\n","Epoch 37/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6916 - acc: 0.7232 - val_loss: 0.6523 - val_acc: 0.6974\n","\n","Epoch 00037: val_acc did not improve from 0.75000\n","Epoch 38/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6699 - acc: 0.7361 - val_loss: 0.6422 - val_acc: 0.7763\n","\n","Epoch 00038: val_acc improved from 0.75000 to 0.77632, saving model to result/all2/dataset_1/OUR6-3/epoch-38-val-acc-0.7763.hdf5\n","Epoch 39/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6765 - acc: 0.7396 - val_loss: 0.6805 - val_acc: 0.7763\n","\n","Epoch 00039: val_acc did not improve from 0.77632\n","Epoch 40/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6303 - acc: 0.7469 - val_loss: 0.6164 - val_acc: 0.7368\n","\n","Epoch 00040: val_acc did not improve from 0.77632\n","Epoch 41/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.6222 - acc: 0.7430 - val_loss: 0.5812 - val_acc: 0.7500\n","\n","Epoch 00041: val_acc did not improve from 0.77632\n","Epoch 42/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6112 - acc: 0.7457 - val_loss: 0.5713 - val_acc: 0.7632\n","\n","Epoch 00042: val_acc did not improve from 0.77632\n","Epoch 43/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6178 - acc: 0.7523 - val_loss: 0.5740 - val_acc: 0.7632\n","\n","Epoch 00043: val_acc did not improve from 0.77632\n","Epoch 44/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.5972 - acc: 0.7729 - val_loss: 0.5731 - val_acc: 0.7500\n","\n","Epoch 00044: val_acc did not improve from 0.77632\n","Epoch 45/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6004 - acc: 0.7631 - val_loss: 0.5857 - val_acc: 0.7632\n","\n","Epoch 00045: val_acc did not improve from 0.77632\n","Epoch 46/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6014 - acc: 0.7656 - val_loss: 0.5558 - val_acc: 0.7763\n","\n","Epoch 00046: val_acc did not improve from 0.77632\n","Epoch 47/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.5286 - acc: 0.7978 - val_loss: 0.5387 - val_acc: 0.7895\n","\n","Epoch 00047: val_acc improved from 0.77632 to 0.78947, saving model to result/all2/dataset_1/OUR6-3/epoch-47-val-acc-0.7895.hdf5\n","Epoch 48/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.5506 - acc: 0.7844 - val_loss: 0.5381 - val_acc: 0.7895\n","\n","Epoch 00048: val_acc did not improve from 0.78947\n","Epoch 49/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.5835 - acc: 0.7678 - val_loss: 0.6625 - val_acc: 0.7500\n","\n","Epoch 00049: val_acc did not improve from 0.78947\n","Epoch 50/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.5567 - acc: 0.7574 - val_loss: 0.5303 - val_acc: 0.8026\n","\n","Epoch 00050: val_acc improved from 0.78947 to 0.80263, saving model to result/all2/dataset_1/OUR6-3/epoch-50-val-acc-0.8026.hdf5\n","Epoch 51/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.5379 - acc: 0.7907 - val_loss: 0.5277 - val_acc: 0.8158\n","\n","Epoch 00051: val_acc improved from 0.80263 to 0.81579, saving model to result/all2/dataset_1/OUR6-3/epoch-51-val-acc-0.8158.hdf5\n","Epoch 52/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.4926 - acc: 0.8058 - val_loss: 0.6534 - val_acc: 0.7500\n","\n","Epoch 00052: val_acc did not improve from 0.81579\n","Epoch 53/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.5347 - acc: 0.7905 - val_loss: 0.5973 - val_acc: 0.7632\n","\n","Epoch 00053: val_acc did not improve from 0.81579\n","Epoch 54/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4986 - acc: 0.8098 - val_loss: 0.5288 - val_acc: 0.8026\n","\n","Epoch 00054: val_acc did not improve from 0.81579\n","Epoch 55/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.5177 - acc: 0.8148 - val_loss: 0.5612 - val_acc: 0.7763\n","\n","Epoch 00055: val_acc did not improve from 0.81579\n","Epoch 56/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4714 - acc: 0.8234 - val_loss: 0.5140 - val_acc: 0.8026\n","\n","Epoch 00056: val_acc did not improve from 0.81579\n","Epoch 57/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4368 - acc: 0.8294 - val_loss: 0.5383 - val_acc: 0.7895\n","\n","Epoch 00057: val_acc did not improve from 0.81579\n","Epoch 58/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4718 - acc: 0.8210 - val_loss: 0.5037 - val_acc: 0.8158\n","\n","Epoch 00058: val_acc did not improve from 0.81579\n","Epoch 59/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4428 - acc: 0.8181 - val_loss: 0.5177 - val_acc: 0.8158\n","\n","Epoch 00059: val_acc did not improve from 0.81579\n","Epoch 60/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4402 - acc: 0.8326 - val_loss: 0.5494 - val_acc: 0.7763\n","\n","Epoch 00060: val_acc did not improve from 0.81579\n","Epoch 61/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4396 - acc: 0.8346 - val_loss: 0.5244 - val_acc: 0.8026\n","\n","Epoch 00061: val_acc did not improve from 0.81579\n","Epoch 62/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4352 - acc: 0.8384 - val_loss: 0.4949 - val_acc: 0.8289\n","\n","Epoch 00062: val_acc improved from 0.81579 to 0.82895, saving model to result/all2/dataset_1/OUR6-3/epoch-62-val-acc-0.8289.hdf5\n","Epoch 63/100\n","32/32 [==============================] - 1s 32ms/step - loss: 0.4173 - acc: 0.8304 - val_loss: 0.5131 - val_acc: 0.8158\n","\n","Epoch 00063: val_acc did not improve from 0.82895\n","Epoch 64/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3896 - acc: 0.8493 - val_loss: 0.4935 - val_acc: 0.8289\n","\n","Epoch 00064: val_acc did not improve from 0.82895\n","Epoch 65/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4278 - acc: 0.8390 - val_loss: 0.5784 - val_acc: 0.7763\n","\n","Epoch 00065: val_acc did not improve from 0.82895\n","Epoch 66/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4444 - acc: 0.8255 - val_loss: 0.5445 - val_acc: 0.7763\n","\n","Epoch 00066: val_acc did not improve from 0.82895\n","Epoch 67/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3961 - acc: 0.8579 - val_loss: 0.5084 - val_acc: 0.7763\n","\n","Epoch 00067: val_acc did not improve from 0.82895\n","Epoch 68/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3804 - acc: 0.8433 - val_loss: 0.5365 - val_acc: 0.8158\n","\n","Epoch 00068: val_acc did not improve from 0.82895\n","Epoch 69/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3751 - acc: 0.8496 - val_loss: 0.5361 - val_acc: 0.8289\n","\n","Epoch 00069: val_acc did not improve from 0.82895\n","Epoch 70/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4161 - acc: 0.8313 - val_loss: 0.5050 - val_acc: 0.8289\n","\n","Epoch 00070: val_acc did not improve from 0.82895\n","Epoch 71/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3792 - acc: 0.8609 - val_loss: 0.5245 - val_acc: 0.8289\n","\n","Epoch 00071: val_acc did not improve from 0.82895\n","Epoch 72/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3703 - acc: 0.8629 - val_loss: 0.5377 - val_acc: 0.7895\n","\n","Epoch 00072: val_acc did not improve from 0.82895\n","Epoch 73/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3504 - acc: 0.8681 - val_loss: 0.5257 - val_acc: 0.8289\n","\n","Epoch 00073: val_acc did not improve from 0.82895\n","Epoch 74/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3515 - acc: 0.8576 - val_loss: 0.5520 - val_acc: 0.8158\n","\n","Epoch 00074: val_acc did not improve from 0.82895\n","Epoch 75/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3341 - acc: 0.8840 - val_loss: 0.6108 - val_acc: 0.7632\n","\n","Epoch 00075: val_acc did not improve from 0.82895\n","Epoch 76/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3305 - acc: 0.8715 - val_loss: 0.5087 - val_acc: 0.8421\n","\n","Epoch 00076: val_acc improved from 0.82895 to 0.84211, saving model to result/all2/dataset_1/OUR6-3/epoch-76-val-acc-0.8421.hdf5\n","Epoch 77/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3542 - acc: 0.8739 - val_loss: 0.5328 - val_acc: 0.7763\n","\n","Epoch 00077: val_acc did not improve from 0.84211\n","Epoch 78/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.3000 - acc: 0.8969 - val_loss: 0.5022 - val_acc: 0.8421\n","\n","Epoch 00078: val_acc improved from 0.84211 to 0.84211, saving model to result/all2/dataset_1/OUR6-3/epoch-78-val-acc-0.8421.hdf5\n","Epoch 79/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3160 - acc: 0.8820 - val_loss: 0.5950 - val_acc: 0.7500\n","\n","Epoch 00079: val_acc did not improve from 0.84211\n","Epoch 80/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3094 - acc: 0.8769 - val_loss: 0.5422 - val_acc: 0.8421\n","\n","Epoch 00080: val_acc did not improve from 0.84211\n","Epoch 81/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3206 - acc: 0.8724 - val_loss: 0.5569 - val_acc: 0.7895\n","\n","Epoch 00081: val_acc did not improve from 0.84211\n","Epoch 82/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.3024 - acc: 0.8906 - val_loss: 0.5383 - val_acc: 0.8158\n","\n","Epoch 00082: val_acc did not improve from 0.84211\n","Epoch 83/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2928 - acc: 0.8837 - val_loss: 0.5642 - val_acc: 0.8026\n","\n","Epoch 00083: val_acc did not improve from 0.84211\n","Epoch 84/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2705 - acc: 0.8969 - val_loss: 0.5619 - val_acc: 0.8158\n","\n","Epoch 00084: val_acc did not improve from 0.84211\n","Epoch 85/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2942 - acc: 0.8954 - val_loss: 0.5991 - val_acc: 0.8026\n","\n","Epoch 00085: val_acc did not improve from 0.84211\n","Epoch 86/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2703 - acc: 0.8991 - val_loss: 0.5652 - val_acc: 0.8289\n","\n","Epoch 00086: val_acc did not improve from 0.84211\n","Epoch 87/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2785 - acc: 0.8977 - val_loss: 0.6485 - val_acc: 0.7895\n","\n","Epoch 00087: val_acc did not improve from 0.84211\n","Epoch 88/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2871 - acc: 0.8818 - val_loss: 0.5951 - val_acc: 0.8026\n","\n","Epoch 00088: val_acc did not improve from 0.84211\n","Epoch 89/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2831 - acc: 0.8939 - val_loss: 0.6099 - val_acc: 0.7632\n","\n","Epoch 00089: val_acc did not improve from 0.84211\n","Epoch 90/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2966 - acc: 0.8787 - val_loss: 0.6124 - val_acc: 0.7632\n","\n","Epoch 00090: val_acc did not improve from 0.84211\n","Epoch 91/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.2596 - acc: 0.9018 - val_loss: 0.6246 - val_acc: 0.7763\n","\n","Epoch 00091: val_acc did not improve from 0.84211\n","Epoch 92/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2255 - acc: 0.9124 - val_loss: 0.5449 - val_acc: 0.8026\n","\n","Epoch 00092: val_acc did not improve from 0.84211\n","Epoch 93/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2529 - acc: 0.9049 - val_loss: 0.5699 - val_acc: 0.8026\n","\n","Epoch 00093: val_acc did not improve from 0.84211\n","Epoch 94/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2408 - acc: 0.9102 - val_loss: 0.5748 - val_acc: 0.8158\n","\n","Epoch 00094: val_acc did not improve from 0.84211\n","Epoch 95/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2311 - acc: 0.9182 - val_loss: 0.6293 - val_acc: 0.7763\n","\n","Epoch 00095: val_acc did not improve from 0.84211\n","Epoch 96/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2272 - acc: 0.9157 - val_loss: 0.5804 - val_acc: 0.7763\n","\n","Epoch 00096: val_acc did not improve from 0.84211\n","Epoch 97/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2219 - acc: 0.9290 - val_loss: 0.5623 - val_acc: 0.8158\n","\n","Epoch 00097: val_acc did not improve from 0.84211\n","Epoch 98/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2571 - acc: 0.9000 - val_loss: 0.5999 - val_acc: 0.7895\n","\n","Epoch 00098: val_acc did not improve from 0.84211\n","Epoch 99/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2360 - acc: 0.9062 - val_loss: 0.6013 - val_acc: 0.7763\n","\n","Epoch 00099: val_acc did not improve from 0.84211\n","Epoch 100/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2248 - acc: 0.9192 - val_loss: 0.6197 - val_acc: 0.7895\n","\n","Epoch 00100: val_acc did not improve from 0.84211\n","\n","<keras.callbacks.History at 0x7f71d11d9e48>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"N3yosxlv8AjM","colab_type":"code","colab":{}},"cell_type":"code","source":["intersection eski\n","\n","\n","\n","Epoch 1/100\n","32/32 [==============================] - 3s 86ms/step - loss: 0.6635 - acc: 0.6256 - val_loss: 0.6866 - val_acc: 0.6000\n","\n","Epoch 00001: val_acc improved from -inf to 0.60000, saving model to result/intersection/data_80_10_10/OUR6-376/epoch-01-val-acc-0.6000.hdf5\n","Epoch 2/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.6400 - acc: 0.6650 - val_loss: 0.6920 - val_acc: 0.6000\n","\n","Epoch 00002: val_acc did not improve from 0.60000\n","Epoch 3/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.6265 - acc: 0.6677 - val_loss: 0.6873 - val_acc: 0.6000\n","\n","Epoch 00003: val_acc did not improve from 0.60000\n","Epoch 4/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.6225 - acc: 0.6790 - val_loss: 0.6910 - val_acc: 0.6000\n","\n","Epoch 00004: val_acc did not improve from 0.60000\n","Epoch 5/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.6274 - acc: 0.6680 - val_loss: 0.6974 - val_acc: 0.6000\n","\n","Epoch 00005: val_acc did not improve from 0.60000\n","Epoch 6/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.6091 - acc: 0.6618 - val_loss: 0.6537 - val_acc: 0.6000\n","\n","Epoch 00006: val_acc did not improve from 0.60000\n","Epoch 7/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.5776 - acc: 0.7066 - val_loss: 0.6315 - val_acc: 0.6000\n","\n","Epoch 00007: val_acc did not improve from 0.60000\n","Epoch 8/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.5265 - acc: 0.7451 - val_loss: 0.5747 - val_acc: 0.7667\n","\n","Epoch 00008: val_acc improved from 0.60000 to 0.76667, saving model to result/intersection/data_80_10_10/OUR6-376/epoch-08-val-acc-0.7667.hdf5\n","Epoch 9/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.4711 - acc: 0.7874 - val_loss: 0.5292 - val_acc: 0.6667\n","\n","Epoch 00009: val_acc did not improve from 0.76667\n","Epoch 10/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.3903 - acc: 0.8171 - val_loss: 0.4857 - val_acc: 0.7333\n","\n","Epoch 00010: val_acc did not improve from 0.76667\n","Epoch 11/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.3361 - acc: 0.8507 - val_loss: 0.5407 - val_acc: 0.7000\n","\n","Epoch 00011: val_acc did not improve from 0.76667\n","Epoch 12/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.3005 - acc: 0.8716 - val_loss: 0.4628 - val_acc: 0.8000\n","\n","Epoch 00012: val_acc improved from 0.76667 to 0.80000, saving model to result/intersection/data_80_10_10/OUR6-376/epoch-12-val-acc-0.8000.hdf5\n","Epoch 13/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.2487 - acc: 0.8903 - val_loss: 0.5512 - val_acc: 0.7667\n","\n","Epoch 00013: val_acc did not improve from 0.80000\n","Epoch 14/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.2424 - acc: 0.9022 - val_loss: 0.5176 - val_acc: 0.7667\n","\n","Epoch 00014: val_acc did not improve from 0.80000\n","Epoch 15/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.2271 - acc: 0.9024 - val_loss: 0.5360 - val_acc: 0.7667\n","\n","Epoch 00015: val_acc did not improve from 0.80000\n","Epoch 16/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1749 - acc: 0.9417 - val_loss: 0.4955 - val_acc: 0.8333\n","\n","Epoch 00016: val_acc improved from 0.80000 to 0.83333, saving model to result/intersection/data_80_10_10/OUR6-376/epoch-16-val-acc-0.8333.hdf5\n","Epoch 17/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.1672 - acc: 0.9283 - val_loss: 0.5962 - val_acc: 0.7333\n","\n","Epoch 00017: val_acc did not improve from 0.83333\n","Epoch 18/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1473 - acc: 0.9455 - val_loss: 0.5441 - val_acc: 0.8000\n","\n","Epoch 00018: val_acc did not improve from 0.83333\n","Epoch 19/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1511 - acc: 0.9374 - val_loss: 0.4544 - val_acc: 0.7667\n","\n","Epoch 00019: val_acc did not improve from 0.83333\n","Epoch 20/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1208 - acc: 0.9572 - val_loss: 0.5432 - val_acc: 0.7667\n","\n","Epoch 00020: val_acc did not improve from 0.83333\n","Epoch 21/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.1138 - acc: 0.9620 - val_loss: 0.5490 - val_acc: 0.7667\n","\n","Epoch 00021: val_acc did not improve from 0.83333\n","Epoch 22/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1053 - acc: 0.9631 - val_loss: 0.5110 - val_acc: 0.8333\n","\n","Epoch 00022: val_acc did not improve from 0.83333\n","Epoch 23/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0909 - acc: 0.9623 - val_loss: 0.4980 - val_acc: 0.8667\n","\n","Epoch 00023: val_acc improved from 0.83333 to 0.86667, saving model to result/intersection/data_80_10_10/OUR6-376/epoch-23-val-acc-0.8667.hdf5\n","Epoch 24/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0819 - acc: 0.9669 - val_loss: 0.5098 - val_acc: 0.8667\n","\n","Epoch 00024: val_acc did not improve from 0.86667\n","Epoch 25/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0731 - acc: 0.9698 - val_loss: 0.4763 - val_acc: 0.8667\n","\n","Epoch 00025: val_acc did not improve from 0.86667\n","Epoch 26/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0610 - acc: 0.9843 - val_loss: 0.5385 - val_acc: 0.8667\n","\n","Epoch 00026: val_acc did not improve from 0.86667\n","Epoch 27/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0538 - acc: 0.9814 - val_loss: 0.5481 - val_acc: 0.8000\n","\n","Epoch 00027: val_acc did not improve from 0.86667\n","Epoch 28/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0461 - acc: 0.9884 - val_loss: 0.6161 - val_acc: 0.8667\n","\n","Epoch 00028: val_acc did not improve from 0.86667\n","Epoch 29/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0434 - acc: 0.9853 - val_loss: 0.5991 - val_acc: 0.8333\n","\n","Epoch 00029: val_acc did not improve from 0.86667\n","Epoch 30/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0528 - acc: 0.9824 - val_loss: 0.5445 - val_acc: 0.8667\n","\n","Epoch 00030: val_acc did not improve from 0.86667\n","Epoch 31/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0416 - acc: 0.9853 - val_loss: 0.6255 - val_acc: 0.8667\n","\n","Epoch 00031: val_acc did not improve from 0.86667\n","Epoch 32/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0574 - acc: 0.9758 - val_loss: 0.5086 - val_acc: 0.9000\n","\n","Epoch 00032: val_acc improved from 0.86667 to 0.90000, saving model to result/intersection/data_80_10_10/OUR6-376/epoch-32-val-acc-0.9000.hdf5\n","Epoch 33/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0414 - acc: 0.9884 - val_loss: 0.5816 - val_acc: 0.8667\n","\n","Epoch 00033: val_acc did not improve from 0.90000\n","Epoch 34/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0367 - acc: 0.9892 - val_loss: 0.6822 - val_acc: 0.8667\n","\n","Epoch 00034: val_acc did not improve from 0.90000\n","Epoch 35/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0288 - acc: 0.9912 - val_loss: 0.7465 - val_acc: 0.8667\n","\n","Epoch 00035: val_acc did not improve from 0.90000\n","Epoch 36/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0248 - acc: 0.9941 - val_loss: 0.7223 - val_acc: 0.8667\n","\n","Epoch 00036: val_acc did not improve from 0.90000\n","Epoch 37/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0315 - acc: 0.9882 - val_loss: 0.6842 - val_acc: 0.8667\n","\n","Epoch 00037: val_acc did not improve from 0.90000\n","Epoch 38/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0296 - acc: 0.9884 - val_loss: 0.6374 - val_acc: 0.8667\n","\n","Epoch 00038: val_acc did not improve from 0.90000\n","Epoch 39/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0244 - acc: 0.9923 - val_loss: 0.6944 - val_acc: 0.8667\n","\n","Epoch 00039: val_acc did not improve from 0.90000\n","Epoch 40/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0256 - acc: 0.9912 - val_loss: 0.8379 - val_acc: 0.8667\n","\n","Epoch 00040: val_acc did not improve from 0.90000\n","Epoch 41/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0218 - acc: 0.9961 - val_loss: 0.8784 - val_acc: 0.8667\n","\n","Epoch 00041: val_acc did not improve from 0.90000\n","Epoch 42/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0251 - acc: 0.9941 - val_loss: 0.7656 - val_acc: 0.8667\n","\n","Epoch 00042: val_acc did not improve from 0.90000\n","Epoch 43/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0272 - acc: 0.9904 - val_loss: 0.7151 - val_acc: 0.8667\n","\n","Epoch 00043: val_acc did not improve from 0.90000\n","Epoch 44/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0256 - acc: 0.9941 - val_loss: 0.8647 - val_acc: 0.8667\n","\n","Epoch 00044: val_acc did not improve from 0.90000\n","Epoch 45/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0323 - acc: 0.9866 - val_loss: 0.9662 - val_acc: 0.7667\n","\n","Epoch 00045: val_acc did not improve from 0.90000\n","Epoch 46/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0216 - acc: 0.9922 - val_loss: 0.7700 - val_acc: 0.8667\n","\n","Epoch 00046: val_acc did not improve from 0.90000\n","Epoch 47/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0129 - acc: 0.9961 - val_loss: 0.8566 - val_acc: 0.8667\n","\n","Epoch 00047: val_acc did not improve from 0.90000\n","Epoch 48/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0129 - acc: 0.9951 - val_loss: 0.9003 - val_acc: 0.8667\n","\n","Epoch 00048: val_acc did not improve from 0.90000\n","Epoch 49/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0112 - acc: 0.9971 - val_loss: 0.8696 - val_acc: 0.8667\n","\n","Epoch 00049: val_acc did not improve from 0.90000\n","Epoch 50/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0268 - acc: 0.9895 - val_loss: 0.8811 - val_acc: 0.8667\n","\n","Epoch 00050: val_acc did not improve from 0.90000\n","Epoch 51/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0188 - acc: 0.9951 - val_loss: 0.8382 - val_acc: 0.8667\n","\n","Epoch 00051: val_acc did not improve from 0.90000\n","Epoch 52/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0163 - acc: 0.9951 - val_loss: 0.8410 - val_acc: 0.8667\n","\n","Epoch 00052: val_acc did not improve from 0.90000\n","Epoch 53/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0114 - acc: 0.9943 - val_loss: 1.0418 - val_acc: 0.8000\n","\n","Epoch 00053: val_acc did not improve from 0.90000\n","Epoch 54/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0146 - acc: 0.9951 - val_loss: 0.8852 - val_acc: 0.8333\n","\n","Epoch 00054: val_acc did not improve from 0.90000\n","Epoch 55/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0147 - acc: 0.9951 - val_loss: 0.9428 - val_acc: 0.8333\n","\n","Epoch 00055: val_acc did not improve from 0.90000\n","Epoch 56/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0141 - acc: 0.9971 - val_loss: 0.9605 - val_acc: 0.8667\n","\n","Epoch 00056: val_acc did not improve from 0.90000\n","Epoch 57/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0085 - acc: 0.9990 - val_loss: 0.8784 - val_acc: 0.8667\n","\n","Epoch 00057: val_acc did not improve from 0.90000\n","Epoch 58/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0094 - acc: 0.9962 - val_loss: 1.0030 - val_acc: 0.8667\n","\n","Epoch 00058: val_acc did not improve from 0.90000\n","Epoch 59/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0052 - acc: 0.9990 - val_loss: 0.9549 - val_acc: 0.8667\n","\n","Epoch 00059: val_acc did not improve from 0.90000\n","Epoch 60/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0117 - acc: 0.9971 - val_loss: 0.8038 - val_acc: 0.8667\n","\n","Epoch 00060: val_acc did not improve from 0.90000\n","Epoch 61/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0136 - acc: 0.9961 - val_loss: 0.9915 - val_acc: 0.8333\n","\n","Epoch 00061: val_acc did not improve from 0.90000\n","Epoch 62/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0156 - acc: 0.9941 - val_loss: 1.0876 - val_acc: 0.8667\n","\n","Epoch 00062: val_acc did not improve from 0.90000\n","Epoch 63/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0104 - acc: 0.9971 - val_loss: 1.0997 - val_acc: 0.8667\n","\n","Epoch 00063: val_acc did not improve from 0.90000\n","Epoch 64/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0120 - acc: 0.9943 - val_loss: 1.0131 - val_acc: 0.8667\n","\n","Epoch 00064: val_acc did not improve from 0.90000\n","Epoch 65/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0232 - acc: 0.9923 - val_loss: 0.8092 - val_acc: 0.8667\n","\n","Epoch 00065: val_acc did not improve from 0.90000\n","Epoch 66/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0133 - acc: 0.9925 - val_loss: 0.9224 - val_acc: 0.8667\n","\n","Epoch 00066: val_acc did not improve from 0.90000\n","Epoch 67/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0141 - acc: 0.9961 - val_loss: 0.9589 - val_acc: 0.8667\n","\n","Epoch 00067: val_acc did not improve from 0.90000\n","Epoch 68/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0078 - acc: 0.9980 - val_loss: 1.0927 - val_acc: 0.8667\n","\n","Epoch 00068: val_acc did not improve from 0.90000\n","Epoch 69/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0084 - acc: 0.9980 - val_loss: 0.9393 - val_acc: 0.8667\n","\n","Epoch 00069: val_acc did not improve from 0.90000\n","Epoch 70/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0091 - acc: 0.9971 - val_loss: 0.9711 - val_acc: 0.8667\n","\n","Epoch 00070: val_acc did not improve from 0.90000\n","Epoch 71/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0051 - acc: 0.9990 - val_loss: 0.8537 - val_acc: 0.8667\n","\n","Epoch 00071: val_acc did not improve from 0.90000\n","Epoch 72/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0047 - acc: 0.9971 - val_loss: 1.0740 - val_acc: 0.8667\n","\n","Epoch 00072: val_acc did not improve from 0.90000\n","Epoch 73/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 1.0297 - val_acc: 0.8667\n","\n","Epoch 00073: val_acc did not improve from 0.90000\n","Epoch 74/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.1773 - val_acc: 0.8333\n","\n","Epoch 00074: val_acc did not improve from 0.90000\n","Epoch 75/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0087 - acc: 0.9971 - val_loss: 1.1021 - val_acc: 0.8667\n","\n","Epoch 00075: val_acc did not improve from 0.90000\n","Epoch 76/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0083 - acc: 0.9953 - val_loss: 0.9337 - val_acc: 0.8667\n","\n","Epoch 00076: val_acc did not improve from 0.90000\n","Epoch 77/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0064 - acc: 0.9990 - val_loss: 1.1918 - val_acc: 0.8667\n","\n","Epoch 00077: val_acc did not improve from 0.90000\n","Epoch 78/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0100 - acc: 0.9953 - val_loss: 0.9065 - val_acc: 0.8667\n","\n","Epoch 00078: val_acc did not improve from 0.90000\n","Epoch 79/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0113 - acc: 0.9961 - val_loss: 0.8355 - val_acc: 0.8667\n","\n","Epoch 00079: val_acc did not improve from 0.90000\n","Epoch 80/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0076 - acc: 0.9980 - val_loss: 1.0747 - val_acc: 0.8667\n","\n","Epoch 00080: val_acc did not improve from 0.90000\n","Epoch 81/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 1.1352 - val_acc: 0.8667\n","\n","Epoch 00081: val_acc did not improve from 0.90000\n","Epoch 82/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 1.0129 - val_acc: 0.8667\n","\n","Epoch 00082: val_acc did not improve from 0.90000\n","Epoch 83/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.1043 - val_acc: 0.8667\n","\n","Epoch 00083: val_acc did not improve from 0.90000\n","Epoch 84/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0041 - acc: 0.9990 - val_loss: 1.1159 - val_acc: 0.8667\n","\n","Epoch 00084: val_acc did not improve from 0.90000\n","Epoch 85/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.1887 - val_acc: 0.8667\n","\n","Epoch 00085: val_acc did not improve from 0.90000\n","Epoch 86/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0049 - acc: 0.9980 - val_loss: 1.0339 - val_acc: 0.8667\n","\n","Epoch 00086: val_acc did not improve from 0.90000\n","Epoch 87/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0092 - acc: 0.9961 - val_loss: 1.1879 - val_acc: 0.8667\n","\n","Epoch 00087: val_acc did not improve from 0.90000\n","Epoch 88/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 1.1264 - val_acc: 0.8667\n","\n","Epoch 00088: val_acc did not improve from 0.90000\n","Epoch 89/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 1.1642 - val_acc: 0.8667\n","\n","Epoch 00089: val_acc did not improve from 0.90000\n","Epoch 90/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0060 - acc: 0.9990 - val_loss: 1.0051 - val_acc: 0.8667\n","\n","Epoch 00090: val_acc did not improve from 0.90000\n","Epoch 91/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0028 - acc: 0.9990 - val_loss: 1.1956 - val_acc: 0.8667\n","\n","Epoch 00091: val_acc did not improve from 0.90000\n","Epoch 92/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0063 - acc: 0.9980 - val_loss: 1.1173 - val_acc: 0.8667\n","\n","Epoch 00092: val_acc did not improve from 0.90000\n","Epoch 93/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0022 - acc: 0.9990 - val_loss: 1.2057 - val_acc: 0.8667\n","\n","Epoch 00093: val_acc did not improve from 0.90000\n","Epoch 94/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0026 - acc: 0.9990 - val_loss: 1.1540 - val_acc: 0.8667\n","\n","Epoch 00094: val_acc did not improve from 0.90000\n","Epoch 95/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0041 - acc: 0.9990 - val_loss: 1.0944 - val_acc: 0.8667\n","\n","Epoch 00095: val_acc did not improve from 0.90000\n","Epoch 96/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.2142 - val_acc: 0.8667\n","\n","Epoch 00096: val_acc did not improve from 0.90000\n","Epoch 97/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0039 - acc: 0.9990 - val_loss: 1.1769 - val_acc: 0.8667\n","\n","Epoch 00097: val_acc did not improve from 0.90000\n","Epoch 98/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0069 - acc: 0.9980 - val_loss: 1.4474 - val_acc: 0.8000\n","\n","Epoch 00098: val_acc did not improve from 0.90000\n","Epoch 99/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0094 - acc: 0.9961 - val_loss: 1.2237 - val_acc: 0.8333\n","\n","Epoch 00099: val_acc did not improve from 0.90000\n","Epoch 100/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0051 - acc: 0.9971 - val_loss: 1.2007 - val_acc: 0.8667\n","\n","Epoch 00100: val_acc did not improve from 0.90000\n","\n","<keras.callbacks.History at 0x7f82d719ffd0>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ln9YV3yFK5th","colab_type":"code","colab":{}},"cell_type":"code","source":["#left-right our6-364 88.89\n","\n","\n","\n","Epoch 1/100\n","32/32 [==============================] - 2s 60ms/step - loss: 1.0696 - acc: 0.4638 - val_loss: 1.0187 - val_acc: 0.6000\n","\n","Epoch 00001: val_acc improved from -inf to 0.60000, saving model to result/left-right/new/OUR6-364/epoch-01-val-acc-0.6000.hdf5\n","Epoch 2/100\n","32/32 [==============================] - 1s 29ms/step - loss: 1.0233 - acc: 0.5183 - val_loss: 0.9987 - val_acc: 0.6000\n","\n","Epoch 00002: val_acc did not improve from 0.60000\n","Epoch 3/100\n","32/32 [==============================] - 1s 28ms/step - loss: 1.0418 - acc: 0.5198 - val_loss: 0.9865 - val_acc: 0.6000\n","\n","Epoch 00003: val_acc did not improve from 0.60000\n","Epoch 4/100\n","32/32 [==============================] - 1s 29ms/step - loss: 1.0236 - acc: 0.5196 - val_loss: 0.9688 - val_acc: 0.6000\n","\n","Epoch 00004: val_acc did not improve from 0.60000\n","Epoch 5/100\n","32/32 [==============================] - 1s 29ms/step - loss: 1.0282 - acc: 0.5165 - val_loss: 0.9794 - val_acc: 0.6000\n","\n","Epoch 00005: val_acc did not improve from 0.60000\n","Epoch 6/100\n","32/32 [==============================] - 1s 29ms/step - loss: 1.0087 - acc: 0.5310 - val_loss: 0.9723 - val_acc: 0.6000\n","\n","Epoch 00006: val_acc did not improve from 0.60000\n","Epoch 7/100\n","32/32 [==============================] - 1s 29ms/step - loss: 1.0152 - acc: 0.5216 - val_loss: 0.9697 - val_acc: 0.6000\n","\n","Epoch 00007: val_acc did not improve from 0.60000\n","Epoch 8/100\n","32/32 [==============================] - 1s 29ms/step - loss: 1.0278 - acc: 0.5117 - val_loss: 0.9639 - val_acc: 0.6000\n","\n","Epoch 00008: val_acc did not improve from 0.60000\n","Epoch 9/100\n","32/32 [==============================] - 1s 28ms/step - loss: 1.0051 - acc: 0.5167 - val_loss: 0.9822 - val_acc: 0.6000\n","\n","Epoch 00009: val_acc did not improve from 0.60000\n","Epoch 10/100\n","32/32 [==============================] - 1s 29ms/step - loss: 1.0198 - acc: 0.5042 - val_loss: 0.9812 - val_acc: 0.6000\n","\n","Epoch 00010: val_acc did not improve from 0.60000\n","Epoch 11/100\n","32/32 [==============================] - 1s 29ms/step - loss: 1.0025 - acc: 0.5225 - val_loss: 0.9386 - val_acc: 0.6000\n","\n","Epoch 00011: val_acc did not improve from 0.60000\n","Epoch 12/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.9922 - acc: 0.5244 - val_loss: 0.9294 - val_acc: 0.6000\n","\n","Epoch 00012: val_acc did not improve from 0.60000\n","Epoch 13/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.9825 - acc: 0.5388 - val_loss: 0.9348 - val_acc: 0.6222\n","\n","Epoch 00013: val_acc improved from 0.60000 to 0.62222, saving model to result/left-right/new/OUR6-364/epoch-13-val-acc-0.6222.hdf5\n","Epoch 14/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.9639 - acc: 0.5605 - val_loss: 0.8861 - val_acc: 0.6000\n","\n","Epoch 00014: val_acc did not improve from 0.62222\n","Epoch 15/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.9660 - acc: 0.5433 - val_loss: 0.9048 - val_acc: 0.6444\n","\n","Epoch 00015: val_acc improved from 0.62222 to 0.64444, saving model to result/left-right/new/OUR6-364/epoch-15-val-acc-0.6444.hdf5\n","Epoch 16/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.9363 - acc: 0.5849 - val_loss: 0.9013 - val_acc: 0.6000\n","\n","Epoch 00016: val_acc did not improve from 0.64444\n","Epoch 17/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.9622 - acc: 0.5450 - val_loss: 0.8717 - val_acc: 0.6000\n","\n","Epoch 00017: val_acc did not improve from 0.64444\n","Epoch 18/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.9376 - acc: 0.5732 - val_loss: 0.8671 - val_acc: 0.6444\n","\n","Epoch 00018: val_acc did not improve from 0.64444\n","Epoch 19/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.9279 - acc: 0.5607 - val_loss: 0.9119 - val_acc: 0.6000\n","\n","Epoch 00019: val_acc did not improve from 0.64444\n","Epoch 20/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.9246 - acc: 0.5771 - val_loss: 0.9113 - val_acc: 0.6222\n","\n","Epoch 00020: val_acc did not improve from 0.64444\n","Epoch 21/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.9220 - acc: 0.5828 - val_loss: 0.8576 - val_acc: 0.6444\n","\n","Epoch 00021: val_acc did not improve from 0.64444\n","Epoch 22/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.8852 - acc: 0.5975 - val_loss: 0.8486 - val_acc: 0.6222\n","\n","Epoch 00022: val_acc did not improve from 0.64444\n","Epoch 23/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.9052 - acc: 0.5800 - val_loss: 0.8492 - val_acc: 0.6444\n","\n","Epoch 00023: val_acc did not improve from 0.64444\n","Epoch 24/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.8759 - acc: 0.5898 - val_loss: 0.8406 - val_acc: 0.6222\n","\n","Epoch 00024: val_acc did not improve from 0.64444\n","Epoch 25/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.8803 - acc: 0.6006 - val_loss: 0.8190 - val_acc: 0.6444\n","\n","Epoch 00025: val_acc did not improve from 0.64444\n","Epoch 26/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.9016 - acc: 0.5774 - val_loss: 0.8398 - val_acc: 0.6222\n","\n","Epoch 00026: val_acc did not improve from 0.64444\n","Epoch 27/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.8680 - acc: 0.6025 - val_loss: 0.7875 - val_acc: 0.6667\n","\n","Epoch 00027: val_acc improved from 0.64444 to 0.66667, saving model to result/left-right/new/OUR6-364/epoch-27-val-acc-0.6667.hdf5\n","Epoch 28/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.8427 - acc: 0.6250 - val_loss: 0.8115 - val_acc: 0.7556\n","\n","Epoch 00028: val_acc improved from 0.66667 to 0.75556, saving model to result/left-right/new/OUR6-364/epoch-28-val-acc-0.7556.hdf5\n","Epoch 29/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.8183 - acc: 0.6464 - val_loss: 0.7129 - val_acc: 0.7556\n","\n","Epoch 00029: val_acc improved from 0.75556 to 0.75556, saving model to result/left-right/new/OUR6-364/epoch-29-val-acc-0.7556.hdf5\n","Epoch 30/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.7955 - acc: 0.6450 - val_loss: 0.7035 - val_acc: 0.7556\n","\n","Epoch 00030: val_acc did not improve from 0.75556\n","Epoch 31/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.7872 - acc: 0.6516 - val_loss: 0.6689 - val_acc: 0.7556\n","\n","Epoch 00031: val_acc did not improve from 0.75556\n","Epoch 32/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.7353 - acc: 0.6973 - val_loss: 0.6268 - val_acc: 0.8000\n","\n","Epoch 00032: val_acc improved from 0.75556 to 0.80000, saving model to result/left-right/new/OUR6-364/epoch-32-val-acc-0.8000.hdf5\n","Epoch 33/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.7331 - acc: 0.6754 - val_loss: 0.6121 - val_acc: 0.8000\n","\n","Epoch 00033: val_acc did not improve from 0.80000\n","Epoch 34/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.6903 - acc: 0.7167 - val_loss: 0.5622 - val_acc: 0.8667\n","\n","Epoch 00034: val_acc improved from 0.80000 to 0.86667, saving model to result/left-right/new/OUR6-364/epoch-34-val-acc-0.8667.hdf5\n","Epoch 35/100\n","32/32 [==============================] - 1s 35ms/step - loss: 0.6786 - acc: 0.7178 - val_loss: 0.5485 - val_acc: 0.8667\n","\n","Epoch 00035: val_acc did not improve from 0.86667\n","Epoch 36/100\n","32/32 [==============================] - 1s 30ms/step - loss: 0.6523 - acc: 0.7337 - val_loss: 0.5258 - val_acc: 0.8444\n","\n","Epoch 00036: val_acc did not improve from 0.86667\n","Epoch 37/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.6533 - acc: 0.7452 - val_loss: 0.5276 - val_acc: 0.8444\n","\n","Epoch 00037: val_acc did not improve from 0.86667\n","Epoch 38/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.6068 - acc: 0.7530 - val_loss: 0.5062 - val_acc: 0.8444\n","\n","Epoch 00038: val_acc did not improve from 0.86667\n","Epoch 39/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.5732 - acc: 0.7812 - val_loss: 0.4938 - val_acc: 0.8667\n","\n","Epoch 00039: val_acc did not improve from 0.86667\n","Epoch 40/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.5444 - acc: 0.7979 - val_loss: 0.4438 - val_acc: 0.8889\n","\n","Epoch 00040: val_acc improved from 0.86667 to 0.88889, saving model to result/left-right/new/OUR6-364/epoch-40-val-acc-0.8889.hdf5\n","Epoch 41/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.5503 - acc: 0.7949 - val_loss: 0.4442 - val_acc: 0.8444\n","\n","Epoch 00041: val_acc did not improve from 0.88889\n","Epoch 42/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.5241 - acc: 0.7970 - val_loss: 0.4424 - val_acc: 0.8889\n","\n","Epoch 00042: val_acc did not improve from 0.88889\n","Epoch 43/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.4822 - acc: 0.8136 - val_loss: 0.4303 - val_acc: 0.8667\n","\n","Epoch 00043: val_acc did not improve from 0.88889\n","Epoch 44/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.4857 - acc: 0.8057 - val_loss: 0.4116 - val_acc: 0.8889\n","\n","Epoch 00044: val_acc did not improve from 0.88889\n","Epoch 45/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.4465 - acc: 0.8399 - val_loss: 0.4552 - val_acc: 0.8222\n","\n","Epoch 00045: val_acc did not improve from 0.88889\n","Epoch 46/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.4245 - acc: 0.8292 - val_loss: 0.4374 - val_acc: 0.8444\n","\n","Epoch 00046: val_acc did not improve from 0.88889\n","Epoch 47/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.4101 - acc: 0.8485 - val_loss: 0.4299 - val_acc: 0.8444\n","\n","Epoch 00047: val_acc did not improve from 0.88889\n","Epoch 48/100\n","32/32 [==============================] - 1s 32ms/step - loss: 0.3944 - acc: 0.8672 - val_loss: 0.4326 - val_acc: 0.8222\n","\n","Epoch 00048: val_acc did not improve from 0.88889\n","Epoch 49/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.3810 - acc: 0.8545 - val_loss: 0.4611 - val_acc: 0.7778\n","\n","Epoch 00049: val_acc did not improve from 0.88889\n","Epoch 50/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.3810 - acc: 0.8535 - val_loss: 0.3861 - val_acc: 0.8667\n","\n","Epoch 00050: val_acc did not improve from 0.88889\n","Epoch 51/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.3501 - acc: 0.8661 - val_loss: 0.3766 - val_acc: 0.8889\n","\n","Epoch 00051: val_acc did not improve from 0.88889\n","Epoch 52/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.3386 - acc: 0.8856 - val_loss: 0.4016 - val_acc: 0.8222\n","\n","Epoch 00052: val_acc did not improve from 0.88889\n","Epoch 53/100\n","32/32 [==============================] - 1s 32ms/step - loss: 0.3550 - acc: 0.8585 - val_loss: 0.3772 - val_acc: 0.8667\n","\n","Epoch 00053: val_acc did not improve from 0.88889\n","Epoch 54/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.3189 - acc: 0.8838 - val_loss: 0.3640 - val_acc: 0.8667\n","\n","Epoch 00054: val_acc did not improve from 0.88889\n","Epoch 55/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.3171 - acc: 0.8811 - val_loss: 0.3841 - val_acc: 0.8667\n","\n","Epoch 00055: val_acc did not improve from 0.88889\n","Epoch 56/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.3135 - acc: 0.8820 - val_loss: 0.3969 - val_acc: 0.7778\n","\n","Epoch 00056: val_acc did not improve from 0.88889\n","Epoch 57/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.3106 - acc: 0.8899 - val_loss: 0.3816 - val_acc: 0.8444\n","\n","Epoch 00057: val_acc did not improve from 0.88889\n","Epoch 58/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.2690 - acc: 0.9022 - val_loss: 0.4011 - val_acc: 0.7556\n","\n","Epoch 00058: val_acc did not improve from 0.88889\n","Epoch 59/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.2623 - acc: 0.9043 - val_loss: 0.4312 - val_acc: 0.7556\n","\n","Epoch 00059: val_acc did not improve from 0.88889\n","Epoch 60/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.2419 - acc: 0.9201 - val_loss: 0.4382 - val_acc: 0.8222\n","\n","Epoch 00060: val_acc did not improve from 0.88889\n","Epoch 61/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.2778 - acc: 0.9062 - val_loss: 0.4157 - val_acc: 0.8000\n","\n","Epoch 00061: val_acc did not improve from 0.88889\n","Epoch 62/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.2320 - acc: 0.9152 - val_loss: 0.4328 - val_acc: 0.8222\n","\n","Epoch 00062: val_acc did not improve from 0.88889\n","Epoch 63/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.2356 - acc: 0.9090 - val_loss: 0.4083 - val_acc: 0.8444\n","\n","Epoch 00063: val_acc did not improve from 0.88889\n","Epoch 64/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.2223 - acc: 0.9150 - val_loss: 0.3888 - val_acc: 0.8000\n","\n","Epoch 00064: val_acc did not improve from 0.88889\n","Epoch 65/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.2063 - acc: 0.9267 - val_loss: 0.4430 - val_acc: 0.8222\n","\n","Epoch 00065: val_acc did not improve from 0.88889\n","Epoch 66/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.2035 - acc: 0.9172 - val_loss: 0.4212 - val_acc: 0.8667\n","\n","Epoch 00066: val_acc did not improve from 0.88889\n","Epoch 67/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1857 - acc: 0.9306 - val_loss: 0.4094 - val_acc: 0.8222\n","\n","Epoch 00067: val_acc did not improve from 0.88889\n","Epoch 68/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1777 - acc: 0.9237 - val_loss: 0.4450 - val_acc: 0.8667\n","\n","Epoch 00068: val_acc did not improve from 0.88889\n","Epoch 69/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1930 - acc: 0.9239 - val_loss: 0.4143 - val_acc: 0.8444\n","\n","Epoch 00069: val_acc did not improve from 0.88889\n","Epoch 70/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1585 - acc: 0.9393 - val_loss: 0.4550 - val_acc: 0.8000\n","\n","Epoch 00070: val_acc did not improve from 0.88889\n","Epoch 71/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1357 - acc: 0.9540 - val_loss: 0.4102 - val_acc: 0.8222\n","\n","Epoch 00071: val_acc did not improve from 0.88889\n","Epoch 72/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1617 - acc: 0.9491 - val_loss: 0.4888 - val_acc: 0.8222\n","\n","Epoch 00072: val_acc did not improve from 0.88889\n","Epoch 73/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1346 - acc: 0.9550 - val_loss: 0.5052 - val_acc: 0.8444\n","\n","Epoch 00073: val_acc did not improve from 0.88889\n","Epoch 74/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1445 - acc: 0.9491 - val_loss: 0.4288 - val_acc: 0.8222\n","\n","Epoch 00074: val_acc did not improve from 0.88889\n","Epoch 75/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1231 - acc: 0.9570 - val_loss: 0.4467 - val_acc: 0.8444\n","\n","Epoch 00075: val_acc did not improve from 0.88889\n","Epoch 76/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1176 - acc: 0.9659 - val_loss: 0.4400 - val_acc: 0.8000\n","\n","Epoch 00076: val_acc did not improve from 0.88889\n","Epoch 77/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1326 - acc: 0.9551 - val_loss: 0.4287 - val_acc: 0.8444\n","\n","Epoch 00077: val_acc did not improve from 0.88889\n","Epoch 78/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.1283 - acc: 0.9522 - val_loss: 0.4059 - val_acc: 0.8444\n","\n","Epoch 00078: val_acc did not improve from 0.88889\n","Epoch 79/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1127 - acc: 0.9590 - val_loss: 0.4459 - val_acc: 0.8222\n","\n","Epoch 00079: val_acc did not improve from 0.88889\n","Epoch 80/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1035 - acc: 0.9609 - val_loss: 0.5118 - val_acc: 0.8222\n","\n","Epoch 00080: val_acc did not improve from 0.88889\n","Epoch 81/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.1098 - acc: 0.9649 - val_loss: 0.4763 - val_acc: 0.8444\n","\n","Epoch 00081: val_acc did not improve from 0.88889\n","Epoch 82/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0960 - acc: 0.9698 - val_loss: 0.5141 - val_acc: 0.8444\n","\n","Epoch 00082: val_acc did not improve from 0.88889\n","Epoch 83/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.1079 - acc: 0.9580 - val_loss: 0.5378 - val_acc: 0.8222\n","\n","Epoch 00083: val_acc did not improve from 0.88889\n","Epoch 84/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.1016 - acc: 0.9677 - val_loss: 0.5134 - val_acc: 0.8000\n","\n","Epoch 00084: val_acc did not improve from 0.88889\n","Epoch 85/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0803 - acc: 0.9717 - val_loss: 0.4956 - val_acc: 0.8444\n","\n","Epoch 00085: val_acc did not improve from 0.88889\n","Epoch 86/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0794 - acc: 0.9785 - val_loss: 0.5336 - val_acc: 0.8222\n","\n","Epoch 00086: val_acc did not improve from 0.88889\n","Epoch 87/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0822 - acc: 0.9765 - val_loss: 0.4680 - val_acc: 0.8222\n","\n","Epoch 00087: val_acc did not improve from 0.88889\n","Epoch 88/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0997 - acc: 0.9687 - val_loss: 0.5630 - val_acc: 0.8222\n","\n","Epoch 00088: val_acc did not improve from 0.88889\n","Epoch 89/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0963 - acc: 0.9659 - val_loss: 0.5459 - val_acc: 0.7778\n","\n","Epoch 00089: val_acc did not improve from 0.88889\n","Epoch 90/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0759 - acc: 0.9765 - val_loss: 0.5395 - val_acc: 0.8444\n","\n","Epoch 00090: val_acc did not improve from 0.88889\n","Epoch 91/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0674 - acc: 0.9814 - val_loss: 0.4864 - val_acc: 0.8000\n","\n","Epoch 00091: val_acc did not improve from 0.88889\n","Epoch 92/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0734 - acc: 0.9755 - val_loss: 0.5009 - val_acc: 0.8444\n","\n","Epoch 00092: val_acc did not improve from 0.88889\n","Epoch 93/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0607 - acc: 0.9863 - val_loss: 0.5860 - val_acc: 0.7778\n","\n","Epoch 00093: val_acc did not improve from 0.88889\n","Epoch 94/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0781 - acc: 0.9698 - val_loss: 0.6151 - val_acc: 0.8000\n","\n","Epoch 00094: val_acc did not improve from 0.88889\n","Epoch 95/100\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0707 - acc: 0.9748 - val_loss: 0.6440 - val_acc: 0.8000\n","\n","Epoch 00095: val_acc did not improve from 0.88889\n","Epoch 96/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0794 - acc: 0.9728 - val_loss: 0.5648 - val_acc: 0.8000\n","\n","Epoch 00096: val_acc did not improve from 0.88889\n","Epoch 97/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0824 - acc: 0.9756 - val_loss: 0.5526 - val_acc: 0.8444\n","\n","Epoch 00097: val_acc did not improve from 0.88889\n","Epoch 98/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0624 - acc: 0.9775 - val_loss: 0.4925 - val_acc: 0.8222\n","\n","Epoch 00098: val_acc did not improve from 0.88889\n","Epoch 99/100\n","32/32 [==============================] - 1s 28ms/step - loss: 0.0491 - acc: 0.9835 - val_loss: 0.5272 - val_acc: 0.8222\n","\n","Epoch 00099: val_acc did not improve from 0.88889\n","Epoch 100/100\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0588 - acc: 0.9835 - val_loss: 0.6023 - val_acc: 0.7778\n","\n","Epoch 00100: val_acc did not improve from 0.88889\n","\n","<keras.callbacks.History at 0x7fe5800b27b8>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ptHo5V8BE4bh","colab_type":"code","colab":{}},"cell_type":"code","source":["# left- right alex drop 91.11\n","\n","\n","Epoch 1/100\n","32/32 [==============================] - 3s 109ms/step - loss: 0.9119 - acc: 0.6084 - val_loss: 1.0522 - val_acc: 0.2889\n","\n","Epoch 00001: val_acc improved from -inf to 0.28889, saving model to result/left-right/new/Alex_drop361/epoch-01-val-acc-0.2889.hdf5\n","Epoch 2/100\n","32/32 [==============================] - 3s 87ms/step - loss: 0.3706 - acc: 0.8604 - val_loss: 0.5092 - val_acc: 0.8222\n","\n","Epoch 00002: val_acc improved from 0.28889 to 0.82222, saving model to result/left-right/new/Alex_drop361/epoch-02-val-acc-0.8222.hdf5\n","Epoch 3/100\n","32/32 [==============================] - 3s 83ms/step - loss: 0.0945 - acc: 0.9726 - val_loss: 0.5703 - val_acc: 0.7556\n","\n","Epoch 00003: val_acc did not improve from 0.82222\n","Epoch 4/100\n","32/32 [==============================] - 3s 84ms/step - loss: 0.0148 - acc: 0.9990 - val_loss: 0.8345 - val_acc: 0.7778\n","\n","Epoch 00004: val_acc did not improve from 0.82222\n","Epoch 5/100\n","32/32 [==============================] - 3s 84ms/step - loss: 0.0647 - acc: 0.9786 - val_loss: 0.7843 - val_acc: 0.7333\n","\n","Epoch 00005: val_acc did not improve from 0.82222\n","Epoch 6/100\n","32/32 [==============================] - 3s 84ms/step - loss: 0.0123 - acc: 0.9990 - val_loss: 0.5370 - val_acc: 0.8444\n","\n","Epoch 00006: val_acc improved from 0.82222 to 0.84444, saving model to result/left-right/new/Alex_drop361/epoch-06-val-acc-0.8444.hdf5\n","Epoch 7/100\n","32/32 [==============================] - 3s 84ms/step - loss: 9.4939e-04 - acc: 1.0000 - val_loss: 0.4413 - val_acc: 0.8222\n","\n","Epoch 00007: val_acc did not improve from 0.84444\n","Epoch 8/100\n","32/32 [==============================] - 3s 85ms/step - loss: 4.4454e-04 - acc: 1.0000 - val_loss: 0.4570 - val_acc: 0.8000\n","\n","Epoch 00008: val_acc did not improve from 0.84444\n","Epoch 9/100\n","32/32 [==============================] - 3s 84ms/step - loss: 2.2413e-04 - acc: 1.0000 - val_loss: 0.4956 - val_acc: 0.8000\n","\n","Epoch 00009: val_acc did not improve from 0.84444\n","Epoch 10/100\n","32/32 [==============================] - 3s 84ms/step - loss: 1.8105e-04 - acc: 1.0000 - val_loss: 0.5166 - val_acc: 0.8000\n","\n","Epoch 00010: val_acc did not improve from 0.84444\n","Epoch 11/100\n","32/32 [==============================] - 3s 85ms/step - loss: 1.3180e-04 - acc: 1.0000 - val_loss: 0.5477 - val_acc: 0.8000\n","\n","Epoch 00011: val_acc did not improve from 0.84444\n","Epoch 12/100\n","32/32 [==============================] - 3s 83ms/step - loss: 1.2308e-04 - acc: 1.0000 - val_loss: 0.5659 - val_acc: 0.8222\n","\n","Epoch 00012: val_acc did not improve from 0.84444\n","Epoch 13/100\n","32/32 [==============================] - 3s 87ms/step - loss: 9.7277e-05 - acc: 1.0000 - val_loss: 0.5842 - val_acc: 0.8000\n","\n","Epoch 00013: val_acc did not improve from 0.84444\n","Epoch 14/100\n","32/32 [==============================] - 3s 85ms/step - loss: 8.3208e-05 - acc: 1.0000 - val_loss: 0.5996 - val_acc: 0.8222\n","\n","Epoch 00014: val_acc did not improve from 0.84444\n","Epoch 15/100\n","32/32 [==============================] - 3s 84ms/step - loss: 7.6875e-05 - acc: 1.0000 - val_loss: 0.6095 - val_acc: 0.8222\n","\n","Epoch 00015: val_acc did not improve from 0.84444\n","Epoch 16/100\n","32/32 [==============================] - 3s 85ms/step - loss: 6.8601e-05 - acc: 1.0000 - val_loss: 0.6223 - val_acc: 0.8000\n","\n","Epoch 00016: val_acc did not improve from 0.84444\n","Epoch 17/100\n","32/32 [==============================] - 3s 85ms/step - loss: 6.1158e-05 - acc: 1.0000 - val_loss: 0.6369 - val_acc: 0.8000\n","\n","Epoch 00017: val_acc did not improve from 0.84444\n","Epoch 18/100\n","32/32 [==============================] - 3s 84ms/step - loss: 4.5285e-05 - acc: 1.0000 - val_loss: 0.6440 - val_acc: 0.8000\n","\n","Epoch 00018: val_acc did not improve from 0.84444\n","Epoch 19/100\n","32/32 [==============================] - 3s 85ms/step - loss: 1.8557e-04 - acc: 1.0000 - val_loss: 0.6538 - val_acc: 0.8000\n","\n","Epoch 00019: val_acc did not improve from 0.84444\n","Epoch 20/100\n","32/32 [==============================] - 3s 84ms/step - loss: 4.5611e-05 - acc: 1.0000 - val_loss: 0.6358 - val_acc: 0.8000\n","\n","Epoch 00020: val_acc did not improve from 0.84444\n","Epoch 21/100\n","32/32 [==============================] - 3s 85ms/step - loss: 4.4157e-05 - acc: 1.0000 - val_loss: 0.6383 - val_acc: 0.8000\n","\n","Epoch 00021: val_acc did not improve from 0.84444\n","Epoch 22/100\n","32/32 [==============================] - 3s 84ms/step - loss: 0.0503 - acc: 0.9815 - val_loss: 1.5489 - val_acc: 0.6444\n","\n","Epoch 00022: val_acc did not improve from 0.84444\n","Epoch 23/100\n","32/32 [==============================] - 3s 85ms/step - loss: 0.2314 - acc: 0.9151 - val_loss: 2.1766 - val_acc: 0.2444\n","\n","Epoch 00023: val_acc did not improve from 0.84444\n","Epoch 24/100\n","32/32 [==============================] - 3s 84ms/step - loss: 0.0760 - acc: 0.9775 - val_loss: 0.7517 - val_acc: 0.6889\n","\n","Epoch 00024: val_acc did not improve from 0.84444\n","Epoch 25/100\n","32/32 [==============================] - 3s 84ms/step - loss: 0.0241 - acc: 0.9971 - val_loss: 0.5519 - val_acc: 0.8222\n","\n","Epoch 00025: val_acc did not improve from 0.84444\n","Epoch 26/100\n","32/32 [==============================] - 3s 85ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6325 - val_acc: 0.7778\n","\n","Epoch 00026: val_acc did not improve from 0.84444\n","Epoch 27/100\n","32/32 [==============================] - 3s 84ms/step - loss: 1.3764e-04 - acc: 1.0000 - val_loss: 0.6338 - val_acc: 0.8000\n","\n","Epoch 00027: val_acc did not improve from 0.84444\n","Epoch 28/100\n","32/32 [==============================] - 3s 84ms/step - loss: 3.4486e-04 - acc: 1.0000 - val_loss: 0.8812 - val_acc: 0.7778\n","\n","Epoch 00028: val_acc did not improve from 0.84444\n","Epoch 29/100\n","32/32 [==============================] - 3s 85ms/step - loss: 0.0330 - acc: 0.9902 - val_loss: 1.2809 - val_acc: 0.3778\n","\n","Epoch 00029: val_acc did not improve from 0.84444\n","Epoch 30/100\n","32/32 [==============================] - 3s 84ms/step - loss: 0.1055 - acc: 0.9698 - val_loss: 1.4766 - val_acc: 0.6444\n","\n","Epoch 00030: val_acc did not improve from 0.84444\n","Epoch 31/100\n","32/32 [==============================] - 3s 84ms/step - loss: 0.1918 - acc: 0.9425 - val_loss: 0.7121 - val_acc: 0.7556\n","\n","Epoch 00031: val_acc did not improve from 0.84444\n","Epoch 32/100\n","32/32 [==============================] - 3s 85ms/step - loss: 0.0119 - acc: 0.9990 - val_loss: 0.5114 - val_acc: 0.7333\n","\n","Epoch 00032: val_acc did not improve from 0.84444\n","Epoch 33/100\n","32/32 [==============================] - 3s 84ms/step - loss: 4.1051e-04 - acc: 1.0000 - val_loss: 0.4338 - val_acc: 0.7556\n","\n","Epoch 00033: val_acc did not improve from 0.84444\n","Epoch 34/100\n","32/32 [==============================] - 3s 85ms/step - loss: 3.5995e-04 - acc: 1.0000 - val_loss: 0.3922 - val_acc: 0.8222\n","\n","Epoch 00034: val_acc did not improve from 0.84444\n","Epoch 35/100\n","32/32 [==============================] - 3s 83ms/step - loss: 1.3024e-04 - acc: 1.0000 - val_loss: 0.2953 - val_acc: 0.8444\n","\n","Epoch 00035: val_acc did not improve from 0.84444\n","Epoch 36/100\n","32/32 [==============================] - 3s 84ms/step - loss: 9.6689e-05 - acc: 1.0000 - val_loss: 0.2685 - val_acc: 0.9111\n","\n","Epoch 00036: val_acc improved from 0.84444 to 0.91111, saving model to result/left-right/new/Alex_drop361/epoch-36-val-acc-0.9111.hdf5\n","Epoch 37/100\n","32/32 [==============================] - 3s 87ms/step - loss: 7.9934e-05 - acc: 1.0000 - val_loss: 0.2758 - val_acc: 0.9111\n","\n","Epoch 00037: val_acc did not improve from 0.91111\n","Epoch 38/100\n","32/32 [==============================] - 3s 84ms/step - loss: 8.1066e-05 - acc: 1.0000 - val_loss: 0.2902 - val_acc: 0.9111\n","\n","Epoch 00038: val_acc did not improve from 0.91111\n","Epoch 39/100\n","32/32 [==============================] - 3s 84ms/step - loss: 5.5603e-05 - acc: 1.0000 - val_loss: 0.3116 - val_acc: 0.9111\n","\n","Epoch 00039: val_acc did not improve from 0.91111\n","Epoch 40/100\n","32/32 [==============================] - 3s 85ms/step - loss: 4.4541e-05 - acc: 1.0000 - val_loss: 0.3274 - val_acc: 0.9111\n","\n","Epoch 00040: val_acc did not improve from 0.91111\n","Epoch 41/100\n","32/32 [==============================] - 3s 83ms/step - loss: 4.1613e-05 - acc: 1.0000 - val_loss: 0.3408 - val_acc: 0.9111\n","\n","Epoch 00041: val_acc did not improve from 0.91111\n","Epoch 42/100\n","32/32 [==============================] - 3s 85ms/step - loss: 3.7056e-05 - acc: 1.0000 - val_loss: 0.3535 - val_acc: 0.9111\n","\n","Epoch 00042: val_acc did not improve from 0.91111\n","Epoch 43/100\n","32/32 [==============================] - 3s 84ms/step - loss: 3.6310e-05 - acc: 1.0000 - val_loss: 0.3747 - val_acc: 0.9111\n","\n","Epoch 00043: val_acc did not improve from 0.91111\n","Epoch 44/100\n","32/32 [==============================] - 3s 84ms/step - loss: 2.8133e-05 - acc: 1.0000 - val_loss: 0.3783 - val_acc: 0.9111\n","\n","Epoch 00044: val_acc did not improve from 0.91111\n","Epoch 45/100\n","32/32 [==============================] - 3s 84ms/step - loss: 2.5650e-05 - acc: 1.0000 - val_loss: 0.3822 - val_acc: 0.9111\n","\n","Epoch 00045: val_acc did not improve from 0.91111\n","Epoch 46/100\n","32/32 [==============================] - 3s 84ms/step - loss: 2.5428e-05 - acc: 1.0000 - val_loss: 0.3885 - val_acc: 0.9111\n","\n","Epoch 00046: val_acc did not improve from 0.91111\n","Epoch 47/100\n","32/32 [==============================] - 3s 85ms/step - loss: 2.6639e-05 - acc: 1.0000 - val_loss: 0.3957 - val_acc: 0.9111\n","\n","Epoch 00047: val_acc did not improve from 0.91111\n","Epoch 48/100\n","32/32 [==============================] - 3s 84ms/step - loss: 1.7568e-05 - acc: 1.0000 - val_loss: 0.3986 - val_acc: 0.9111\n","\n","Epoch 00048: val_acc did not improve from 0.91111\n","Epoch 49/100\n","32/32 [==============================] - 3s 84ms/step - loss: 1.6194e-05 - acc: 1.0000 - val_loss: 0.3984 - val_acc: 0.9111\n","\n","Epoch 00049: val_acc did not improve from 0.91111\n","Epoch 50/100\n","32/32 [==============================] - 3s 84ms/step - loss: 1.5865e-05 - acc: 1.0000 - val_loss: 0.4016 - val_acc: 0.9111\n","\n","Epoch 00050: val_acc did not improve from 0.91111\n","Epoch 51/100\n","32/32 [==============================] - 3s 85ms/step - loss: 1.3046e-05 - acc: 1.0000 - val_loss: 0.4052 - val_acc: 0.9111\n","\n","Epoch 00051: val_acc did not improve from 0.91111\n","Epoch 52/100\n","32/32 [==============================] - 3s 85ms/step - loss: 1.1623e-05 - acc: 1.0000 - val_loss: 0.4086 - val_acc: 0.9111\n","\n","Epoch 00052: val_acc did not improve from 0.91111\n","Epoch 53/100\n","32/32 [==============================] - 3s 84ms/step - loss: 1.0827e-05 - acc: 1.0000 - val_loss: 0.4130 - val_acc: 0.9111\n","\n","Epoch 00053: val_acc did not improve from 0.91111\n","Epoch 54/100\n","32/32 [==============================] - 3s 84ms/step - loss: 1.9125e-05 - acc: 1.0000 - val_loss: 0.4156 - val_acc: 0.9111\n","\n","Epoch 00054: val_acc did not improve from 0.91111\n","Epoch 55/100\n","32/32 [==============================] - 3s 85ms/step - loss: 1.4848e-05 - acc: 1.0000 - val_loss: 0.4163 - val_acc: 0.8889\n","\n","Epoch 00055: val_acc did not improve from 0.91111\n","Epoch 56/100\n","32/32 [==============================] - 3s 82ms/step - loss: 7.9989e-06 - acc: 1.0000 - val_loss: 0.4218 - val_acc: 0.8889\n","\n","Epoch 00056: val_acc did not improve from 0.91111\n","Epoch 57/100\n","32/32 [==============================] - 3s 84ms/step - loss: 8.4937e-06 - acc: 1.0000 - val_loss: 0.4237 - val_acc: 0.9111\n","\n","Epoch 00057: val_acc did not improve from 0.91111\n","Epoch 58/100\n","32/32 [==============================] - 3s 84ms/step - loss: 7.2458e-06 - acc: 1.0000 - val_loss: 0.4276 - val_acc: 0.9111\n","\n","Epoch 00058: val_acc did not improve from 0.91111\n","Epoch 59/100\n","32/32 [==============================] - 3s 83ms/step - loss: 7.4983e-06 - acc: 1.0000 - val_loss: 0.4286 - val_acc: 0.9111\n","\n","Epoch 00059: val_acc did not improve from 0.91111\n","Epoch 60/100\n","32/32 [==============================] - 3s 84ms/step - loss: 5.7226e-06 - acc: 1.0000 - val_loss: 0.4310 - val_acc: 0.9111\n","\n","Epoch 00060: val_acc did not improve from 0.91111\n","Epoch 61/100\n","32/32 [==============================] - 3s 84ms/step - loss: 5.4698e-06 - acc: 1.0000 - val_loss: 0.4339 - val_acc: 0.9111\n","\n","Epoch 00061: val_acc did not improve from 0.91111\n","Epoch 62/100\n","32/32 [==============================] - 3s 84ms/step - loss: 6.5403e-06 - acc: 1.0000 - val_loss: 0.4371 - val_acc: 0.9111\n","\n","Epoch 00062: val_acc did not improve from 0.91111\n","Epoch 63/100\n","32/32 [==============================] - 3s 83ms/step - loss: 5.9855e-06 - acc: 1.0000 - val_loss: 0.4409 - val_acc: 0.9111\n","\n","Epoch 00063: val_acc did not improve from 0.91111\n","Epoch 64/100\n","32/32 [==============================] - 3s 84ms/step - loss: 7.8944e-06 - acc: 1.0000 - val_loss: 0.4450 - val_acc: 0.9111\n","\n","Epoch 00064: val_acc did not improve from 0.91111\n","Epoch 65/100\n","32/32 [==============================] - 3s 84ms/step - loss: 6.2964e-06 - acc: 1.0000 - val_loss: 0.4499 - val_acc: 0.9111\n","\n","Epoch 00065: val_acc did not improve from 0.91111\n","Epoch 66/100\n","32/32 [==============================] - 3s 84ms/step - loss: 3.8917e-06 - acc: 1.0000 - val_loss: 0.4514 - val_acc: 0.9111\n","\n","Epoch 00066: val_acc did not improve from 0.91111\n","Epoch 67/100\n","32/32 [==============================] - 3s 84ms/step - loss: 5.4569e-06 - acc: 1.0000 - val_loss: 0.4515 - val_acc: 0.8889\n","\n","Epoch 00067: val_acc did not improve from 0.91111\n","Epoch 68/100\n","32/32 [==============================] - 3s 84ms/step - loss: 3.8970e-06 - acc: 1.0000 - val_loss: 0.4556 - val_acc: 0.8889\n","\n","Epoch 00068: val_acc did not improve from 0.91111\n","Epoch 69/100\n","32/32 [==============================] - 3s 84ms/step - loss: 3.8613e-06 - acc: 1.0000 - val_loss: 0.4579 - val_acc: 0.8889\n","\n","Epoch 00069: val_acc did not improve from 0.91111\n","Epoch 70/100\n","32/32 [==============================] - 3s 86ms/step - loss: 3.3825e-06 - acc: 1.0000 - val_loss: 0.4604 - val_acc: 0.8889\n","\n","Epoch 00070: val_acc did not improve from 0.91111\n","Epoch 71/100\n","32/32 [==============================] - 3s 83ms/step - loss: 4.1514e-06 - acc: 1.0000 - val_loss: 0.4608 - val_acc: 0.8889\n","\n","Epoch 00071: val_acc did not improve from 0.91111\n","Epoch 72/100\n","32/32 [==============================] - 3s 85ms/step - loss: 3.1311e-06 - acc: 1.0000 - val_loss: 0.4626 - val_acc: 0.8889\n","\n","Epoch 00072: val_acc did not improve from 0.91111\n","Epoch 73/100\n","32/32 [==============================] - 3s 84ms/step - loss: 2.9374e-06 - acc: 1.0000 - val_loss: 0.4642 - val_acc: 0.8889\n","\n","Epoch 00073: val_acc did not improve from 0.91111\n","Epoch 74/100\n","32/32 [==============================] - 3s 83ms/step - loss: 3.1249e-06 - acc: 1.0000 - val_loss: 0.4669 - val_acc: 0.8889\n","\n","Epoch 00074: val_acc did not improve from 0.91111\n","Epoch 75/100\n","32/32 [==============================] - 3s 84ms/step - loss: 2.8439e-06 - acc: 1.0000 - val_loss: 0.4696 - val_acc: 0.8889\n","\n","Epoch 00075: val_acc did not improve from 0.91111\n","Epoch 76/100\n","32/32 [==============================] - 3s 84ms/step - loss: 2.9814e-06 - acc: 1.0000 - val_loss: 0.4719 - val_acc: 0.8889\n","\n","Epoch 00076: val_acc did not improve from 0.91111\n","Epoch 77/100\n","32/32 [==============================] - 3s 83ms/step - loss: 2.7214e-06 - acc: 1.0000 - val_loss: 0.4732 - val_acc: 0.9111\n","\n","Epoch 00077: val_acc did not improve from 0.91111\n","Epoch 78/100\n","32/32 [==============================] - 3s 85ms/step - loss: 2.1015e-06 - acc: 1.0000 - val_loss: 0.4765 - val_acc: 0.9111\n","\n","Epoch 00078: val_acc did not improve from 0.91111\n","Epoch 79/100\n","32/32 [==============================] - 3s 83ms/step - loss: 8.2573e-06 - acc: 1.0000 - val_loss: 0.4931 - val_acc: 0.8889\n","\n","Epoch 00079: val_acc did not improve from 0.91111\n","Epoch 80/100\n","32/32 [==============================] - 3s 85ms/step - loss: 2.0962e-06 - acc: 1.0000 - val_loss: 0.4939 - val_acc: 0.8667\n","\n","Epoch 00080: val_acc did not improve from 0.91111\n","Epoch 81/100\n","32/32 [==============================] - 3s 84ms/step - loss: 2.1476e-06 - acc: 1.0000 - val_loss: 0.4903 - val_acc: 0.8889\n","\n","Epoch 00081: val_acc did not improve from 0.91111\n","Epoch 82/100\n","32/32 [==============================] - 3s 84ms/step - loss: 1.9649e-06 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.8889\n","\n","Epoch 00082: val_acc did not improve from 0.91111\n","Epoch 83/100\n","32/32 [==============================] - 3s 85ms/step - loss: 6.7959e-06 - acc: 1.0000 - val_loss: 0.4909 - val_acc: 0.8667\n","\n","Epoch 00083: val_acc did not improve from 0.91111\n","Epoch 84/100\n","32/32 [==============================] - 3s 84ms/step - loss: 1.8656e-06 - acc: 1.0000 - val_loss: 0.4959 - val_acc: 0.8667\n","\n","Epoch 00084: val_acc did not improve from 0.91111\n","Epoch 85/100\n","32/32 [==============================] - 3s 84ms/step - loss: 2.6823e-06 - acc: 1.0000 - val_loss: 0.4963 - val_acc: 0.8667\n","\n","Epoch 00085: val_acc did not improve from 0.91111\n","Epoch 86/100\n","32/32 [==============================] - 3s 84ms/step - loss: 1.8645e-06 - acc: 1.0000 - val_loss: 0.4981 - val_acc: 0.8667\n","\n","Epoch 00086: val_acc did not improve from 0.91111\n","Epoch 87/100\n","32/32 [==============================] - 3s 84ms/step - loss: 1.3747e-06 - acc: 1.0000 - val_loss: 0.5002 - val_acc: 0.8667\n","\n","Epoch 00087: val_acc did not improve from 0.91111\n","Epoch 88/100\n","32/32 [==============================] - 3s 85ms/step - loss: 1.4680e-06 - acc: 1.0000 - val_loss: 0.5015 - val_acc: 0.8667\n","\n","Epoch 00088: val_acc did not improve from 0.91111\n","Epoch 89/100\n","32/32 [==============================] - 3s 84ms/step - loss: 1.4777e-06 - acc: 1.0000 - val_loss: 0.5024 - val_acc: 0.8667\n","\n","Epoch 00089: val_acc did not improve from 0.91111\n","Epoch 90/100\n","32/32 [==============================] - 3s 85ms/step - loss: 1.7753e-06 - acc: 1.0000 - val_loss: 0.5068 - val_acc: 0.8667\n","\n","Epoch 00090: val_acc did not improve from 0.91111\n","Epoch 91/100\n","32/32 [==============================] - 3s 84ms/step - loss: 1.5435e-06 - acc: 1.0000 - val_loss: 0.5072 - val_acc: 0.8667\n","\n","Epoch 00091: val_acc did not improve from 0.91111\n","Epoch 92/100\n","32/32 [==============================] - 3s 85ms/step - loss: 1.1808e-06 - acc: 1.0000 - val_loss: 0.5091 - val_acc: 0.8667\n","\n","Epoch 00092: val_acc did not improve from 0.91111\n","Epoch 93/100\n","32/32 [==============================] - 3s 84ms/step - loss: 1.1810e-06 - acc: 1.0000 - val_loss: 0.5121 - val_acc: 0.8667\n","\n","Epoch 00093: val_acc did not improve from 0.91111\n","Epoch 94/100\n","32/32 [==============================] - 3s 84ms/step - loss: 1.1693e-06 - acc: 1.0000 - val_loss: 0.5127 - val_acc: 0.8667\n","\n","Epoch 00094: val_acc did not improve from 0.91111\n","Epoch 95/100\n","32/32 [==============================] - 3s 85ms/step - loss: 1.5791e-06 - acc: 1.0000 - val_loss: 0.5126 - val_acc: 0.8667\n","\n","Epoch 00095: val_acc did not improve from 0.91111\n","Epoch 96/100\n","32/32 [==============================] - 3s 83ms/step - loss: 9.3105e-07 - acc: 1.0000 - val_loss: 0.5149 - val_acc: 0.8667\n","\n","Epoch 00096: val_acc did not improve from 0.91111\n","Epoch 97/100\n","32/32 [==============================] - 3s 85ms/step - loss: 9.4767e-07 - acc: 1.0000 - val_loss: 0.5154 - val_acc: 0.8667\n","\n","Epoch 00097: val_acc did not improve from 0.91111\n","Epoch 98/100\n","32/32 [==============================] - 3s 83ms/step - loss: 2.0746e-06 - acc: 1.0000 - val_loss: 0.5158 - val_acc: 0.8667\n","\n","Epoch 00098: val_acc did not improve from 0.91111\n","Epoch 99/100\n","32/32 [==============================] - 3s 85ms/step - loss: 9.7002e-07 - acc: 1.0000 - val_loss: 0.5145 - val_acc: 0.8444\n","\n","Epoch 00099: val_acc did not improve from 0.91111\n","Epoch 100/100\n","32/32 [==============================] - 3s 84ms/step - loss: 1.0556e-06 - acc: 1.0000 - val_loss: 0.5157 - val_acc: 0.8667\n","\n","Epoch 00100: val_acc did not improve from 0.91111\n","\n","<keras.callbacks.History at 0x7fe581db70f0>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"773z7NbkAIYe","colab_type":"code","colab":{}},"cell_type":"code","source":["# left rigth our5-359  86.67\n","\n","\n","\n","Epoch 1/100\n","32/32 [==============================] - 1s 34ms/step - loss: 1.0266 - acc: 0.5146 - val_loss: 0.9713 - val_acc: 0.6000\n","\n","Epoch 00001: val_acc improved from -inf to 0.60000, saving model to result/left-right/new/OUR5-362/epoch-01-val-acc-0.6000.hdf5\n","Epoch 2/100\n","32/32 [==============================] - 1s 24ms/step - loss: 1.0087 - acc: 0.5186 - val_loss: 0.9487 - val_acc: 0.6000\n","\n","Epoch 00002: val_acc did not improve from 0.60000\n","Epoch 3/100\n","32/32 [==============================] - 1s 21ms/step - loss: 0.9811 - acc: 0.5138 - val_loss: 0.9253 - val_acc: 0.6000\n","\n","Epoch 00003: val_acc did not improve from 0.60000\n","Epoch 4/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.9242 - acc: 0.5623 - val_loss: 0.8937 - val_acc: 0.6222\n","\n","Epoch 00004: val_acc improved from 0.60000 to 0.62222, saving model to result/left-right/new/OUR5-362/epoch-04-val-acc-0.6222.hdf5\n","Epoch 5/100\n","32/32 [==============================] - 1s 21ms/step - loss: 0.8842 - acc: 0.6203 - val_loss: 0.8241 - val_acc: 0.6889\n","\n","Epoch 00005: val_acc improved from 0.62222 to 0.68889, saving model to result/left-right/new/OUR5-362/epoch-05-val-acc-0.6889.hdf5\n","Epoch 6/100\n","32/32 [==============================] - 1s 21ms/step - loss: 0.8109 - acc: 0.6798 - val_loss: 0.7880 - val_acc: 0.7333\n","\n","Epoch 00006: val_acc improved from 0.68889 to 0.73333, saving model to result/left-right/new/OUR5-362/epoch-06-val-acc-0.7333.hdf5\n","Epoch 7/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.7726 - acc: 0.7034 - val_loss: 0.7070 - val_acc: 0.6667\n","\n","Epoch 00007: val_acc did not improve from 0.73333\n","Epoch 8/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.7039 - acc: 0.7216 - val_loss: 0.6917 - val_acc: 0.7556\n","\n","Epoch 00008: val_acc improved from 0.73333 to 0.75556, saving model to result/left-right/new/OUR5-362/epoch-08-val-acc-0.7556.hdf5\n","Epoch 9/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.6606 - acc: 0.7472 - val_loss: 0.6245 - val_acc: 0.7111\n","\n","Epoch 00009: val_acc did not improve from 0.75556\n","Epoch 10/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.6158 - acc: 0.7704 - val_loss: 0.5878 - val_acc: 0.7333\n","\n","Epoch 00010: val_acc did not improve from 0.75556\n","Epoch 11/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.5878 - acc: 0.7873 - val_loss: 0.5653 - val_acc: 0.7111\n","\n","Epoch 00011: val_acc did not improve from 0.75556\n","Epoch 12/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.5483 - acc: 0.8104 - val_loss: 0.5525 - val_acc: 0.7556\n","\n","Epoch 00012: val_acc did not improve from 0.75556\n","Epoch 13/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.5423 - acc: 0.8007 - val_loss: 0.5617 - val_acc: 0.7556\n","\n","Epoch 00013: val_acc did not improve from 0.75556\n","Epoch 14/100\n","32/32 [==============================] - 1s 22ms/step - loss: 0.5292 - acc: 0.7940 - val_loss: 0.5307 - val_acc: 0.7778\n","\n","Epoch 00014: val_acc improved from 0.75556 to 0.77778, saving model to result/left-right/new/OUR5-362/epoch-14-val-acc-0.7778.hdf5\n","Epoch 15/100\n","32/32 [==============================] - 1s 21ms/step - loss: 0.4961 - acc: 0.8134 - val_loss: 0.5128 - val_acc: 0.7556\n","\n","Epoch 00015: val_acc did not improve from 0.77778\n","Epoch 16/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.4714 - acc: 0.8233 - val_loss: 0.5395 - val_acc: 0.7778\n","\n","Epoch 00016: val_acc did not improve from 0.77778\n","Epoch 17/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.4455 - acc: 0.8322 - val_loss: 0.5017 - val_acc: 0.8000\n","\n","Epoch 00017: val_acc improved from 0.77778 to 0.80000, saving model to result/left-right/new/OUR5-362/epoch-17-val-acc-0.8000.hdf5\n","Epoch 18/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.4220 - acc: 0.8545 - val_loss: 0.4814 - val_acc: 0.7556\n","\n","Epoch 00018: val_acc did not improve from 0.80000\n","Epoch 19/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.4160 - acc: 0.8505 - val_loss: 0.4914 - val_acc: 0.7778\n","\n","Epoch 00019: val_acc did not improve from 0.80000\n","Epoch 20/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.4106 - acc: 0.8536 - val_loss: 0.4701 - val_acc: 0.8000\n","\n","Epoch 00020: val_acc did not improve from 0.80000\n","Epoch 21/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.3711 - acc: 0.8641 - val_loss: 0.5136 - val_acc: 0.7333\n","\n","Epoch 00021: val_acc did not improve from 0.80000\n","Epoch 22/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.3660 - acc: 0.8585 - val_loss: 0.4803 - val_acc: 0.7778\n","\n","Epoch 00022: val_acc did not improve from 0.80000\n","Epoch 23/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.3609 - acc: 0.8652 - val_loss: 0.4615 - val_acc: 0.8000\n","\n","Epoch 00023: val_acc did not improve from 0.80000\n","Epoch 24/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.3263 - acc: 0.8760 - val_loss: 0.4733 - val_acc: 0.8000\n","\n","Epoch 00024: val_acc did not improve from 0.80000\n","Epoch 25/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.3149 - acc: 0.8965 - val_loss: 0.4683 - val_acc: 0.8000\n","\n","Epoch 00025: val_acc did not improve from 0.80000\n","Epoch 26/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.3285 - acc: 0.8829 - val_loss: 0.4667 - val_acc: 0.8000\n","\n","Epoch 00026: val_acc did not improve from 0.80000\n","Epoch 27/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.2976 - acc: 0.8937 - val_loss: 0.4659 - val_acc: 0.8000\n","\n","Epoch 00027: val_acc did not improve from 0.80000\n","Epoch 28/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.2867 - acc: 0.8996 - val_loss: 0.4836 - val_acc: 0.8222\n","\n","Epoch 00028: val_acc improved from 0.80000 to 0.82222, saving model to result/left-right/new/OUR5-362/epoch-28-val-acc-0.8222.hdf5\n","Epoch 29/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.2610 - acc: 0.9198 - val_loss: 0.4621 - val_acc: 0.8000\n","\n","Epoch 00029: val_acc did not improve from 0.82222\n","Epoch 30/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.2404 - acc: 0.9276 - val_loss: 0.4534 - val_acc: 0.8222\n","\n","Epoch 00030: val_acc did not improve from 0.82222\n","Epoch 31/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.2289 - acc: 0.9315 - val_loss: 0.4591 - val_acc: 0.8222\n","\n","Epoch 00031: val_acc did not improve from 0.82222\n","Epoch 32/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.2047 - acc: 0.9422 - val_loss: 0.4531 - val_acc: 0.8222\n","\n","Epoch 00032: val_acc did not improve from 0.82222\n","Epoch 33/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.2141 - acc: 0.9376 - val_loss: 0.4769 - val_acc: 0.7778\n","\n","Epoch 00033: val_acc did not improve from 0.82222\n","Epoch 34/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.2063 - acc: 0.9345 - val_loss: 0.5215 - val_acc: 0.7778\n","\n","Epoch 00034: val_acc did not improve from 0.82222\n","Epoch 35/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.1868 - acc: 0.9541 - val_loss: 0.4490 - val_acc: 0.8222\n","\n","Epoch 00035: val_acc did not improve from 0.82222\n","Epoch 36/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.1734 - acc: 0.9540 - val_loss: 0.4400 - val_acc: 0.8444\n","\n","Epoch 00036: val_acc improved from 0.82222 to 0.84444, saving model to result/left-right/new/OUR5-362/epoch-36-val-acc-0.8444.hdf5\n","Epoch 37/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.1626 - acc: 0.9579 - val_loss: 0.4947 - val_acc: 0.7778\n","\n","Epoch 00037: val_acc did not improve from 0.84444\n","Epoch 38/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.1476 - acc: 0.9667 - val_loss: 0.4729 - val_acc: 0.8222\n","\n","Epoch 00038: val_acc did not improve from 0.84444\n","Epoch 39/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.1379 - acc: 0.9687 - val_loss: 0.4658 - val_acc: 0.8222\n","\n","Epoch 00039: val_acc did not improve from 0.84444\n","Epoch 40/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.1377 - acc: 0.9736 - val_loss: 0.4814 - val_acc: 0.8000\n","\n","Epoch 00040: val_acc did not improve from 0.84444\n","Epoch 41/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.1336 - acc: 0.9679 - val_loss: 0.4699 - val_acc: 0.8222\n","\n","Epoch 00041: val_acc did not improve from 0.84444\n","Epoch 42/100\n","32/32 [==============================] - 1s 21ms/step - loss: 0.1352 - acc: 0.9707 - val_loss: 0.4738 - val_acc: 0.8222\n","\n","Epoch 00042: val_acc did not improve from 0.84444\n","Epoch 43/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.1121 - acc: 0.9755 - val_loss: 0.4565 - val_acc: 0.8222\n","\n","Epoch 00043: val_acc did not improve from 0.84444\n","Epoch 44/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.1015 - acc: 0.9804 - val_loss: 0.5145 - val_acc: 0.7778\n","\n","Epoch 00044: val_acc did not improve from 0.84444\n","Epoch 45/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0997 - acc: 0.9814 - val_loss: 0.5059 - val_acc: 0.8000\n","\n","Epoch 00045: val_acc did not improve from 0.84444\n","Epoch 46/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0955 - acc: 0.9863 - val_loss: 0.5046 - val_acc: 0.8222\n","\n","Epoch 00046: val_acc did not improve from 0.84444\n","Epoch 47/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0885 - acc: 0.9844 - val_loss: 0.4761 - val_acc: 0.8222\n","\n","Epoch 00047: val_acc did not improve from 0.84444\n","Epoch 48/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0812 - acc: 0.9873 - val_loss: 0.5112 - val_acc: 0.8222\n","\n","Epoch 00048: val_acc did not improve from 0.84444\n","Epoch 49/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0851 - acc: 0.9864 - val_loss: 0.4855 - val_acc: 0.8444\n","\n","Epoch 00049: val_acc did not improve from 0.84444\n","Epoch 50/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0693 - acc: 0.9883 - val_loss: 0.5064 - val_acc: 0.8222\n","\n","Epoch 00050: val_acc did not improve from 0.84444\n","Epoch 51/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.0678 - acc: 0.9892 - val_loss: 0.5024 - val_acc: 0.8000\n","\n","Epoch 00051: val_acc did not improve from 0.84444\n","Epoch 52/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.0613 - acc: 0.9951 - val_loss: 0.5160 - val_acc: 0.8222\n","\n","Epoch 00052: val_acc did not improve from 0.84444\n","Epoch 53/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.0624 - acc: 0.9912 - val_loss: 0.5202 - val_acc: 0.8222\n","\n","Epoch 00053: val_acc did not improve from 0.84444\n","Epoch 54/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0556 - acc: 0.9931 - val_loss: 0.5165 - val_acc: 0.8444\n","\n","Epoch 00054: val_acc did not improve from 0.84444\n","Epoch 55/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.0566 - acc: 0.9932 - val_loss: 0.5457 - val_acc: 0.8222\n","\n","Epoch 00055: val_acc did not improve from 0.84444\n","Epoch 56/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0456 - acc: 0.9961 - val_loss: 0.5366 - val_acc: 0.8222\n","\n","Epoch 00056: val_acc did not improve from 0.84444\n","Epoch 57/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0459 - acc: 0.9941 - val_loss: 0.5349 - val_acc: 0.7778\n","\n","Epoch 00057: val_acc did not improve from 0.84444\n","Epoch 58/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0444 - acc: 0.9971 - val_loss: 0.5015 - val_acc: 0.8444\n","\n","Epoch 00058: val_acc did not improve from 0.84444\n","Epoch 59/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0389 - acc: 0.9990 - val_loss: 0.5309 - val_acc: 0.8444\n","\n","Epoch 00059: val_acc did not improve from 0.84444\n","Epoch 60/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0452 - acc: 0.9951 - val_loss: 0.5320 - val_acc: 0.8444\n","\n","Epoch 00060: val_acc did not improve from 0.84444\n","Epoch 61/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0392 - acc: 0.9971 - val_loss: 0.5282 - val_acc: 0.8444\n","\n","Epoch 00061: val_acc did not improve from 0.84444\n","Epoch 62/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0393 - acc: 0.9971 - val_loss: 0.5440 - val_acc: 0.8444\n","\n","Epoch 00062: val_acc did not improve from 0.84444\n","Epoch 63/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0490 - acc: 0.9913 - val_loss: 0.5499 - val_acc: 0.8222\n","\n","Epoch 00063: val_acc did not improve from 0.84444\n","Epoch 64/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0409 - acc: 0.9951 - val_loss: 0.5280 - val_acc: 0.8444\n","\n","Epoch 00064: val_acc did not improve from 0.84444\n","Epoch 65/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0338 - acc: 0.9980 - val_loss: 0.5408 - val_acc: 0.8444\n","\n","Epoch 00065: val_acc did not improve from 0.84444\n","Epoch 66/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0312 - acc: 0.9951 - val_loss: 0.5455 - val_acc: 0.8222\n","\n","Epoch 00066: val_acc did not improve from 0.84444\n","Epoch 67/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.0299 - acc: 0.9980 - val_loss: 0.5656 - val_acc: 0.8444\n","\n","Epoch 00067: val_acc did not improve from 0.84444\n","Epoch 68/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.0329 - acc: 0.9980 - val_loss: 0.5564 - val_acc: 0.8222\n","\n","Epoch 00068: val_acc did not improve from 0.84444\n","Epoch 69/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0294 - acc: 1.0000 - val_loss: 0.5521 - val_acc: 0.8444\n","\n","Epoch 00069: val_acc did not improve from 0.84444\n","Epoch 70/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0237 - acc: 0.9980 - val_loss: 0.5769 - val_acc: 0.8444\n","\n","Epoch 00070: val_acc did not improve from 0.84444\n","Epoch 71/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0256 - acc: 0.9980 - val_loss: 0.5584 - val_acc: 0.8444\n","\n","Epoch 00071: val_acc did not improve from 0.84444\n","Epoch 72/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0248 - acc: 0.9961 - val_loss: 0.5539 - val_acc: 0.8444\n","\n","Epoch 00072: val_acc did not improve from 0.84444\n","Epoch 73/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.5496 - val_acc: 0.8444\n","\n","Epoch 00073: val_acc did not improve from 0.84444\n","Epoch 74/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0243 - acc: 0.9990 - val_loss: 0.6099 - val_acc: 0.7778\n","\n","Epoch 00074: val_acc did not improve from 0.84444\n","Epoch 75/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0230 - acc: 0.9980 - val_loss: 0.5916 - val_acc: 0.8667\n","\n","Epoch 00075: val_acc improved from 0.84444 to 0.86667, saving model to result/left-right/new/OUR5-362/epoch-75-val-acc-0.8667.hdf5\n","Epoch 76/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.0191 - acc: 0.9971 - val_loss: 0.6109 - val_acc: 0.8444\n","\n","Epoch 00076: val_acc did not improve from 0.86667\n","Epoch 77/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.6036 - val_acc: 0.8667\n","\n","Epoch 00077: val_acc did not improve from 0.86667\n","Epoch 78/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0247 - acc: 0.9980 - val_loss: 0.5979 - val_acc: 0.7556\n","\n","Epoch 00078: val_acc did not improve from 0.86667\n","Epoch 79/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.6179 - val_acc: 0.8222\n","\n","Epoch 00079: val_acc did not improve from 0.86667\n","Epoch 80/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.6287 - val_acc: 0.8444\n","\n","Epoch 00080: val_acc did not improve from 0.86667\n","Epoch 81/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.6009 - val_acc: 0.8667\n","\n","Epoch 00081: val_acc did not improve from 0.86667\n","Epoch 82/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.6348 - val_acc: 0.8444\n","\n","Epoch 00082: val_acc did not improve from 0.86667\n","Epoch 83/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0142 - acc: 0.9990 - val_loss: 0.5984 - val_acc: 0.8667\n","\n","Epoch 00083: val_acc did not improve from 0.86667\n","Epoch 84/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.6315 - val_acc: 0.8222\n","\n","Epoch 00084: val_acc did not improve from 0.86667\n","Epoch 85/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.6261 - val_acc: 0.8444\n","\n","Epoch 00085: val_acc did not improve from 0.86667\n","Epoch 86/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.6250 - val_acc: 0.8667\n","\n","Epoch 00086: val_acc did not improve from 0.86667\n","Epoch 87/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0133 - acc: 0.9990 - val_loss: 0.6347 - val_acc: 0.8444\n","\n","Epoch 00087: val_acc did not improve from 0.86667\n","Epoch 88/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0138 - acc: 0.9990 - val_loss: 0.6042 - val_acc: 0.8444\n","\n","Epoch 00088: val_acc did not improve from 0.86667\n","Epoch 89/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0143 - acc: 0.9980 - val_loss: 0.6332 - val_acc: 0.8222\n","\n","Epoch 00089: val_acc did not improve from 0.86667\n","Epoch 90/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.6378 - val_acc: 0.8667\n","\n","Epoch 00090: val_acc did not improve from 0.86667\n","Epoch 91/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.6400 - val_acc: 0.8667\n","\n","Epoch 00091: val_acc did not improve from 0.86667\n","Epoch 92/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0107 - acc: 0.9990 - val_loss: 0.6663 - val_acc: 0.8667\n","\n","Epoch 00092: val_acc did not improve from 0.86667\n","Epoch 93/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.6606 - val_acc: 0.8444\n","\n","Epoch 00093: val_acc did not improve from 0.86667\n","Epoch 94/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0133 - acc: 0.9980 - val_loss: 0.6736 - val_acc: 0.8667\n","\n","Epoch 00094: val_acc did not improve from 0.86667\n","Epoch 95/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.6531 - val_acc: 0.8222\n","\n","Epoch 00095: val_acc did not improve from 0.86667\n","Epoch 96/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.6786 - val_acc: 0.8222\n","\n","Epoch 00096: val_acc did not improve from 0.86667\n","Epoch 97/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.6858 - val_acc: 0.8444\n","\n","Epoch 00097: val_acc did not improve from 0.86667\n","Epoch 98/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0123 - acc: 0.9980 - val_loss: 0.7110 - val_acc: 0.8667\n","\n","Epoch 00098: val_acc did not improve from 0.86667\n","Epoch 99/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.6789 - val_acc: 0.8444\n","\n","Epoch 00099: val_acc did not improve from 0.86667\n","Epoch 100/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.7088 - val_acc: 0.7778\n","\n","Epoch 00100: val_acc did not improve from 0.86667\n","\n","<keras.callbacks.History at 0x7fe581d159e8>\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uvPbn2PZjXwv","colab_type":"code","colab":{}},"cell_type":"code","source":["#Aguamantation model\n","\n","\n","\n","\n","root='datasets/'\n","root2='result/'\n","k=k+1\n","sgd = optimizers.SGD(lr=0.01, decay=1e-3, momentum=0.9, nesterov=True)\n","model.compile(loss='mean_squared_error', optimizer=sgd)\n","\n","model.compile(loss='categorical_crossentropy', \n","              optimizer=Adam(), \n","              metrics=['accuracy'])\n","\n","datagen = ImageDataGenerator(\n","    featurewise_center=True,\n","    featurewise_std_normalization=True,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True)\n","\n","# compute quantities required for featurewise normalization\n","# (std, mean, and principal components if ZCA whitening is applied)\n","#datagen.fit(X_train)\n","\n","         \n","foldername=root2+typ+name+str(k)\n","filename=\"/epoch-{epoch:02d}-val-acc-{val_acc:.4f}.hdf5\"\n","\n","checkpoints = []\n","\n","if not os.path.exists(foldername):\n","    os.makedirs(foldername)\n","\n","checkpoints.append(ModelCheckpoint(foldername+filename, \n","                                   monitor='val_acc', \n","                                   verbose=1, \n","                                   save_best_only=True, \n","                                   save_weights_only=True, \n","                                   mode='auto',\n","                                   period=1))\n","\n","log_dir2=foldername+'/TensorBoardLogs'\n","\n","checkpoints.append(TensorBoard(log_dir2, \n","                               histogram_freq=0, \n","                               write_graph=True, \n","                               write_images=False, \n","                               embeddings_freq=0, \n","                               embeddings_layer_names=None, \n","                               embeddings_metadata=None))\n","\n","\n","# fits the model on batches with real-time data augmentation:\n","model.fit_generator(datagen.flow(X_train, Y_train, batch_size=16),\n","                    validation_data=(X_test, Y_test),\n","                    validation_steps=16,\n","                    callbacks=checkpoints,\n","                    steps_per_epoch=len(X_train) / 16, epochs=100)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XkSH1b5SmrYf","colab_type":"code","outputId":"15ef5496-b09f-4e0d-846b-1202850f70e7","executionInfo":{"status":"ok","timestamp":1539870914866,"user_tz":-180,"elapsed":692,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["foldername\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'result/intersection/OUR6-112'"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"DXaoZm0kdgjf","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title\n","import tensorflow as tf\n","tf.test.gpu_device_name()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DzRmfRV9epvw","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title\n","# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"obATPi_-hJEy","colab_type":"code","cellView":"both","colab":{}},"cell_type":"code","source":["#@title\n","!kill -9 -1 #sıfırlama"],"execution_count":0,"outputs":[]},{"metadata":{"id":"27wG0S-_jUvR","colab_type":"code","cellView":"both","colab":{}},"cell_type":"code","source":["#@title\n","#@title\n","!kill -9 -1 #sıfırlama\n","import tensorflow as tf\n","tf.nn.sigmoid_cross_entropy_with_logits?"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wI0PqAqeuI-K","colab_type":"code","colab":{}},"cell_type":"code","source":["foldername='result/intersection/OUR6-60'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u5JgfqJUkAHX","colab_type":"code","cellView":"both","colab":{}},"cell_type":"code","source":["#@title\n","\n","log_dir2=foldername+'/TensorBoardLogs'\n","LOG_DIR = log_dir2\n","\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip\n","\n","import os\n","if not os.path.exists(LOG_DIR):\n","  os.makedirs(LOG_DIR)\n","  \n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR))\n","\n","get_ipython().system_raw('./ngrok http 6006 &')\n","\n","!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"R8rDZy8tbCD2","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Default title text\n","# TRAINING THE MODEL\n","model.fit_generator(train_generator, \n","                    steps_per_epoch=32, \n","                    epochs=10, \n","                    validation_data=(X_val, Y_val),\n","                    validation_steps=32,\n","                    callbacks=checkpoints)#callbacks_list yerine checkpoints"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wzDJb6HuEvYl","colab_type":"code","outputId":"5df99f3f-d5b9-433f-d779-c240a3ed49c4","executionInfo":{"status":"ok","timestamp":1540200051549,"user_tz":-180,"elapsed":3616,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["Y_val.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(126, 5)"]},"metadata":{"tags":[]},"execution_count":46}]},{"metadata":{"id":"4p4wDZmqDJqg","colab_type":"code","colab":{}},"cell_type":"code","source":["# five vgg 75-15-15 75.39\n","\n","\n","\n","Epoch 1/100\n","64/64 [==============================] - 4s 62ms/step - loss: 1.4776 - acc: 0.3760 - val_loss: 1.3027 - val_acc: 0.4286\n","\n","Epoch 00001: val_acc improved from -inf to 0.42857, saving model to result/all/five/data_70_15_15/VGG5-17/epoch-01-val-acc-0.4286.hdf5\n","Epoch 2/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.8591 - acc: 0.6953 - val_loss: 0.9374 - val_acc: 0.6429\n","\n","Epoch 00002: val_acc improved from 0.42857 to 0.64286, saving model to result/all/five/data_70_15_15/VGG5-17/epoch-02-val-acc-0.6429.hdf5\n","Epoch 3/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.4092 - acc: 0.8677 - val_loss: 1.1732 - val_acc: 0.6111\n","\n","Epoch 00003: val_acc did not improve from 0.64286\n","Epoch 4/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.1730 - acc: 0.9557 - val_loss: 1.1877 - val_acc: 0.7063\n","\n","Epoch 00004: val_acc improved from 0.64286 to 0.70635, saving model to result/all/five/data_70_15_15/VGG5-17/epoch-04-val-acc-0.7063.hdf5\n","Epoch 5/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0818 - acc: 0.9834 - val_loss: 1.2020 - val_acc: 0.7222\n","\n","Epoch 00005: val_acc improved from 0.70635 to 0.72222, saving model to result/all/five/data_70_15_15/VGG5-17/epoch-05-val-acc-0.7222.hdf5\n","Epoch 6/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0421 - acc: 0.9902 - val_loss: 1.6125 - val_acc: 0.6508\n","\n","Epoch 00006: val_acc did not improve from 0.72222\n","Epoch 7/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0256 - acc: 0.9941 - val_loss: 1.3925 - val_acc: 0.7302\n","\n","Epoch 00007: val_acc improved from 0.72222 to 0.73016, saving model to result/all/five/data_70_15_15/VGG5-17/epoch-07-val-acc-0.7302.hdf5\n","Epoch 8/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0104 - acc: 0.9988 - val_loss: 1.5324 - val_acc: 0.7381\n","\n","Epoch 00008: val_acc improved from 0.73016 to 0.73810, saving model to result/all/five/data_70_15_15/VGG5-17/epoch-08-val-acc-0.7381.hdf5\n","Epoch 9/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0108 - acc: 0.9971 - val_loss: 1.6067 - val_acc: 0.6984\n","\n","Epoch 00009: val_acc did not improve from 0.73810\n","Epoch 10/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0062 - acc: 0.9993 - val_loss: 1.6596 - val_acc: 0.7302\n","\n","Epoch 00010: val_acc did not improve from 0.73810\n","Epoch 11/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0051 - acc: 0.9995 - val_loss: 1.7039 - val_acc: 0.7302\n","\n","Epoch 00011: val_acc did not improve from 0.73810\n","Epoch 12/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0070 - acc: 0.9985 - val_loss: 1.6069 - val_acc: 0.7460\n","\n","Epoch 00012: val_acc improved from 0.73810 to 0.74603, saving model to result/all/five/data_70_15_15/VGG5-17/epoch-12-val-acc-0.7460.hdf5\n","Epoch 13/100\n","64/64 [==============================] - 3s 48ms/step - loss: 0.0036 - acc: 0.9995 - val_loss: 1.7566 - val_acc: 0.7540\n","\n","Epoch 00013: val_acc improved from 0.74603 to 0.75397, saving model to result/all/five/data_70_15_15/VGG5-17/epoch-13-val-acc-0.7540.hdf5\n","Epoch 14/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0042 - acc: 0.9995 - val_loss: 1.6784 - val_acc: 0.7460\n","\n","Epoch 00014: val_acc did not improve from 0.75397\n","Epoch 15/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.8216 - val_acc: 0.7302\n","\n","Epoch 00015: val_acc did not improve from 0.75397\n","Epoch 16/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0054 - acc: 0.9990 - val_loss: 1.8001 - val_acc: 0.7302\n","\n","Epoch 00016: val_acc did not improve from 0.75397\n","Epoch 17/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0036 - acc: 0.9995 - val_loss: 1.8328 - val_acc: 0.7143\n","\n","Epoch 00017: val_acc did not improve from 0.75397\n","Epoch 18/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.8334 - val_acc: 0.7460\n","\n","Epoch 00018: val_acc did not improve from 0.75397\n","Epoch 19/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 1.8072 - val_acc: 0.7063\n","\n","Epoch 00019: val_acc did not improve from 0.75397\n","Epoch 20/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0045 - acc: 0.9995 - val_loss: 1.9475 - val_acc: 0.7222\n","\n","Epoch 00020: val_acc did not improve from 0.75397\n","Epoch 21/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0050 - acc: 0.9993 - val_loss: 1.7429 - val_acc: 0.7143\n","\n","Epoch 00021: val_acc did not improve from 0.75397\n","Epoch 22/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0066 - acc: 0.9990 - val_loss: 1.7526 - val_acc: 0.6984\n","\n","Epoch 00022: val_acc did not improve from 0.75397\n","Epoch 23/100\n","64/64 [==============================] - 3s 49ms/step - loss: 0.0401 - acc: 0.9900 - val_loss: 1.9397 - val_acc: 0.6746\n","\n","Epoch 00023: val_acc did not improve from 0.75397\n","Epoch 24/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0169 - acc: 0.9958 - val_loss: 1.8389 - val_acc: 0.7143\n","\n","Epoch 00024: val_acc did not improve from 0.75397\n","Epoch 25/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.9345 - val_acc: 0.7063\n","\n","Epoch 00025: val_acc did not improve from 0.75397\n","Epoch 26/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0022 - acc: 0.9993 - val_loss: 2.0575 - val_acc: 0.7063\n","\n","Epoch 00026: val_acc did not improve from 0.75397\n","Epoch 27/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0039 - acc: 0.9993 - val_loss: 2.0580 - val_acc: 0.6825\n","\n","Epoch 00027: val_acc did not improve from 0.75397\n","Epoch 28/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0042 - acc: 0.9993 - val_loss: 2.0268 - val_acc: 0.6905\n","\n","Epoch 00028: val_acc did not improve from 0.75397\n","Epoch 29/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0025 - acc: 0.9993 - val_loss: 2.0016 - val_acc: 0.6984\n","\n","Epoch 00029: val_acc did not improve from 0.75397\n","Epoch 30/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.1489 - val_acc: 0.7143\n","\n","Epoch 00030: val_acc did not improve from 0.75397\n","Epoch 31/100\n","64/64 [==============================] - 3s 46ms/step - loss: 6.7256e-04 - acc: 1.0000 - val_loss: 2.1893 - val_acc: 0.7063\n","\n","Epoch 00031: val_acc did not improve from 0.75397\n","Epoch 32/100\n","64/64 [==============================] - 3s 46ms/step - loss: 5.0511e-04 - acc: 1.0000 - val_loss: 2.2490 - val_acc: 0.7063\n","\n","Epoch 00032: val_acc did not improve from 0.75397\n","Epoch 33/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0020 - acc: 0.9993 - val_loss: 2.1328 - val_acc: 0.6746\n","\n","Epoch 00033: val_acc did not improve from 0.75397\n","Epoch 34/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.1486 - val_acc: 0.6984\n","\n","Epoch 00034: val_acc did not improve from 0.75397\n","Epoch 35/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0017 - acc: 0.9995 - val_loss: 2.1414 - val_acc: 0.7222\n","\n","Epoch 00035: val_acc did not improve from 0.75397\n","Epoch 36/100\n","64/64 [==============================] - 3s 47ms/step - loss: 7.3894e-04 - acc: 1.0000 - val_loss: 2.2839 - val_acc: 0.7302\n","\n","Epoch 00036: val_acc did not improve from 0.75397\n","Epoch 37/100\n","64/64 [==============================] - 3s 45ms/step - loss: 5.2404e-04 - acc: 1.0000 - val_loss: 2.4964 - val_acc: 0.6825\n","\n","Epoch 00037: val_acc did not improve from 0.75397\n","Epoch 38/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0051 - acc: 0.9988 - val_loss: 1.6510 - val_acc: 0.6984\n","\n","Epoch 00038: val_acc did not improve from 0.75397\n","Epoch 39/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0032 - acc: 0.9990 - val_loss: 2.1033 - val_acc: 0.6984\n","\n","Epoch 00039: val_acc did not improve from 0.75397\n","Epoch 40/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.0199 - val_acc: 0.7302\n","\n","Epoch 00040: val_acc did not improve from 0.75397\n","Epoch 41/100\n","64/64 [==============================] - 3s 46ms/step - loss: 7.1681e-04 - acc: 1.0000 - val_loss: 2.1082 - val_acc: 0.7302\n","\n","Epoch 00041: val_acc did not improve from 0.75397\n","Epoch 42/100\n","64/64 [==============================] - 3s 46ms/step - loss: 4.7406e-04 - acc: 1.0000 - val_loss: 2.2127 - val_acc: 0.7143\n","\n","Epoch 00042: val_acc did not improve from 0.75397\n","Epoch 43/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0010 - acc: 0.9998 - val_loss: 2.1575 - val_acc: 0.7143\n","\n","Epoch 00043: val_acc did not improve from 0.75397\n","Epoch 44/100\n","64/64 [==============================] - 3s 47ms/step - loss: 4.1577e-04 - acc: 1.0000 - val_loss: 2.2867 - val_acc: 0.7302\n","\n","Epoch 00044: val_acc did not improve from 0.75397\n","Epoch 45/100\n","64/64 [==============================] - 3s 45ms/step - loss: 5.8186e-04 - acc: 1.0000 - val_loss: 2.2850 - val_acc: 0.7302\n","\n","Epoch 00045: val_acc did not improve from 0.75397\n","Epoch 46/100\n","64/64 [==============================] - 3s 46ms/step - loss: 2.3184e-04 - acc: 1.0000 - val_loss: 2.2826 - val_acc: 0.7381\n","\n","Epoch 00046: val_acc did not improve from 0.75397\n","Epoch 47/100\n","64/64 [==============================] - 3s 46ms/step - loss: 4.6723e-04 - acc: 1.0000 - val_loss: 2.3513 - val_acc: 0.7143\n","\n","Epoch 00047: val_acc did not improve from 0.75397\n","Epoch 48/100\n","64/64 [==============================] - 3s 45ms/step - loss: 5.9748e-04 - acc: 0.9998 - val_loss: 2.1459 - val_acc: 0.7540\n","\n","Epoch 00048: val_acc did not improve from 0.75397\n","Epoch 49/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0102 - acc: 0.9966 - val_loss: 2.1475 - val_acc: 0.6349\n","\n","Epoch 00049: val_acc did not improve from 0.75397\n","Epoch 50/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0059 - acc: 0.9988 - val_loss: 2.0461 - val_acc: 0.6746\n","\n","Epoch 00050: val_acc did not improve from 0.75397\n","Epoch 51/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0045 - acc: 0.9988 - val_loss: 2.2366 - val_acc: 0.6825\n","\n","Epoch 00051: val_acc did not improve from 0.75397\n","Epoch 52/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0058 - acc: 0.9985 - val_loss: 2.0486 - val_acc: 0.7302\n","\n","Epoch 00052: val_acc did not improve from 0.75397\n","Epoch 53/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0012 - acc: 0.9998 - val_loss: 2.2619 - val_acc: 0.6905\n","\n","Epoch 00053: val_acc did not improve from 0.75397\n","Epoch 54/100\n","64/64 [==============================] - 3s 45ms/step - loss: 8.9517e-04 - acc: 1.0000 - val_loss: 2.3958 - val_acc: 0.7063\n","\n","Epoch 00054: val_acc did not improve from 0.75397\n","Epoch 55/100\n","64/64 [==============================] - 3s 45ms/step - loss: 2.4456e-04 - acc: 1.0000 - val_loss: 2.3813 - val_acc: 0.7063\n","\n","Epoch 00055: val_acc did not improve from 0.75397\n","Epoch 56/100\n","64/64 [==============================] - 3s 46ms/step - loss: 1.0932e-04 - acc: 1.0000 - val_loss: 2.4863 - val_acc: 0.7063\n","\n","Epoch 00056: val_acc did not improve from 0.75397\n","Epoch 57/100\n","64/64 [==============================] - 3s 45ms/step - loss: 7.7448e-05 - acc: 1.0000 - val_loss: 2.5509 - val_acc: 0.6984\n","\n","Epoch 00057: val_acc did not improve from 0.75397\n","Epoch 58/100\n","64/64 [==============================] - 3s 45ms/step - loss: 1.8354e-04 - acc: 1.0000 - val_loss: 2.5825 - val_acc: 0.6905\n","\n","Epoch 00058: val_acc did not improve from 0.75397\n","Epoch 59/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 2.3458 - val_acc: 0.6905\n","\n","Epoch 00059: val_acc did not improve from 0.75397\n","Epoch 60/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0029 - acc: 0.9990 - val_loss: 2.1729 - val_acc: 0.7143\n","\n","Epoch 00060: val_acc did not improve from 0.75397\n","Epoch 61/100\n","64/64 [==============================] - 3s 46ms/step - loss: 6.8205e-04 - acc: 1.0000 - val_loss: 2.3845 - val_acc: 0.7143\n","\n","Epoch 00061: val_acc did not improve from 0.75397\n","Epoch 62/100\n","64/64 [==============================] - 3s 45ms/step - loss: 6.6862e-04 - acc: 0.9998 - val_loss: 2.5366 - val_acc: 0.7063\n","\n","Epoch 00062: val_acc did not improve from 0.75397\n","Epoch 63/100\n","64/64 [==============================] - 3s 45ms/step - loss: 1.5274e-04 - acc: 1.0000 - val_loss: 2.6545 - val_acc: 0.6984\n","\n","Epoch 00063: val_acc did not improve from 0.75397\n","Epoch 64/100\n","64/64 [==============================] - 3s 46ms/step - loss: 4.4522e-04 - acc: 0.9998 - val_loss: 2.7115 - val_acc: 0.6825\n","\n","Epoch 00064: val_acc did not improve from 0.75397\n","Epoch 65/100\n","64/64 [==============================] - 3s 45ms/step - loss: 5.6102e-04 - acc: 1.0000 - val_loss: 2.7855 - val_acc: 0.6984\n","\n","Epoch 00065: val_acc did not improve from 0.75397\n","Epoch 66/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 3.4290 - val_acc: 0.6587\n","\n","Epoch 00066: val_acc did not improve from 0.75397\n","Epoch 67/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0048 - acc: 0.9988 - val_loss: 2.4505 - val_acc: 0.6746\n","\n","Epoch 00067: val_acc did not improve from 0.75397\n","Epoch 68/100\n","64/64 [==============================] - 3s 45ms/step - loss: 6.7884e-04 - acc: 1.0000 - val_loss: 2.5982 - val_acc: 0.6746\n","\n","Epoch 00068: val_acc did not improve from 0.75397\n","Epoch 69/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0049 - acc: 0.9978 - val_loss: 2.3084 - val_acc: 0.6825\n","\n","Epoch 00069: val_acc did not improve from 0.75397\n","Epoch 70/100\n","64/64 [==============================] - 3s 47ms/step - loss: 8.4986e-04 - acc: 1.0000 - val_loss: 2.5266 - val_acc: 0.7063\n","\n","Epoch 00070: val_acc did not improve from 0.75397\n","Epoch 71/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0040 - acc: 0.9993 - val_loss: 2.5827 - val_acc: 0.6746\n","\n","Epoch 00071: val_acc did not improve from 0.75397\n","Epoch 72/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 2.4731 - val_acc: 0.6508\n","\n","Epoch 00072: val_acc did not improve from 0.75397\n","Epoch 73/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 2.1955 - val_acc: 0.6667\n","\n","Epoch 00073: val_acc did not improve from 0.75397\n","Epoch 74/100\n","64/64 [==============================] - 3s 46ms/step - loss: 9.3439e-04 - acc: 0.9995 - val_loss: 2.3638 - val_acc: 0.6587\n","\n","Epoch 00074: val_acc did not improve from 0.75397\n","Epoch 75/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0012 - acc: 0.9995 - val_loss: 2.3757 - val_acc: 0.7143\n","\n","Epoch 00075: val_acc did not improve from 0.75397\n","Epoch 76/100\n","64/64 [==============================] - 3s 45ms/step - loss: 5.6460e-04 - acc: 1.0000 - val_loss: 2.4419 - val_acc: 0.7143\n","\n","Epoch 00076: val_acc did not improve from 0.75397\n","Epoch 77/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0170 - acc: 0.9936 - val_loss: 2.2524 - val_acc: 0.6587\n","\n","Epoch 00077: val_acc did not improve from 0.75397\n","Epoch 78/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0050 - acc: 0.9988 - val_loss: 2.3093 - val_acc: 0.6667\n","\n","Epoch 00078: val_acc did not improve from 0.75397\n","Epoch 79/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0039 - acc: 0.9980 - val_loss: 2.4869 - val_acc: 0.6111\n","\n","Epoch 00079: val_acc did not improve from 0.75397\n","Epoch 80/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 2.7198 - val_acc: 0.6349\n","\n","Epoch 00080: val_acc did not improve from 0.75397\n","Epoch 81/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0186 - acc: 0.9905 - val_loss: 2.9254 - val_acc: 0.6429\n","\n","Epoch 00081: val_acc did not improve from 0.75397\n","Epoch 82/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0032 - acc: 0.9990 - val_loss: 2.6504 - val_acc: 0.6667\n","\n","Epoch 00082: val_acc did not improve from 0.75397\n","Epoch 83/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0037 - acc: 0.9990 - val_loss: 2.7270 - val_acc: 0.6349\n","\n","Epoch 00083: val_acc did not improve from 0.75397\n","Epoch 84/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0018 - acc: 0.9998 - val_loss: 2.6812 - val_acc: 0.6587\n","\n","Epoch 00084: val_acc did not improve from 0.75397\n","Epoch 85/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0010 - acc: 0.9998 - val_loss: 2.6551 - val_acc: 0.6746\n","\n","Epoch 00085: val_acc did not improve from 0.75397\n","Epoch 86/100\n","64/64 [==============================] - 3s 45ms/step - loss: 2.2624e-04 - acc: 1.0000 - val_loss: 2.7241 - val_acc: 0.6905\n","\n","Epoch 00086: val_acc did not improve from 0.75397\n","Epoch 87/100\n","64/64 [==============================] - 3s 47ms/step - loss: 8.0100e-05 - acc: 1.0000 - val_loss: 2.7617 - val_acc: 0.6905\n","\n","Epoch 00087: val_acc did not improve from 0.75397\n","Epoch 88/100\n","64/64 [==============================] - 3s 46ms/step - loss: 3.2103e-04 - acc: 1.0000 - val_loss: 2.7675 - val_acc: 0.6667\n","\n","Epoch 00088: val_acc did not improve from 0.75397\n","Epoch 89/100\n","64/64 [==============================] - 3s 45ms/step - loss: 3.6263e-04 - acc: 0.9998 - val_loss: 2.8951 - val_acc: 0.6349\n","\n","Epoch 00089: val_acc did not improve from 0.75397\n","Epoch 90/100\n","64/64 [==============================] - 3s 45ms/step - loss: 2.4676e-04 - acc: 1.0000 - val_loss: 2.8634 - val_acc: 0.6905\n","\n","Epoch 00090: val_acc did not improve from 0.75397\n","Epoch 91/100\n","64/64 [==============================] - 3s 45ms/step - loss: 1.2215e-04 - acc: 1.0000 - val_loss: 2.9568 - val_acc: 0.6984\n","\n","Epoch 00091: val_acc did not improve from 0.75397\n","Epoch 92/100\n","64/64 [==============================] - 3s 45ms/step - loss: 1.7740e-04 - acc: 1.0000 - val_loss: 2.9778 - val_acc: 0.6825\n","\n","Epoch 00092: val_acc did not improve from 0.75397\n","Epoch 93/100\n","64/64 [==============================] - 3s 45ms/step - loss: 1.0822e-04 - acc: 1.0000 - val_loss: 2.9622 - val_acc: 0.6429\n","\n","Epoch 00093: val_acc did not improve from 0.75397\n","Epoch 94/100\n","64/64 [==============================] - 3s 45ms/step - loss: 8.1295e-05 - acc: 1.0000 - val_loss: 2.9529 - val_acc: 0.6508\n","\n","Epoch 00094: val_acc did not improve from 0.75397\n","Epoch 95/100\n","64/64 [==============================] - 3s 45ms/step - loss: 8.3057e-05 - acc: 1.0000 - val_loss: 2.9986 - val_acc: 0.6587\n","\n","Epoch 00095: val_acc did not improve from 0.75397\n","Epoch 96/100\n","64/64 [==============================] - 3s 46ms/step - loss: 1.1791e-04 - acc: 1.0000 - val_loss: 2.9223 - val_acc: 0.6587\n","\n","Epoch 00096: val_acc did not improve from 0.75397\n","Epoch 97/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0017 - acc: 0.9993 - val_loss: 2.9537 - val_acc: 0.6270\n","\n","Epoch 00097: val_acc did not improve from 0.75397\n","Epoch 98/100\n","64/64 [==============================] - 3s 46ms/step - loss: 8.3711e-04 - acc: 0.9998 - val_loss: 2.8869 - val_acc: 0.6746\n","\n","Epoch 00098: val_acc did not improve from 0.75397\n","Epoch 99/100\n","64/64 [==============================] - 3s 45ms/step - loss: 2.2374e-04 - acc: 1.0000 - val_loss: 2.9719 - val_acc: 0.6587\n","\n","Epoch 00099: val_acc did not improve from 0.75397\n","Epoch 100/100\n","64/64 [==============================] - 3s 45ms/step - loss: 9.3827e-05 - acc: 1.0000 - val_loss: 2.8449 - val_acc: 0.6667\n","\n","Epoch 00100: val_acc did not improve from 0.75397\n","\n","<keras.callbacks.History at 0x7ff3f69ba2e8>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LkLyBLJ_-2Kq","colab_type":"code","colab":{}},"cell_type":"code","source":["#five all 70-15-15 76.98\n","\n","Epoch 1/100\n","64/64 [==============================] - 4s 59ms/step - loss: 1.5705 - acc: 0.2592 - val_loss: 1.6054 - val_acc: 0.2381\n","\n","Epoch 00001: val_acc improved from -inf to 0.23810, saving model to result/all/five/data_70_15_15/OUR-1-14/epoch-01-val-acc-0.2381.hdf5\n","Epoch 2/100\n","64/64 [==============================] - 3s 44ms/step - loss: 1.5578 - acc: 0.2771 - val_loss: 1.5110 - val_acc: 0.2540\n","\n","Epoch 00002: val_acc improved from 0.23810 to 0.25397, saving model to result/all/five/data_70_15_15/OUR-1-14/epoch-02-val-acc-0.2540.hdf5\n","Epoch 3/100\n","64/64 [==============================] - 3s 41ms/step - loss: 1.4293 - acc: 0.3912 - val_loss: 1.3260 - val_acc: 0.5238\n","\n","Epoch 00003: val_acc improved from 0.25397 to 0.52381, saving model to result/all/five/data_70_15_15/OUR-1-14/epoch-03-val-acc-0.5238.hdf5\n","Epoch 4/100\n","64/64 [==============================] - 3s 42ms/step - loss: 1.0962 - acc: 0.5906 - val_loss: 1.1973 - val_acc: 0.5397\n","\n","Epoch 00004: val_acc improved from 0.52381 to 0.53968, saving model to result/all/five/data_70_15_15/OUR-1-14/epoch-04-val-acc-0.5397.hdf5\n","Epoch 5/100\n","64/64 [==============================] - 3s 42ms/step - loss: 0.6990 - acc: 0.7455 - val_loss: 1.0203 - val_acc: 0.6270\n","\n","Epoch 00005: val_acc improved from 0.53968 to 0.62698, saving model to result/all/five/data_70_15_15/OUR-1-14/epoch-05-val-acc-0.6270.hdf5\n","Epoch 6/100\n","64/64 [==============================] - 3s 41ms/step - loss: 0.3289 - acc: 0.8731 - val_loss: 1.3373 - val_acc: 0.6984\n","\n","Epoch 00006: val_acc improved from 0.62698 to 0.69841, saving model to result/all/five/data_70_15_15/OUR-1-14/epoch-06-val-acc-0.6984.hdf5\n","Epoch 7/100\n","64/64 [==============================] - 3s 42ms/step - loss: 0.2002 - acc: 0.9257 - val_loss: 1.3044 - val_acc: 0.7381\n","\n","Epoch 00007: val_acc improved from 0.69841 to 0.73810, saving model to result/all/five/data_70_15_15/OUR-1-14/epoch-07-val-acc-0.7381.hdf5\n","Epoch 8/100\n","64/64 [==============================] - 3s 43ms/step - loss: 0.0635 - acc: 0.9800 - val_loss: 1.9065 - val_acc: 0.6905\n","\n","Epoch 00008: val_acc did not improve from 0.73810\n","Epoch 9/100\n","64/64 [==============================] - 3s 41ms/step - loss: 0.0747 - acc: 0.9738 - val_loss: 1.5297 - val_acc: 0.7460\n","\n","Epoch 00009: val_acc improved from 0.73810 to 0.74603, saving model to result/all/five/data_70_15_15/OUR-1-14/epoch-09-val-acc-0.7460.hdf5\n","Epoch 10/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.8208 - val_acc: 0.7381\n","\n","Epoch 00010: val_acc did not improve from 0.74603\n","Epoch 11/100\n","64/64 [==============================] - 3s 44ms/step - loss: 2.5509e-04 - acc: 1.0000 - val_loss: 1.8627 - val_acc: 0.7302\n","\n","Epoch 00011: val_acc did not improve from 0.74603\n","Epoch 12/100\n","64/64 [==============================] - 3s 42ms/step - loss: 1.3829e-04 - acc: 1.0000 - val_loss: 1.9108 - val_acc: 0.7302\n","\n","Epoch 00012: val_acc did not improve from 0.74603\n","Epoch 13/100\n","64/64 [==============================] - 3s 42ms/step - loss: 8.5447e-05 - acc: 1.0000 - val_loss: 1.9844 - val_acc: 0.7222\n","\n","Epoch 00013: val_acc did not improve from 0.74603\n","Epoch 14/100\n","64/64 [==============================] - 3s 41ms/step - loss: 5.2587e-05 - acc: 1.0000 - val_loss: 1.9795 - val_acc: 0.7460\n","\n","Epoch 00014: val_acc improved from 0.74603 to 0.74603, saving model to result/all/five/data_70_15_15/OUR-1-14/epoch-14-val-acc-0.7460.hdf5\n","Epoch 15/100\n","64/64 [==============================] - 3s 42ms/step - loss: 3.5717e-05 - acc: 1.0000 - val_loss: 2.0243 - val_acc: 0.7460\n","\n","Epoch 00015: val_acc did not improve from 0.74603\n","Epoch 16/100\n","64/64 [==============================] - 3s 42ms/step - loss: 2.6271e-05 - acc: 1.0000 - val_loss: 2.0152 - val_acc: 0.7302\n","\n","Epoch 00016: val_acc did not improve from 0.74603\n","Epoch 17/100\n","64/64 [==============================] - 3s 42ms/step - loss: 2.1098e-05 - acc: 1.0000 - val_loss: 2.0449 - val_acc: 0.7381\n","\n","Epoch 00017: val_acc did not improve from 0.74603\n","Epoch 18/100\n","64/64 [==============================] - 3s 42ms/step - loss: 1.7451e-05 - acc: 1.0000 - val_loss: 2.0571 - val_acc: 0.7381\n","\n","Epoch 00018: val_acc did not improve from 0.74603\n","Epoch 19/100\n","64/64 [==============================] - 3s 41ms/step - loss: 1.4156e-05 - acc: 1.0000 - val_loss: 2.0579 - val_acc: 0.7460\n","\n","Epoch 00019: val_acc improved from 0.74603 to 0.74603, saving model to result/all/five/data_70_15_15/OUR-1-14/epoch-19-val-acc-0.7460.hdf5\n","Epoch 20/100\n","64/64 [==============================] - 3s 43ms/step - loss: 1.2046e-05 - acc: 1.0000 - val_loss: 2.0622 - val_acc: 0.7460\n","\n","Epoch 00020: val_acc did not improve from 0.74603\n","Epoch 21/100\n","64/64 [==============================] - 3s 41ms/step - loss: 1.0019e-05 - acc: 1.0000 - val_loss: 2.0777 - val_acc: 0.7460\n","\n","Epoch 00021: val_acc did not improve from 0.74603\n","Epoch 22/100\n","64/64 [==============================] - 3s 42ms/step - loss: 8.9896e-06 - acc: 1.0000 - val_loss: 2.0850 - val_acc: 0.7381\n","\n","Epoch 00022: val_acc did not improve from 0.74603\n","Epoch 23/100\n","64/64 [==============================] - 3s 43ms/step - loss: 7.3304e-06 - acc: 1.0000 - val_loss: 2.0973 - val_acc: 0.7381\n","\n","Epoch 00023: val_acc did not improve from 0.74603\n","Epoch 24/100\n","64/64 [==============================] - 3s 42ms/step - loss: 7.0002e-06 - acc: 1.0000 - val_loss: 2.0934 - val_acc: 0.7460\n","\n","Epoch 00024: val_acc did not improve from 0.74603\n","Epoch 25/100\n","64/64 [==============================] - 3s 42ms/step - loss: 5.7196e-06 - acc: 1.0000 - val_loss: 2.1211 - val_acc: 0.7381\n","\n","Epoch 00025: val_acc did not improve from 0.74603\n","Epoch 26/100\n","64/64 [==============================] - 3s 42ms/step - loss: 5.3073e-06 - acc: 1.0000 - val_loss: 2.1343 - val_acc: 0.7381\n","\n","Epoch 00026: val_acc did not improve from 0.74603\n","Epoch 27/100\n","64/64 [==============================] - 3s 42ms/step - loss: 4.5096e-06 - acc: 1.0000 - val_loss: 2.1631 - val_acc: 0.7381\n","\n","Epoch 00027: val_acc did not improve from 0.74603\n","Epoch 28/100\n","64/64 [==============================] - 3s 43ms/step - loss: 4.1077e-06 - acc: 1.0000 - val_loss: 2.1505 - val_acc: 0.7460\n","\n","Epoch 00028: val_acc did not improve from 0.74603\n","Epoch 29/100\n","64/64 [==============================] - 3s 41ms/step - loss: 3.9274e-06 - acc: 1.0000 - val_loss: 2.1708 - val_acc: 0.7460\n","\n","Epoch 00029: val_acc did not improve from 0.74603\n","Epoch 30/100\n","64/64 [==============================] - 3s 42ms/step - loss: 3.2080e-06 - acc: 1.0000 - val_loss: 2.1696 - val_acc: 0.7381\n","\n","Epoch 00030: val_acc did not improve from 0.74603\n","Epoch 31/100\n","64/64 [==============================] - 3s 42ms/step - loss: 2.9978e-06 - acc: 1.0000 - val_loss: 2.1878 - val_acc: 0.7381\n","\n","Epoch 00031: val_acc did not improve from 0.74603\n","Epoch 32/100\n","64/64 [==============================] - 3s 42ms/step - loss: 2.9498e-06 - acc: 1.0000 - val_loss: 2.1954 - val_acc: 0.7381\n","\n","Epoch 00032: val_acc did not improve from 0.74603\n","Epoch 33/100\n","64/64 [==============================] - 3s 42ms/step - loss: 2.5974e-06 - acc: 1.0000 - val_loss: 2.1960 - val_acc: 0.7381\n","\n","Epoch 00033: val_acc did not improve from 0.74603\n","Epoch 34/100\n","64/64 [==============================] - 3s 42ms/step - loss: 2.3004e-06 - acc: 1.0000 - val_loss: 2.2060 - val_acc: 0.7381\n","\n","Epoch 00034: val_acc did not improve from 0.74603\n","Epoch 35/100\n","64/64 [==============================] - 3s 43ms/step - loss: 2.3272e-06 - acc: 1.0000 - val_loss: 2.2179 - val_acc: 0.7302\n","\n","Epoch 00035: val_acc did not improve from 0.74603\n","Epoch 36/100\n","64/64 [==============================] - 3s 41ms/step - loss: 2.0692e-06 - acc: 1.0000 - val_loss: 2.2084 - val_acc: 0.7460\n","\n","Epoch 00036: val_acc did not improve from 0.74603\n","Epoch 37/100\n","64/64 [==============================] - 3s 42ms/step - loss: 1.9304e-06 - acc: 1.0000 - val_loss: 2.2147 - val_acc: 0.7460\n","\n","Epoch 00037: val_acc did not improve from 0.74603\n","Epoch 38/100\n","64/64 [==============================] - 3s 43ms/step - loss: 1.7698e-06 - acc: 1.0000 - val_loss: 2.2308 - val_acc: 0.7381\n","\n","Epoch 00038: val_acc did not improve from 0.74603\n","Epoch 39/100\n","64/64 [==============================] - 3s 42ms/step - loss: 1.7090e-06 - acc: 1.0000 - val_loss: 2.2259 - val_acc: 0.7460\n","\n","Epoch 00039: val_acc did not improve from 0.74603\n","Epoch 40/100\n","64/64 [==============================] - 3s 42ms/step - loss: 1.5179e-06 - acc: 1.0000 - val_loss: 2.2263 - val_acc: 0.7460\n","\n","Epoch 00040: val_acc did not improve from 0.74603\n","Epoch 41/100\n","64/64 [==============================] - 3s 43ms/step - loss: 1.5174e-06 - acc: 1.0000 - val_loss: 2.2375 - val_acc: 0.7540\n","\n","Epoch 00041: val_acc improved from 0.74603 to 0.75397, saving model to result/all/five/data_70_15_15/OUR-1-14/epoch-41-val-acc-0.7540.hdf5\n","Epoch 42/100\n","64/64 [==============================] - 3s 42ms/step - loss: 1.4185e-06 - acc: 1.0000 - val_loss: 2.2473 - val_acc: 0.7619\n","\n","Epoch 00042: val_acc improved from 0.75397 to 0.76190, saving model to result/all/five/data_70_15_15/OUR-1-14/epoch-42-val-acc-0.7619.hdf5\n","Epoch 43/100\n","64/64 [==============================] - 3s 42ms/step - loss: 1.2518e-06 - acc: 1.0000 - val_loss: 2.2475 - val_acc: 0.7540\n","\n","Epoch 00043: val_acc did not improve from 0.76190\n","Epoch 44/100\n","64/64 [==============================] - 3s 44ms/step - loss: 1.1955e-06 - acc: 1.0000 - val_loss: 2.2464 - val_acc: 0.7540\n","\n","Epoch 00044: val_acc did not improve from 0.76190\n","Epoch 45/100\n","64/64 [==============================] - 3s 41ms/step - loss: 1.1302e-06 - acc: 1.0000 - val_loss: 2.2523 - val_acc: 0.7540\n","\n","Epoch 00045: val_acc did not improve from 0.76190\n","Epoch 46/100\n","64/64 [==============================] - 3s 42ms/step - loss: 1.0739e-06 - acc: 1.0000 - val_loss: 2.2597 - val_acc: 0.7460\n","\n","Epoch 00046: val_acc did not improve from 0.76190\n","Epoch 47/100\n","64/64 [==============================] - 3s 42ms/step - loss: 1.0261e-06 - acc: 1.0000 - val_loss: 2.2615 - val_acc: 0.7460\n","\n","Epoch 00047: val_acc did not improve from 0.76190\n","Epoch 48/100\n","64/64 [==============================] - 3s 42ms/step - loss: 9.5995e-07 - acc: 1.0000 - val_loss: 2.2591 - val_acc: 0.7619\n","\n","Epoch 00048: val_acc did not improve from 0.76190\n","Epoch 49/100\n","64/64 [==============================] - 3s 42ms/step - loss: 9.0341e-07 - acc: 1.0000 - val_loss: 2.2703 - val_acc: 0.7540\n","\n","Epoch 00049: val_acc did not improve from 0.76190\n","Epoch 50/100\n","64/64 [==============================] - 3s 42ms/step - loss: 8.8908e-07 - acc: 1.0000 - val_loss: 2.2686 - val_acc: 0.7619\n","\n","Epoch 00050: val_acc did not improve from 0.76190\n","Epoch 51/100\n","64/64 [==============================] - 3s 42ms/step - loss: 8.4452e-07 - acc: 1.0000 - val_loss: 2.2750 - val_acc: 0.7698\n","\n","Epoch 00051: val_acc improved from 0.76190 to 0.76984, saving model to result/all/five/data_70_15_15/OUR-1-14/epoch-51-val-acc-0.7698.hdf5\n","Epoch 52/100\n","64/64 [==============================] - 3s 41ms/step - loss: 7.9433e-07 - acc: 1.0000 - val_loss: 2.2760 - val_acc: 0.7698\n","\n","Epoch 00052: val_acc did not improve from 0.76984\n","Epoch 53/100\n","64/64 [==============================] - 3s 42ms/step - loss: 7.9222e-07 - acc: 1.0000 - val_loss: 2.2829 - val_acc: 0.7698\n","\n","Epoch 00053: val_acc did not improve from 0.76984\n","Epoch 54/100\n","64/64 [==============================] - 3s 42ms/step - loss: 7.4454e-07 - acc: 1.0000 - val_loss: 2.2792 - val_acc: 0.7698\n","\n","Epoch 00054: val_acc did not improve from 0.76984\n","Epoch 55/100\n","64/64 [==============================] - 3s 42ms/step - loss: 7.3320e-07 - acc: 1.0000 - val_loss: 2.2833 - val_acc: 0.7698\n","\n","Epoch 00055: val_acc did not improve from 0.76984\n","Epoch 56/100\n","64/64 [==============================] - 3s 42ms/step - loss: 6.8343e-07 - acc: 1.0000 - val_loss: 2.2910 - val_acc: 0.7698\n","\n","Epoch 00056: val_acc did not improve from 0.76984\n","Epoch 57/100\n","64/64 [==============================] - 3s 42ms/step - loss: 6.5722e-07 - acc: 1.0000 - val_loss: 2.2976 - val_acc: 0.7698\n","\n","Epoch 00057: val_acc did not improve from 0.76984\n","Epoch 58/100\n","64/64 [==============================] - 3s 42ms/step - loss: 6.1215e-07 - acc: 1.0000 - val_loss: 2.2894 - val_acc: 0.7698\n","\n","Epoch 00058: val_acc did not improve from 0.76984\n","Epoch 59/100\n","64/64 [==============================] - 3s 42ms/step - loss: 6.1188e-07 - acc: 1.0000 - val_loss: 2.2896 - val_acc: 0.7698\n","\n","Epoch 00059: val_acc did not improve from 0.76984\n","Epoch 60/100\n","64/64 [==============================] - 3s 41ms/step - loss: 5.8026e-07 - acc: 1.0000 - val_loss: 2.3035 - val_acc: 0.7698\n","\n","Epoch 00060: val_acc did not improve from 0.76984\n","Epoch 61/100\n","64/64 [==============================] - 3s 42ms/step - loss: 5.7920e-07 - acc: 1.0000 - val_loss: 2.3050 - val_acc: 0.7698\n","\n","Epoch 00061: val_acc did not improve from 0.76984\n","Epoch 62/100\n","64/64 [==============================] - 3s 43ms/step - loss: 5.3423e-07 - acc: 1.0000 - val_loss: 2.3017 - val_acc: 0.7698\n","\n","Epoch 00062: val_acc did not improve from 0.76984\n","Epoch 63/100\n","64/64 [==============================] - 3s 42ms/step - loss: 5.0366e-07 - acc: 1.0000 - val_loss: 2.3069 - val_acc: 0.7698\n","\n","Epoch 00063: val_acc did not improve from 0.76984\n","Epoch 64/100\n","64/64 [==============================] - 3s 43ms/step - loss: 5.0167e-07 - acc: 1.0000 - val_loss: 2.3066 - val_acc: 0.7698\n","\n","Epoch 00064: val_acc did not improve from 0.76984\n","Epoch 65/100\n","64/64 [==============================] - 3s 42ms/step - loss: 5.1359e-07 - acc: 1.0000 - val_loss: 2.3119 - val_acc: 0.7698\n","\n","Epoch 00065: val_acc did not improve from 0.76984\n","Epoch 66/100\n","64/64 [==============================] - 3s 43ms/step - loss: 4.4897e-07 - acc: 1.0000 - val_loss: 2.3237 - val_acc: 0.7698\n","\n","Epoch 00066: val_acc did not improve from 0.76984\n","Epoch 67/100\n","64/64 [==============================] - 3s 42ms/step - loss: 4.5576e-07 - acc: 1.0000 - val_loss: 2.3161 - val_acc: 0.7698\n","\n","Epoch 00067: val_acc did not improve from 0.76984\n","Epoch 68/100\n","64/64 [==============================] - 3s 42ms/step - loss: 4.2137e-07 - acc: 1.0000 - val_loss: 2.3268 - val_acc: 0.7698\n","\n","Epoch 00068: val_acc did not improve from 0.76984\n","Epoch 69/100\n","64/64 [==============================] - 3s 42ms/step - loss: 4.4082e-07 - acc: 1.0000 - val_loss: 2.3257 - val_acc: 0.7698\n","\n","Epoch 00069: val_acc improved from 0.76984 to 0.76984, saving model to result/all/five/data_70_15_15/OUR-1-14/epoch-69-val-acc-0.7698.hdf5\n","Epoch 70/100\n","64/64 [==============================] - 3s 43ms/step - loss: 4.1127e-07 - acc: 1.0000 - val_loss: 2.3277 - val_acc: 0.7698\n","\n","Epoch 00070: val_acc did not improve from 0.76984\n","Epoch 71/100\n","64/64 [==============================] - 3s 44ms/step - loss: 3.9507e-07 - acc: 1.0000 - val_loss: 2.3323 - val_acc: 0.7698\n","\n","Epoch 00071: val_acc did not improve from 0.76984\n","Epoch 72/100\n","64/64 [==============================] - 3s 43ms/step - loss: 3.7783e-07 - acc: 1.0000 - val_loss: 2.3273 - val_acc: 0.7619\n","\n","Epoch 00072: val_acc did not improve from 0.76984\n","Epoch 73/100\n","64/64 [==============================] - 3s 43ms/step - loss: 3.7135e-07 - acc: 1.0000 - val_loss: 2.3427 - val_acc: 0.7698\n","\n","Epoch 00073: val_acc did not improve from 0.76984\n","Epoch 74/100\n","64/64 [==============================] - 3s 43ms/step - loss: 3.6864e-07 - acc: 1.0000 - val_loss: 2.3399 - val_acc: 0.7698\n","\n","Epoch 00074: val_acc did not improve from 0.76984\n","Epoch 75/100\n","64/64 [==============================] - 3s 42ms/step - loss: 3.4803e-07 - acc: 1.0000 - val_loss: 2.3447 - val_acc: 0.7698\n","\n","Epoch 00075: val_acc did not improve from 0.76984\n","Epoch 76/100\n","64/64 [==============================] - 3s 42ms/step - loss: 3.4212e-07 - acc: 1.0000 - val_loss: 2.3420 - val_acc: 0.7698\n","\n","Epoch 00076: val_acc did not improve from 0.76984\n","Epoch 77/100\n","64/64 [==============================] - 3s 43ms/step - loss: 3.2986e-07 - acc: 1.0000 - val_loss: 2.3451 - val_acc: 0.7698\n","\n","Epoch 00077: val_acc did not improve from 0.76984\n","Epoch 78/100\n","64/64 [==============================] - 3s 43ms/step - loss: 3.1434e-07 - acc: 1.0000 - val_loss: 2.3472 - val_acc: 0.7698\n","\n","Epoch 00078: val_acc did not improve from 0.76984\n","Epoch 79/100\n","64/64 [==============================] - 3s 42ms/step - loss: 3.1215e-07 - acc: 1.0000 - val_loss: 2.3534 - val_acc: 0.7698\n","\n","Epoch 00079: val_acc did not improve from 0.76984\n","Epoch 80/100\n","64/64 [==============================] - 3s 42ms/step - loss: 2.9573e-07 - acc: 1.0000 - val_loss: 2.3529 - val_acc: 0.7698\n","\n","Epoch 00080: val_acc did not improve from 0.76984\n","Epoch 81/100\n","64/64 [==============================] - 3s 42ms/step - loss: 2.9219e-07 - acc: 1.0000 - val_loss: 2.3569 - val_acc: 0.7698\n","\n","Epoch 00081: val_acc did not improve from 0.76984\n","Epoch 82/100\n","64/64 [==============================] - 3s 44ms/step - loss: 2.7920e-07 - acc: 1.0000 - val_loss: 2.3589 - val_acc: 0.7698\n","\n","Epoch 00082: val_acc did not improve from 0.76984\n","Epoch 83/100\n","64/64 [==============================] - 3s 43ms/step - loss: 2.8372e-07 - acc: 1.0000 - val_loss: 2.3650 - val_acc: 0.7698\n","\n","Epoch 00083: val_acc did not improve from 0.76984\n","Epoch 84/100\n","64/64 [==============================] - 3s 42ms/step - loss: 2.6985e-07 - acc: 1.0000 - val_loss: 2.3631 - val_acc: 0.7698\n","\n","Epoch 00084: val_acc did not improve from 0.76984\n","Epoch 85/100\n","64/64 [==============================] - 3s 43ms/step - loss: 2.6641e-07 - acc: 1.0000 - val_loss: 2.3706 - val_acc: 0.7698\n","\n","Epoch 00085: val_acc did not improve from 0.76984\n","Epoch 86/100\n","64/64 [==============================] - 3s 41ms/step - loss: 2.5861e-07 - acc: 1.0000 - val_loss: 2.3745 - val_acc: 0.7698\n","\n","Epoch 00086: val_acc did not improve from 0.76984\n","Epoch 87/100\n","64/64 [==============================] - 3s 41ms/step - loss: 2.6578e-07 - acc: 1.0000 - val_loss: 2.3750 - val_acc: 0.7698\n","\n","Epoch 00087: val_acc did not improve from 0.76984\n","Epoch 88/100\n","64/64 [==============================] - 3s 43ms/step - loss: 2.4045e-07 - acc: 1.0000 - val_loss: 2.3843 - val_acc: 0.7698\n","\n","Epoch 00088: val_acc did not improve from 0.76984\n","Epoch 89/100\n","64/64 [==============================] - 3s 43ms/step - loss: 2.4580e-07 - acc: 1.0000 - val_loss: 2.3799 - val_acc: 0.7619\n","\n","Epoch 00089: val_acc did not improve from 0.76984\n","Epoch 90/100\n","64/64 [==============================] - 3s 42ms/step - loss: 2.3393e-07 - acc: 1.0000 - val_loss: 2.3836 - val_acc: 0.7619\n","\n","Epoch 00090: val_acc did not improve from 0.76984\n","Epoch 91/100\n","64/64 [==============================] - 3s 44ms/step - loss: 2.3090e-07 - acc: 1.0000 - val_loss: 2.3879 - val_acc: 0.7619\n","\n","Epoch 00091: val_acc did not improve from 0.76984\n","Epoch 92/100\n","64/64 [==============================] - 3s 42ms/step - loss: 2.1872e-07 - acc: 1.0000 - val_loss: 2.3844 - val_acc: 0.7619\n","\n","Epoch 00092: val_acc did not improve from 0.76984\n","Epoch 93/100\n","64/64 [==============================] - 3s 42ms/step - loss: 2.1919e-07 - acc: 1.0000 - val_loss: 2.3837 - val_acc: 0.7619\n","\n","Epoch 00093: val_acc did not improve from 0.76984\n","Epoch 94/100\n","64/64 [==============================] - 3s 42ms/step - loss: 2.1618e-07 - acc: 1.0000 - val_loss: 2.3833 - val_acc: 0.7619\n","\n","Epoch 00094: val_acc did not improve from 0.76984\n","Epoch 95/100\n","64/64 [==============================] - 3s 44ms/step - loss: 2.0819e-07 - acc: 1.0000 - val_loss: 2.3928 - val_acc: 0.7619\n","\n","Epoch 00095: val_acc did not improve from 0.76984\n","Epoch 96/100\n","64/64 [==============================] - 3s 41ms/step - loss: 2.1131e-07 - acc: 1.0000 - val_loss: 2.3881 - val_acc: 0.7619\n","\n","Epoch 00096: val_acc did not improve from 0.76984\n","Epoch 97/100\n","64/64 [==============================] - 3s 43ms/step - loss: 2.0604e-07 - acc: 1.0000 - val_loss: 2.4054 - val_acc: 0.7619\n","\n","Epoch 00097: val_acc did not improve from 0.76984\n","Epoch 98/100\n","64/64 [==============================] - 3s 44ms/step - loss: 1.9650e-07 - acc: 1.0000 - val_loss: 2.3986 - val_acc: 0.7619\n","\n","Epoch 00098: val_acc did not improve from 0.76984\n","Epoch 99/100\n","64/64 [==============================] - 3s 42ms/step - loss: 1.9073e-07 - acc: 1.0000 - val_loss: 2.4009 - val_acc: 0.7619\n","\n","Epoch 00099: val_acc did not improve from 0.76984\n","Epoch 100/100\n","64/64 [==============================] - 3s 43ms/step - loss: 1.9310e-07 - acc: 1.0000 - val_loss: 2.4025 - val_acc: 0.7619\n","\n","Epoch 00100: val_acc did not improve from 0.76984\n","\n","<keras.callbacks.History at 0x7ff3f644d390>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L14WxLbWK63c","colab_type":"code","colab":{}},"cell_type":"code","source":["#Alexnet 78\n","\n","Epoch 1/100\n","64/64 [==============================] - 9s 139ms/step - loss: 1.4782 - acc: 0.3422 - val_loss: 1.4888 - val_acc: 0.3000\n","\n","Epoch 00001: val_acc improved from -inf to 0.30000, saving model to result/all/four/data_70_15_15/Alex_drop7/epoch-01-val-acc-0.3000.hdf5\n","Epoch 2/100\n","64/64 [==============================] - 8s 119ms/step - loss: 1.1847 - acc: 0.5092 - val_loss: 1.2472 - val_acc: 0.4818\n","\n","Epoch 00002: val_acc improved from 0.30000 to 0.48182, saving model to result/all/four/data_70_15_15/Alex_drop7/epoch-02-val-acc-0.4818.hdf5\n","Epoch 3/100\n","64/64 [==============================] - 7s 116ms/step - loss: 0.9656 - acc: 0.6049 - val_loss: 6.8619 - val_acc: 0.3000\n","\n","Epoch 00003: val_acc did not improve from 0.48182\n","Epoch 4/100\n","64/64 [==============================] - 7s 116ms/step - loss: 0.8294 - acc: 0.6662 - val_loss: 1.2203 - val_acc: 0.4455\n","\n","Epoch 00004: val_acc did not improve from 0.48182\n","Epoch 5/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.8584 - acc: 0.6461 - val_loss: 10.4755 - val_acc: 0.2818\n","\n","Epoch 00005: val_acc did not improve from 0.48182\n","Epoch 6/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.8937 - acc: 0.6593 - val_loss: 1.5605 - val_acc: 0.4818\n","\n","Epoch 00006: val_acc did not improve from 0.48182\n","Epoch 7/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.6947 - acc: 0.7233 - val_loss: 1.4471 - val_acc: 0.4727\n","\n","Epoch 00007: val_acc did not improve from 0.48182\n","Epoch 8/100\n","64/64 [==============================] - 7s 117ms/step - loss: 0.6895 - acc: 0.7398 - val_loss: 1.9394 - val_acc: 0.3727\n","\n","Epoch 00008: val_acc did not improve from 0.48182\n","Epoch 9/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.8985 - acc: 0.6701 - val_loss: 1.6681 - val_acc: 0.3364\n","\n","Epoch 00009: val_acc did not improve from 0.48182\n","Epoch 10/100\n","64/64 [==============================] - 7s 113ms/step - loss: 0.7616 - acc: 0.7193 - val_loss: 2.0468 - val_acc: 0.3727\n","\n","Epoch 00010: val_acc did not improve from 0.48182\n","Epoch 11/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.6419 - acc: 0.7527 - val_loss: 1.8454 - val_acc: 0.3727\n","\n","Epoch 00011: val_acc did not improve from 0.48182\n","Epoch 12/100\n","64/64 [==============================] - 7s 117ms/step - loss: 0.5067 - acc: 0.8146 - val_loss: 1.3948 - val_acc: 0.5455\n","\n","Epoch 00012: val_acc improved from 0.48182 to 0.54545, saving model to result/all/four/data_70_15_15/Alex_drop7/epoch-12-val-acc-0.5455.hdf5\n","Epoch 13/100\n","64/64 [==============================] - 7s 114ms/step - loss: 0.5283 - acc: 0.8287 - val_loss: 2.1945 - val_acc: 0.5000\n","\n","Epoch 00013: val_acc did not improve from 0.54545\n","Epoch 14/100\n","64/64 [==============================] - 7s 116ms/step - loss: 0.5402 - acc: 0.8298 - val_loss: 2.8601 - val_acc: 0.4273\n","\n","Epoch 00014: val_acc did not improve from 0.54545\n","Epoch 15/100\n","64/64 [==============================] - 7s 116ms/step - loss: 0.3182 - acc: 0.9069 - val_loss: 1.4952 - val_acc: 0.6545\n","\n","Epoch 00015: val_acc improved from 0.54545 to 0.65455, saving model to result/all/four/data_70_15_15/Alex_drop7/epoch-15-val-acc-0.6545.hdf5\n","Epoch 16/100\n","64/64 [==============================] - 7s 113ms/step - loss: 0.3622 - acc: 0.8767 - val_loss: 1.5678 - val_acc: 0.4818\n","\n","Epoch 00016: val_acc did not improve from 0.65455\n","Epoch 17/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.4771 - acc: 0.8201 - val_loss: 4.3421 - val_acc: 0.4273\n","\n","Epoch 00017: val_acc did not improve from 0.65455\n","Epoch 18/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.2499 - acc: 0.9138 - val_loss: 3.1264 - val_acc: 0.4818\n","\n","Epoch 00018: val_acc did not improve from 0.65455\n","Epoch 19/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.6229 - acc: 0.8181 - val_loss: 1.5132 - val_acc: 0.5182\n","\n","Epoch 00019: val_acc did not improve from 0.65455\n","Epoch 20/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.4843 - acc: 0.8387 - val_loss: 4.3242 - val_acc: 0.4727\n","\n","Epoch 00020: val_acc did not improve from 0.65455\n","Epoch 21/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.3947 - acc: 0.8879 - val_loss: 5.4333 - val_acc: 0.4182\n","\n","Epoch 00021: val_acc did not improve from 0.65455\n","Epoch 22/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.5280 - acc: 0.8238 - val_loss: 2.9836 - val_acc: 0.5455\n","\n","Epoch 00022: val_acc did not improve from 0.65455\n","Epoch 23/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.2908 - acc: 0.8980 - val_loss: 2.0136 - val_acc: 0.6636\n","\n","Epoch 00023: val_acc improved from 0.65455 to 0.66364, saving model to result/all/four/data_70_15_15/Alex_drop7/epoch-23-val-acc-0.6636.hdf5\n","Epoch 24/100\n","64/64 [==============================] - 7s 117ms/step - loss: 0.3224 - acc: 0.9027 - val_loss: 4.9653 - val_acc: 0.4727\n","\n","Epoch 00024: val_acc did not improve from 0.66364\n","Epoch 25/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.5387 - acc: 0.8724 - val_loss: 4.6321 - val_acc: 0.4273\n","\n","Epoch 00025: val_acc did not improve from 0.66364\n","Epoch 26/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.8756 - acc: 0.7259 - val_loss: 5.2105 - val_acc: 0.3091\n","\n","Epoch 00026: val_acc did not improve from 0.66364\n","Epoch 27/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.6200 - acc: 0.8226 - val_loss: 5.3140 - val_acc: 0.4545\n","\n","Epoch 00027: val_acc did not improve from 0.66364\n","Epoch 28/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.3273 - acc: 0.8793 - val_loss: 3.5799 - val_acc: 0.5636\n","\n","Epoch 00028: val_acc did not improve from 0.66364\n","Epoch 29/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.6600 - acc: 0.8376 - val_loss: 2.6503 - val_acc: 0.3818\n","\n","Epoch 00029: val_acc did not improve from 0.66364\n","Epoch 30/100\n","64/64 [==============================] - 7s 113ms/step - loss: 0.4204 - acc: 0.8458 - val_loss: 1.6715 - val_acc: 0.5455\n","\n","Epoch 00030: val_acc did not improve from 0.66364\n","Epoch 31/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.1505 - acc: 0.9451 - val_loss: 2.9438 - val_acc: 0.5455\n","\n","Epoch 00031: val_acc did not improve from 0.66364\n","Epoch 32/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.1201 - acc: 0.9623 - val_loss: 1.8542 - val_acc: 0.6636\n","\n","Epoch 00032: val_acc did not improve from 0.66364\n","Epoch 33/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.3297 - acc: 0.9246 - val_loss: 6.2811 - val_acc: 0.4091\n","\n","Epoch 00033: val_acc did not improve from 0.66364\n","Epoch 34/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.7514 - acc: 0.8411 - val_loss: 7.6380 - val_acc: 0.2545\n","\n","Epoch 00034: val_acc did not improve from 0.66364\n","Epoch 35/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.2735 - acc: 0.9059 - val_loss: 2.0389 - val_acc: 0.6000\n","\n","Epoch 00035: val_acc did not improve from 0.66364\n","Epoch 36/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.2022 - acc: 0.9614 - val_loss: 3.7447 - val_acc: 0.5364\n","\n","Epoch 00036: val_acc did not improve from 0.66364\n","Epoch 37/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.1608 - acc: 0.9632 - val_loss: 2.8953 - val_acc: 0.6182\n","\n","Epoch 00037: val_acc did not improve from 0.66364\n","Epoch 38/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.4100 - acc: 0.9000 - val_loss: 5.8662 - val_acc: 0.4727\n","\n","Epoch 00038: val_acc did not improve from 0.66364\n","Epoch 39/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.1248 - acc: 0.9729 - val_loss: 3.4995 - val_acc: 0.6000\n","\n","Epoch 00039: val_acc did not improve from 0.66364\n","Epoch 40/100\n","64/64 [==============================] - 7s 113ms/step - loss: 0.1666 - acc: 0.9705 - val_loss: 4.3206 - val_acc: 0.5273\n","\n","Epoch 00040: val_acc did not improve from 0.66364\n","Epoch 41/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.6613 - acc: 0.8966 - val_loss: 10.9058 - val_acc: 0.2727\n","\n","Epoch 00041: val_acc did not improve from 0.66364\n","Epoch 42/100\n","64/64 [==============================] - 7s 116ms/step - loss: 0.2774 - acc: 0.9162 - val_loss: 3.5341 - val_acc: 0.2818\n","\n","Epoch 00042: val_acc did not improve from 0.66364\n","Epoch 43/100\n","64/64 [==============================] - 7s 116ms/step - loss: 0.4697 - acc: 0.8898 - val_loss: 2.5526 - val_acc: 0.5727\n","\n","Epoch 00043: val_acc did not improve from 0.66364\n","Epoch 44/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.2454 - acc: 0.9291 - val_loss: 2.1144 - val_acc: 0.5364\n","\n","Epoch 00044: val_acc did not improve from 0.66364\n","Epoch 45/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.0954 - acc: 0.9785 - val_loss: 2.1018 - val_acc: 0.6455\n","\n","Epoch 00045: val_acc did not improve from 0.66364\n","Epoch 46/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.1733 - acc: 0.9686 - val_loss: 5.3552 - val_acc: 0.4091\n","\n","Epoch 00046: val_acc did not improve from 0.66364\n","Epoch 47/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.1549 - acc: 0.9764 - val_loss: 6.9712 - val_acc: 0.5091\n","\n","Epoch 00047: val_acc did not improve from 0.66364\n","Epoch 48/100\n","64/64 [==============================] - 7s 116ms/step - loss: 0.9126 - acc: 0.8494 - val_loss: 1.7384 - val_acc: 0.4273\n","\n","Epoch 00048: val_acc did not improve from 0.66364\n","Epoch 49/100\n","64/64 [==============================] - 7s 113ms/step - loss: 0.3673 - acc: 0.9082 - val_loss: 2.9330 - val_acc: 0.5909\n","\n","Epoch 00049: val_acc did not improve from 0.66364\n","Epoch 50/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.5093 - acc: 0.8756 - val_loss: 9.3911 - val_acc: 0.3091\n","\n","Epoch 00050: val_acc did not improve from 0.66364\n","Epoch 51/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.2793 - acc: 0.9237 - val_loss: 4.5383 - val_acc: 0.6091\n","\n","Epoch 00051: val_acc did not improve from 0.66364\n","Epoch 52/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.2026 - acc: 0.9637 - val_loss: 3.9131 - val_acc: 0.6182\n","\n","Epoch 00052: val_acc did not improve from 0.66364\n","Epoch 53/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.3918 - acc: 0.9130 - val_loss: 4.2207 - val_acc: 0.6000\n","\n","Epoch 00053: val_acc did not improve from 0.66364\n","Epoch 54/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.2857 - acc: 0.9468 - val_loss: 3.9784 - val_acc: 0.6636\n","\n","Epoch 00054: val_acc improved from 0.66364 to 0.66364, saving model to result/all/four/data_70_15_15/Alex_drop7/epoch-54-val-acc-0.6636.hdf5\n","Epoch 55/100\n","64/64 [==============================] - 7s 115ms/step - loss: 0.1188 - acc: 0.9686 - val_loss: 2.2700 - val_acc: 0.7000\n","\n","Epoch 00055: val_acc improved from 0.66364 to 0.70000, saving model to result/all/four/data_70_15_15/Alex_drop7/epoch-55-val-acc-0.7000.hdf5\n","Epoch 56/100\n","64/64 [==============================] - 7s 115ms/step - loss: 0.0407 - acc: 0.9949 - val_loss: 1.9349 - val_acc: 0.7273\n","\n","Epoch 00056: val_acc improved from 0.70000 to 0.72727, saving model to result/all/four/data_70_15_15/Alex_drop7/epoch-56-val-acc-0.7273.hdf5\n","Epoch 57/100\n","64/64 [==============================] - 8s 117ms/step - loss: 0.2825 - acc: 0.9408 - val_loss: 5.0382 - val_acc: 0.5091\n","\n","Epoch 00057: val_acc did not improve from 0.72727\n","Epoch 58/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.0998 - acc: 0.9809 - val_loss: 3.0001 - val_acc: 0.7091\n","\n","Epoch 00058: val_acc did not improve from 0.72727\n","Epoch 59/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.9266 - acc: 0.8748 - val_loss: 4.0189 - val_acc: 0.4091\n","\n","Epoch 00059: val_acc did not improve from 0.72727\n","Epoch 60/100\n","64/64 [==============================] - 7s 110ms/step - loss: 0.4359 - acc: 0.8837 - val_loss: 2.2066 - val_acc: 0.4636\n","\n","Epoch 00060: val_acc did not improve from 0.72727\n","Epoch 61/100\n","64/64 [==============================] - 8s 117ms/step - loss: 0.2917 - acc: 0.9287 - val_loss: 5.6855 - val_acc: 0.5545\n","\n","Epoch 00061: val_acc did not improve from 0.72727\n","Epoch 62/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.3939 - acc: 0.9248 - val_loss: 5.7840 - val_acc: 0.4727\n","\n","Epoch 00062: val_acc did not improve from 0.72727\n","Epoch 63/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.2492 - acc: 0.9678 - val_loss: 3.6885 - val_acc: 0.6636\n","\n","Epoch 00063: val_acc did not improve from 0.72727\n","Epoch 64/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.0128 - acc: 0.9968 - val_loss: 3.6451 - val_acc: 0.6545\n","\n","Epoch 00064: val_acc did not improve from 0.72727\n","Epoch 65/100\n","64/64 [==============================] - 7s 112ms/step - loss: 1.0845 - acc: 0.8243 - val_loss: 5.8293 - val_acc: 0.2909\n","\n","Epoch 00065: val_acc did not improve from 0.72727\n","Epoch 66/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.3279 - acc: 0.9023 - val_loss: 1.8511 - val_acc: 0.6182\n","\n","Epoch 00066: val_acc did not improve from 0.72727\n","Epoch 67/100\n","64/64 [==============================] - 7s 115ms/step - loss: 0.6347 - acc: 0.8816 - val_loss: 4.4448 - val_acc: 0.5091\n","\n","Epoch 00067: val_acc did not improve from 0.72727\n","Epoch 68/100\n","64/64 [==============================] - 7s 117ms/step - loss: 0.3432 - acc: 0.9210 - val_loss: 2.4066 - val_acc: 0.6091\n","\n","Epoch 00068: val_acc did not improve from 0.72727\n","Epoch 69/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.6053 - acc: 0.9126 - val_loss: 5.1407 - val_acc: 0.5727\n","\n","Epoch 00069: val_acc did not improve from 0.72727\n","Epoch 70/100\n","64/64 [==============================] - 7s 116ms/step - loss: 0.5509 - acc: 0.8746 - val_loss: 2.2664 - val_acc: 0.5818\n","\n","Epoch 00070: val_acc did not improve from 0.72727\n","Epoch 71/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.4151 - acc: 0.9072 - val_loss: 2.8883 - val_acc: 0.5727\n","\n","Epoch 00071: val_acc did not improve from 0.72727\n","Epoch 72/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.0940 - acc: 0.9834 - val_loss: 2.1740 - val_acc: 0.6727\n","\n","Epoch 00072: val_acc did not improve from 0.72727\n","Epoch 73/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.6559 - acc: 0.8409 - val_loss: 4.3632 - val_acc: 0.5727\n","\n","Epoch 00073: val_acc did not improve from 0.72727\n","Epoch 74/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.4524 - acc: 0.8945 - val_loss: 2.8618 - val_acc: 0.5727\n","\n","Epoch 00074: val_acc did not improve from 0.72727\n","Epoch 75/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.1283 - acc: 0.9802 - val_loss: 2.2343 - val_acc: 0.6727\n","\n","Epoch 00075: val_acc did not improve from 0.72727\n","Epoch 76/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.6514 - acc: 0.8879 - val_loss: 4.1423 - val_acc: 0.4182\n","\n","Epoch 00076: val_acc did not improve from 0.72727\n","Epoch 77/100\n","64/64 [==============================] - 7s 110ms/step - loss: 0.6025 - acc: 0.8362 - val_loss: 1.9162 - val_acc: 0.5545\n","\n","Epoch 00077: val_acc did not improve from 0.72727\n","Epoch 78/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.2195 - acc: 0.9386 - val_loss: 1.9455 - val_acc: 0.6091\n","\n","Epoch 00078: val_acc did not improve from 0.72727\n","Epoch 79/100\n","64/64 [==============================] - 7s 113ms/step - loss: 0.1423 - acc: 0.9488 - val_loss: 1.7016 - val_acc: 0.6727\n","\n","Epoch 00079: val_acc did not improve from 0.72727\n","Epoch 80/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.3099 - acc: 0.9324 - val_loss: 1.8009 - val_acc: 0.6636\n","\n","Epoch 00080: val_acc did not improve from 0.72727\n","Epoch 81/100\n","64/64 [==============================] - 7s 116ms/step - loss: 0.1036 - acc: 0.9668 - val_loss: 3.0973 - val_acc: 0.5636\n","\n","Epoch 00081: val_acc did not improve from 0.72727\n","Epoch 82/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.4356 - acc: 0.9100 - val_loss: 1.6750 - val_acc: 0.7000\n","\n","Epoch 00082: val_acc did not improve from 0.72727\n","Epoch 83/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.2931 - acc: 0.9531 - val_loss: 1.7391 - val_acc: 0.6909\n","\n","Epoch 00083: val_acc did not improve from 0.72727\n","Epoch 84/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.1726 - acc: 0.9597 - val_loss: 4.6585 - val_acc: 0.5727\n","\n","Epoch 00084: val_acc did not improve from 0.72727\n","Epoch 85/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.2678 - acc: 0.9240 - val_loss: 2.2208 - val_acc: 0.6455\n","\n","Epoch 00085: val_acc did not improve from 0.72727\n","Epoch 86/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.4541 - acc: 0.9178 - val_loss: 2.0874 - val_acc: 0.5818\n","\n","Epoch 00086: val_acc did not improve from 0.72727\n","Epoch 87/100\n","64/64 [==============================] - 7s 113ms/step - loss: 0.3016 - acc: 0.9513 - val_loss: 3.2081 - val_acc: 0.5909\n","\n","Epoch 00087: val_acc did not improve from 0.72727\n","Epoch 88/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.2409 - acc: 0.9477 - val_loss: 3.1067 - val_acc: 0.6182\n","\n","Epoch 00088: val_acc did not improve from 0.72727\n","Epoch 89/100\n","64/64 [==============================] - 7s 111ms/step - loss: 1.0533 - acc: 0.8763 - val_loss: 7.7739 - val_acc: 0.3909\n","\n","Epoch 00089: val_acc did not improve from 0.72727\n","Epoch 90/100\n","64/64 [==============================] - 7s 113ms/step - loss: 0.5108 - acc: 0.8661 - val_loss: 4.9737 - val_acc: 0.3455\n","\n","Epoch 00090: val_acc did not improve from 0.72727\n","Epoch 91/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.2851 - acc: 0.9342 - val_loss: 2.9468 - val_acc: 0.5636\n","\n","Epoch 00091: val_acc did not improve from 0.72727\n","Epoch 92/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.2976 - acc: 0.9377 - val_loss: 2.9018 - val_acc: 0.5273\n","\n","Epoch 00092: val_acc did not improve from 0.72727\n","Epoch 93/100\n","64/64 [==============================] - 7s 111ms/step - loss: 0.2417 - acc: 0.9439 - val_loss: 1.5093 - val_acc: 0.7000\n","\n","Epoch 00093: val_acc did not improve from 0.72727\n","Epoch 94/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.2227 - acc: 0.9525 - val_loss: 1.1860 - val_acc: 0.6727\n","\n","Epoch 00094: val_acc did not improve from 0.72727\n","Epoch 95/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.1205 - acc: 0.9582 - val_loss: 5.7810 - val_acc: 0.4364\n","\n","Epoch 00095: val_acc did not improve from 0.72727\n","Epoch 96/100\n","64/64 [==============================] - 7s 110ms/step - loss: 0.0919 - acc: 0.9823 - val_loss: 2.7857 - val_acc: 0.6455\n","\n","Epoch 00096: val_acc did not improve from 0.72727\n","Epoch 97/100\n","64/64 [==============================] - 7s 114ms/step - loss: 0.3070 - acc: 0.9351 - val_loss: 7.2856 - val_acc: 0.4000\n","\n","Epoch 00097: val_acc did not improve from 0.72727\n","Epoch 98/100\n","64/64 [==============================] - 7s 116ms/step - loss: 0.2241 - acc: 0.9529 - val_loss: 1.4937 - val_acc: 0.7545\n","\n","Epoch 00098: val_acc improved from 0.72727 to 0.75455, saving model to result/all/four/data_70_15_15/Alex_drop7/epoch-98-val-acc-0.7545.hdf5\n","Epoch 99/100\n","64/64 [==============================] - 8s 119ms/step - loss: 0.3393 - acc: 0.9340 - val_loss: 1.6161 - val_acc: 0.7273\n","\n","Epoch 00099: val_acc did not improve from 0.75455\n","Epoch 100/100\n","64/64 [==============================] - 7s 112ms/step - loss: 0.1197 - acc: 0.9683 - val_loss: 1.1788 - val_acc: 0.7818\n","\n","Epoch 00100: val_acc improved from 0.75455 to 0.78182, saving model to result/all/four/data_70_15_15/Alex_drop7/epoch-100-val-acc-0.7818.hdf5\n","\n","<keras.callbacks.History at 0x7f3a0aa917f0>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dHAzwOyPHqut","colab_type":"code","colab":{}},"cell_type":"code","source":["#four 70-15-15 75.45\n","\n","\n","\n","Epoch 1/100\n","64/64 [==============================] - 3s 53ms/step - loss: 1.3758 - acc: 0.2918 - val_loss: 1.3720 - val_acc: 0.2727\n","\n","Epoch 00001: val_acc improved from -inf to 0.27273, saving model to result/all/four/data_70_15_15/OUR6-6/epoch-01-val-acc-0.2727.hdf5\n","Epoch 2/100\n","64/64 [==============================] - 3s 45ms/step - loss: 1.3330 - acc: 0.3435 - val_loss: 1.3299 - val_acc: 0.4000\n","\n","Epoch 00002: val_acc improved from 0.27273 to 0.40000, saving model to result/all/four/data_70_15_15/OUR6-6/epoch-02-val-acc-0.4000.hdf5\n","Epoch 3/100\n","64/64 [==============================] - 3s 45ms/step - loss: 1.0994 - acc: 0.5601 - val_loss: 1.1177 - val_acc: 0.5545\n","\n","Epoch 00003: val_acc improved from 0.40000 to 0.55455, saving model to result/all/four/data_70_15_15/OUR6-6/epoch-03-val-acc-0.5545.hdf5\n","Epoch 4/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.8062 - acc: 0.6888 - val_loss: 0.9467 - val_acc: 0.6636\n","\n","Epoch 00004: val_acc improved from 0.55455 to 0.66364, saving model to result/all/four/data_70_15_15/OUR6-6/epoch-04-val-acc-0.6636.hdf5\n","Epoch 5/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.7043 - acc: 0.7320 - val_loss: 1.0058 - val_acc: 0.7091\n","\n","Epoch 00005: val_acc improved from 0.66364 to 0.70909, saving model to result/all/four/data_70_15_15/OUR6-6/epoch-05-val-acc-0.7091.hdf5\n","Epoch 6/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.3615 - acc: 0.8624 - val_loss: 1.1119 - val_acc: 0.6545\n","\n","Epoch 00006: val_acc did not improve from 0.70909\n","Epoch 7/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.3645 - acc: 0.8638 - val_loss: 1.2735 - val_acc: 0.6545\n","\n","Epoch 00007: val_acc did not improve from 0.70909\n","Epoch 8/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.1359 - acc: 0.9530 - val_loss: 1.4163 - val_acc: 0.6727\n","\n","Epoch 00008: val_acc did not improve from 0.70909\n","Epoch 9/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0743 - acc: 0.9748 - val_loss: 1.7035 - val_acc: 0.6455\n","\n","Epoch 00009: val_acc did not improve from 0.70909\n","Epoch 10/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0804 - acc: 0.9705 - val_loss: 2.6419 - val_acc: 0.5182\n","\n","Epoch 00010: val_acc did not improve from 0.70909\n","Epoch 11/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.3065 - acc: 0.9098 - val_loss: 1.3230 - val_acc: 0.7091\n","\n","Epoch 00011: val_acc did not improve from 0.70909\n","Epoch 12/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.5038 - acc: 0.8324 - val_loss: 1.1371 - val_acc: 0.6818\n","\n","Epoch 00012: val_acc did not improve from 0.70909\n","Epoch 13/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0870 - acc: 0.9714 - val_loss: 1.3057 - val_acc: 0.7364\n","\n","Epoch 00013: val_acc improved from 0.70909 to 0.73636, saving model to result/all/four/data_70_15_15/OUR6-6/epoch-13-val-acc-0.7364.hdf5\n","Epoch 14/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0651 - acc: 0.9790 - val_loss: 1.2732 - val_acc: 0.7273\n","\n","Epoch 00014: val_acc did not improve from 0.73636\n","Epoch 15/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0294 - acc: 0.9912 - val_loss: 1.4014 - val_acc: 0.7364\n","\n","Epoch 00015: val_acc did not improve from 0.73636\n","Epoch 16/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0922 - acc: 0.9659 - val_loss: 1.3138 - val_acc: 0.7545\n","\n","Epoch 00016: val_acc improved from 0.73636 to 0.75455, saving model to result/all/four/data_70_15_15/OUR6-6/epoch-16-val-acc-0.7545.hdf5\n","Epoch 17/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0282 - acc: 0.9924 - val_loss: 1.3132 - val_acc: 0.6909\n","\n","Epoch 00017: val_acc did not improve from 0.75455\n","Epoch 18/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0881 - acc: 0.9705 - val_loss: 1.5540 - val_acc: 0.7273\n","\n","Epoch 00018: val_acc did not improve from 0.75455\n","Epoch 19/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0217 - acc: 0.9932 - val_loss: 1.5053 - val_acc: 0.7091\n","\n","Epoch 00019: val_acc did not improve from 0.75455\n","Epoch 20/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0121 - acc: 0.9958 - val_loss: 1.6185 - val_acc: 0.7273\n","\n","Epoch 00020: val_acc did not improve from 0.75455\n","Epoch 21/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0178 - acc: 0.9946 - val_loss: 1.6010 - val_acc: 0.7000\n","\n","Epoch 00021: val_acc did not improve from 0.75455\n","Epoch 22/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0064 - acc: 0.9980 - val_loss: 1.7398 - val_acc: 0.7455\n","\n","Epoch 00022: val_acc did not improve from 0.75455\n","Epoch 23/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0088 - acc: 0.9973 - val_loss: 1.6965 - val_acc: 0.7364\n","\n","Epoch 00023: val_acc did not improve from 0.75455\n","Epoch 24/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0078 - acc: 0.9976 - val_loss: 1.7000 - val_acc: 0.7545\n","\n","Epoch 00024: val_acc did not improve from 0.75455\n","Epoch 25/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0075 - acc: 0.9978 - val_loss: 1.8012 - val_acc: 0.7273\n","\n","Epoch 00025: val_acc did not improve from 0.75455\n","Epoch 26/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0108 - acc: 0.9968 - val_loss: 1.8552 - val_acc: 0.7182\n","\n","Epoch 00026: val_acc did not improve from 0.75455\n","Epoch 27/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0070 - acc: 0.9980 - val_loss: 1.8089 - val_acc: 0.7545\n","\n","Epoch 00027: val_acc did not improve from 0.75455\n","Epoch 28/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 1.7561 - val_acc: 0.7273\n","\n","Epoch 00028: val_acc did not improve from 0.75455\n","Epoch 29/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0042 - acc: 0.9985 - val_loss: 1.7896 - val_acc: 0.7273\n","\n","Epoch 00029: val_acc did not improve from 0.75455\n","Epoch 30/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0051 - acc: 0.9990 - val_loss: 1.7755 - val_acc: 0.7364\n","\n","Epoch 00030: val_acc did not improve from 0.75455\n","Epoch 31/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0061 - acc: 0.9980 - val_loss: 1.8614 - val_acc: 0.7273\n","\n","Epoch 00031: val_acc did not improve from 0.75455\n","Epoch 32/100\n","64/64 [==============================] - 3s 48ms/step - loss: 0.0041 - acc: 0.9990 - val_loss: 1.9031 - val_acc: 0.7273\n","\n","Epoch 00032: val_acc did not improve from 0.75455\n","Epoch 33/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0026 - acc: 0.9995 - val_loss: 1.9377 - val_acc: 0.7091\n","\n","Epoch 00033: val_acc did not improve from 0.75455\n","Epoch 34/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.8740 - val_acc: 0.7091\n","\n","Epoch 00034: val_acc did not improve from 0.75455\n","Epoch 35/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 1.9977 - val_acc: 0.7091\n","\n","Epoch 00035: val_acc did not improve from 0.75455\n","Epoch 36/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0043 - acc: 0.9988 - val_loss: 2.1934 - val_acc: 0.7455\n","\n","Epoch 00036: val_acc did not improve from 0.75455\n","Epoch 37/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0092 - acc: 0.9963 - val_loss: 2.0730 - val_acc: 0.7273\n","\n","Epoch 00037: val_acc did not improve from 0.75455\n","Epoch 38/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0041 - acc: 0.9995 - val_loss: 1.9315 - val_acc: 0.7000\n","\n","Epoch 00038: val_acc did not improve from 0.75455\n","Epoch 39/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0035 - acc: 0.9985 - val_loss: 1.9316 - val_acc: 0.7455\n","\n","Epoch 00039: val_acc did not improve from 0.75455\n","Epoch 40/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0017 - acc: 0.9998 - val_loss: 1.9680 - val_acc: 0.7455\n","\n","Epoch 00040: val_acc did not improve from 0.75455\n","Epoch 41/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0089 - acc: 0.9968 - val_loss: 2.5246 - val_acc: 0.6818\n","\n","Epoch 00041: val_acc did not improve from 0.75455\n","Epoch 42/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.7223 - acc: 0.8892 - val_loss: 3.3284 - val_acc: 0.5545\n","\n","Epoch 00042: val_acc did not improve from 0.75455\n","Epoch 43/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.4684 - acc: 0.8780 - val_loss: 2.3763 - val_acc: 0.5455\n","\n","Epoch 00043: val_acc did not improve from 0.75455\n","Epoch 44/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.3861 - acc: 0.8860 - val_loss: 1.4146 - val_acc: 0.6909\n","\n","Epoch 00044: val_acc did not improve from 0.75455\n","Epoch 45/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0457 - acc: 0.9829 - val_loss: 1.5740 - val_acc: 0.6818\n","\n","Epoch 00045: val_acc did not improve from 0.75455\n","Epoch 46/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0233 - acc: 0.9922 - val_loss: 1.7036 - val_acc: 0.6818\n","\n","Epoch 00046: val_acc did not improve from 0.75455\n","Epoch 47/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0133 - acc: 0.9963 - val_loss: 1.7061 - val_acc: 0.6636\n","\n","Epoch 00047: val_acc did not improve from 0.75455\n","Epoch 48/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0135 - acc: 0.9946 - val_loss: 1.8143 - val_acc: 0.6545\n","\n","Epoch 00048: val_acc did not improve from 0.75455\n","Epoch 49/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0103 - acc: 0.9963 - val_loss: 1.8072 - val_acc: 0.6727\n","\n","Epoch 00049: val_acc did not improve from 0.75455\n","Epoch 50/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0108 - acc: 0.9973 - val_loss: 1.8641 - val_acc: 0.7000\n","\n","Epoch 00050: val_acc did not improve from 0.75455\n","Epoch 51/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0136 - acc: 0.9961 - val_loss: 1.9029 - val_acc: 0.7000\n","\n","Epoch 00051: val_acc did not improve from 0.75455\n","Epoch 52/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0129 - acc: 0.9951 - val_loss: 1.8725 - val_acc: 0.7182\n","\n","Epoch 00052: val_acc did not improve from 0.75455\n","Epoch 53/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0065 - acc: 0.9978 - val_loss: 1.9533 - val_acc: 0.6818\n","\n","Epoch 00053: val_acc did not improve from 0.75455\n","Epoch 54/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0046 - acc: 0.9990 - val_loss: 1.9013 - val_acc: 0.7000\n","\n","Epoch 00054: val_acc did not improve from 0.75455\n","Epoch 55/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0044 - acc: 0.9983 - val_loss: 1.9572 - val_acc: 0.7273\n","\n","Epoch 00055: val_acc did not improve from 0.75455\n","Epoch 56/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0038 - acc: 0.9983 - val_loss: 1.9705 - val_acc: 0.7091\n","\n","Epoch 00056: val_acc did not improve from 0.75455\n","Epoch 57/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 1.9203 - val_acc: 0.7273\n","\n","Epoch 00057: val_acc did not improve from 0.75455\n","Epoch 58/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0037 - acc: 0.9990 - val_loss: 1.9551 - val_acc: 0.6818\n","\n","Epoch 00058: val_acc did not improve from 0.75455\n","Epoch 59/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0025 - acc: 0.9993 - val_loss: 1.9096 - val_acc: 0.6909\n","\n","Epoch 00059: val_acc did not improve from 0.75455\n","Epoch 60/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 2.0633 - val_acc: 0.7182\n","\n","Epoch 00060: val_acc did not improve from 0.75455\n","Epoch 61/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0023 - acc: 0.9993 - val_loss: 2.1498 - val_acc: 0.7000\n","\n","Epoch 00061: val_acc did not improve from 0.75455\n","Epoch 62/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0047 - acc: 0.9985 - val_loss: 2.1007 - val_acc: 0.7000\n","\n","Epoch 00062: val_acc did not improve from 0.75455\n","Epoch 63/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0056 - acc: 0.9978 - val_loss: 2.0145 - val_acc: 0.7273\n","\n","Epoch 00063: val_acc did not improve from 0.75455\n","Epoch 64/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0166 - acc: 0.9956 - val_loss: 2.1372 - val_acc: 0.7091\n","\n","Epoch 00064: val_acc did not improve from 0.75455\n","Epoch 65/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0074 - acc: 0.9971 - val_loss: 2.1024 - val_acc: 0.7000\n","\n","Epoch 00065: val_acc did not improve from 0.75455\n","Epoch 66/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0118 - acc: 0.9973 - val_loss: 2.2061 - val_acc: 0.6636\n","\n","Epoch 00066: val_acc did not improve from 0.75455\n","Epoch 67/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0311 - acc: 0.9934 - val_loss: 2.3541 - val_acc: 0.6818\n","\n","Epoch 00067: val_acc did not improve from 0.75455\n","Epoch 68/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0126 - acc: 0.9963 - val_loss: 2.0827 - val_acc: 0.7000\n","\n","Epoch 00068: val_acc did not improve from 0.75455\n","Epoch 69/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0102 - acc: 0.9968 - val_loss: 1.9240 - val_acc: 0.6636\n","\n","Epoch 00069: val_acc did not improve from 0.75455\n","Epoch 70/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0070 - acc: 0.9988 - val_loss: 2.0891 - val_acc: 0.6636\n","\n","Epoch 00070: val_acc did not improve from 0.75455\n","Epoch 71/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0079 - acc: 0.9980 - val_loss: 1.9339 - val_acc: 0.6818\n","\n","Epoch 00071: val_acc did not improve from 0.75455\n","Epoch 72/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0052 - acc: 0.9980 - val_loss: 2.1014 - val_acc: 0.6909\n","\n","Epoch 00072: val_acc did not improve from 0.75455\n","Epoch 73/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0037 - acc: 0.9995 - val_loss: 2.1762 - val_acc: 0.6909\n","\n","Epoch 00073: val_acc did not improve from 0.75455\n","Epoch 74/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0341 - acc: 0.9857 - val_loss: 3.0612 - val_acc: 0.6273\n","\n","Epoch 00074: val_acc did not improve from 0.75455\n","Epoch 75/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.1044 - acc: 0.9699 - val_loss: 2.2016 - val_acc: 0.6182\n","\n","Epoch 00075: val_acc did not improve from 0.75455\n","Epoch 76/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0148 - acc: 0.9954 - val_loss: 2.2207 - val_acc: 0.6455\n","\n","Epoch 00076: val_acc did not improve from 0.75455\n","Epoch 77/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0123 - acc: 0.9963 - val_loss: 2.3595 - val_acc: 0.6273\n","\n","Epoch 00077: val_acc did not improve from 0.75455\n","Epoch 78/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0076 - acc: 0.9980 - val_loss: 2.2649 - val_acc: 0.6636\n","\n","Epoch 00078: val_acc did not improve from 0.75455\n","Epoch 79/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0049 - acc: 0.9973 - val_loss: 2.3547 - val_acc: 0.6636\n","\n","Epoch 00079: val_acc did not improve from 0.75455\n","Epoch 80/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0032 - acc: 0.9990 - val_loss: 2.3970 - val_acc: 0.6545\n","\n","Epoch 00080: val_acc did not improve from 0.75455\n","Epoch 81/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0054 - acc: 0.9985 - val_loss: 2.3436 - val_acc: 0.6545\n","\n","Epoch 00081: val_acc did not improve from 0.75455\n","Epoch 82/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0033 - acc: 0.9990 - val_loss: 2.4953 - val_acc: 0.6455\n","\n","Epoch 00082: val_acc did not improve from 0.75455\n","Epoch 83/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0138 - acc: 0.9963 - val_loss: 2.4869 - val_acc: 0.6636\n","\n","Epoch 00083: val_acc did not improve from 0.75455\n","Epoch 84/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0057 - acc: 0.9973 - val_loss: 2.4262 - val_acc: 0.6818\n","\n","Epoch 00084: val_acc did not improve from 0.75455\n","Epoch 85/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0077 - acc: 0.9973 - val_loss: 2.4269 - val_acc: 0.6727\n","\n","Epoch 00085: val_acc did not improve from 0.75455\n","Epoch 86/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0056 - acc: 0.9973 - val_loss: 2.3890 - val_acc: 0.6818\n","\n","Epoch 00086: val_acc did not improve from 0.75455\n","Epoch 87/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0020 - acc: 0.9998 - val_loss: 2.3249 - val_acc: 0.6727\n","\n","Epoch 00087: val_acc did not improve from 0.75455\n","Epoch 88/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 2.3201 - val_acc: 0.6727\n","\n","Epoch 00088: val_acc did not improve from 0.75455\n","Epoch 89/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0021 - acc: 0.9993 - val_loss: 2.3333 - val_acc: 0.6636\n","\n","Epoch 00089: val_acc did not improve from 0.75455\n","Epoch 90/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0015 - acc: 0.9998 - val_loss: 2.3233 - val_acc: 0.7000\n","\n","Epoch 00090: val_acc did not improve from 0.75455\n","Epoch 91/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0018 - acc: 0.9993 - val_loss: 2.2980 - val_acc: 0.6727\n","\n","Epoch 00091: val_acc did not improve from 0.75455\n","Epoch 92/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 2.3242 - val_acc: 0.6818\n","\n","Epoch 00092: val_acc did not improve from 0.75455\n","Epoch 93/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 2.2750 - val_acc: 0.6818\n","\n","Epoch 00093: val_acc did not improve from 0.75455\n","Epoch 94/100\n","64/64 [==============================] - 3s 44ms/step - loss: 4.7696e-04 - acc: 1.0000 - val_loss: 2.3054 - val_acc: 0.6818\n","\n","Epoch 00094: val_acc did not improve from 0.75455\n","Epoch 95/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0054 - acc: 0.9985 - val_loss: 2.3364 - val_acc: 0.7000\n","\n","Epoch 00095: val_acc did not improve from 0.75455\n","Epoch 96/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0024 - acc: 0.9990 - val_loss: 2.4406 - val_acc: 0.6909\n","\n","Epoch 00096: val_acc did not improve from 0.75455\n","Epoch 97/100\n","64/64 [==============================] - 3s 44ms/step - loss: 0.0014 - acc: 0.9995 - val_loss: 2.4771 - val_acc: 0.6727\n","\n","Epoch 00097: val_acc did not improve from 0.75455\n","Epoch 98/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0028 - acc: 0.9985 - val_loss: 2.3008 - val_acc: 0.6545\n","\n","Epoch 00098: val_acc did not improve from 0.75455\n","Epoch 99/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0027 - acc: 0.9988 - val_loss: 2.6274 - val_acc: 0.6636\n","\n","Epoch 00099: val_acc did not improve from 0.75455\n","Epoch 100/100\n","64/64 [==============================] - 3s 45ms/step - loss: 0.0041 - acc: 0.9983 - val_loss: 2.5733 - val_acc: 0.6818\n","\n","Epoch 00100: val_acc did not improve from 0.75455\n","\n","<keras.callbacks.History at 0x7f3a0c0c8da0>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Htxb1n-a-BTP","colab_type":"code","colab":{}},"cell_type":"code","source":["#five our6-22 77.38\n","\n","Epoch 1/100\n","64/64 [==============================] - 4s 57ms/step - loss: 1.5673 - acc: 0.2865 - val_loss: 1.5267 - val_acc: 0.3690\n","\n","Epoch 00001: val_acc improved from -inf to 0.36905, saving model to result/all/five/new/OUR6-22/epoch-01-val-acc-0.3690.hdf5\n","Epoch 2/100\n","64/64 [==============================] - 3s 48ms/step - loss: 1.1761 - acc: 0.5169 - val_loss: 0.9396 - val_acc: 0.6190\n","\n","Epoch 00002: val_acc improved from 0.36905 to 0.61905, saving model to result/all/five/new/OUR6-22/epoch-02-val-acc-0.6190.hdf5\n","Epoch 3/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.7180 - acc: 0.7227 - val_loss: 1.0184 - val_acc: 0.6190\n","\n","Epoch 00003: val_acc did not improve from 0.61905\n","Epoch 4/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.4228 - acc: 0.8498 - val_loss: 0.8692 - val_acc: 0.6667\n","\n","Epoch 00004: val_acc improved from 0.61905 to 0.66667, saving model to result/all/five/new/OUR6-22/epoch-04-val-acc-0.6667.hdf5\n","Epoch 5/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.3117 - acc: 0.8881 - val_loss: 1.0873 - val_acc: 0.6786\n","\n","Epoch 00005: val_acc improved from 0.66667 to 0.67857, saving model to result/all/five/new/OUR6-22/epoch-05-val-acc-0.6786.hdf5\n","Epoch 6/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.1646 - acc: 0.9424 - val_loss: 1.2815 - val_acc: 0.6786\n","\n","Epoch 00006: val_acc did not improve from 0.67857\n","Epoch 7/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.1273 - acc: 0.9556 - val_loss: 1.5488 - val_acc: 0.6190\n","\n","Epoch 00007: val_acc did not improve from 0.67857\n","Epoch 8/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0945 - acc: 0.9681 - val_loss: 1.3814 - val_acc: 0.6905\n","\n","Epoch 00008: val_acc improved from 0.67857 to 0.69048, saving model to result/all/five/new/OUR6-22/epoch-08-val-acc-0.6905.hdf5\n","Epoch 9/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0945 - acc: 0.9673 - val_loss: 1.3630 - val_acc: 0.6905\n","\n","Epoch 00009: val_acc improved from 0.69048 to 0.69048, saving model to result/all/five/new/OUR6-22/epoch-09-val-acc-0.6905.hdf5\n","Epoch 10/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0822 - acc: 0.9710 - val_loss: 1.7780 - val_acc: 0.6071\n","\n","Epoch 00010: val_acc did not improve from 0.69048\n","Epoch 11/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0683 - acc: 0.9758 - val_loss: 1.3240 - val_acc: 0.7024\n","\n","Epoch 00011: val_acc improved from 0.69048 to 0.70238, saving model to result/all/five/new/OUR6-22/epoch-11-val-acc-0.7024.hdf5\n","Epoch 12/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0537 - acc: 0.9842 - val_loss: 1.5561 - val_acc: 0.6310\n","\n","Epoch 00012: val_acc did not improve from 0.70238\n","Epoch 13/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0388 - acc: 0.9879 - val_loss: 1.5049 - val_acc: 0.6786\n","\n","Epoch 00013: val_acc did not improve from 0.70238\n","Epoch 14/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0456 - acc: 0.9860 - val_loss: 2.0336 - val_acc: 0.6310\n","\n","Epoch 00014: val_acc did not improve from 0.70238\n","Epoch 15/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0579 - acc: 0.9821 - val_loss: 1.4092 - val_acc: 0.6667\n","\n","Epoch 00015: val_acc did not improve from 0.70238\n","Epoch 16/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0317 - acc: 0.9887 - val_loss: 1.7337 - val_acc: 0.6786\n","\n","Epoch 00016: val_acc did not improve from 0.70238\n","Epoch 17/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0326 - acc: 0.9882 - val_loss: 1.9236 - val_acc: 0.6310\n","\n","Epoch 00017: val_acc did not improve from 0.70238\n","Epoch 18/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0541 - acc: 0.9848 - val_loss: 1.4786 - val_acc: 0.7024\n","\n","Epoch 00018: val_acc did not improve from 0.70238\n","Epoch 19/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0710 - acc: 0.9792 - val_loss: 1.5451 - val_acc: 0.6429\n","\n","Epoch 00019: val_acc did not improve from 0.70238\n","Epoch 20/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0239 - acc: 0.9912 - val_loss: 1.9949 - val_acc: 0.7143\n","\n","Epoch 00020: val_acc improved from 0.70238 to 0.71429, saving model to result/all/five/new/OUR6-22/epoch-20-val-acc-0.7143.hdf5\n","Epoch 21/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0139 - acc: 0.9951 - val_loss: 1.8531 - val_acc: 0.6548\n","\n","Epoch 00021: val_acc did not improve from 0.71429\n","Epoch 22/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0202 - acc: 0.9938 - val_loss: 1.9187 - val_acc: 0.6905\n","\n","Epoch 00022: val_acc did not improve from 0.71429\n","Epoch 23/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0123 - acc: 0.9963 - val_loss: 2.0857 - val_acc: 0.6190\n","\n","Epoch 00023: val_acc did not improve from 0.71429\n","Epoch 24/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0656 - acc: 0.9802 - val_loss: 2.0910 - val_acc: 0.7024\n","\n","Epoch 00024: val_acc did not improve from 0.71429\n","Epoch 25/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0448 - acc: 0.9835 - val_loss: 1.8430 - val_acc: 0.6429\n","\n","Epoch 00025: val_acc did not improve from 0.71429\n","Epoch 26/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0433 - acc: 0.9855 - val_loss: 1.7525 - val_acc: 0.6667\n","\n","Epoch 00026: val_acc did not improve from 0.71429\n","Epoch 27/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0370 - acc: 0.9883 - val_loss: 1.9176 - val_acc: 0.6190\n","\n","Epoch 00027: val_acc did not improve from 0.71429\n","Epoch 28/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0276 - acc: 0.9910 - val_loss: 1.7160 - val_acc: 0.6548\n","\n","Epoch 00028: val_acc did not improve from 0.71429\n","Epoch 29/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0197 - acc: 0.9932 - val_loss: 1.9633 - val_acc: 0.6548\n","\n","Epoch 00029: val_acc did not improve from 0.71429\n","Epoch 30/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0270 - acc: 0.9919 - val_loss: 1.7426 - val_acc: 0.6786\n","\n","Epoch 00030: val_acc did not improve from 0.71429\n","Epoch 31/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0343 - acc: 0.9891 - val_loss: 2.0555 - val_acc: 0.6429\n","\n","Epoch 00031: val_acc did not improve from 0.71429\n","Epoch 32/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0212 - acc: 0.9941 - val_loss: 1.9849 - val_acc: 0.7024\n","\n","Epoch 00032: val_acc did not improve from 0.71429\n","Epoch 33/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0124 - acc: 0.9949 - val_loss: 2.0687 - val_acc: 0.6786\n","\n","Epoch 00033: val_acc did not improve from 0.71429\n","Epoch 34/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0199 - acc: 0.9934 - val_loss: 1.9383 - val_acc: 0.6905\n","\n","Epoch 00034: val_acc did not improve from 0.71429\n","Epoch 35/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0336 - acc: 0.9878 - val_loss: 2.3828 - val_acc: 0.7024\n","\n","Epoch 00035: val_acc did not improve from 0.71429\n","Epoch 36/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0685 - acc: 0.9775 - val_loss: 2.4766 - val_acc: 0.6310\n","\n","Epoch 00036: val_acc did not improve from 0.71429\n","Epoch 37/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0610 - acc: 0.9840 - val_loss: 2.3177 - val_acc: 0.6905\n","\n","Epoch 00037: val_acc did not improve from 0.71429\n","Epoch 38/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0305 - acc: 0.9900 - val_loss: 1.8590 - val_acc: 0.6786\n","\n","Epoch 00038: val_acc did not improve from 0.71429\n","Epoch 39/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0214 - acc: 0.9936 - val_loss: 1.8265 - val_acc: 0.6905\n","\n","Epoch 00039: val_acc did not improve from 0.71429\n","Epoch 40/100\n","64/64 [==============================] - 3s 48ms/step - loss: 0.0125 - acc: 0.9954 - val_loss: 1.9992 - val_acc: 0.6905\n","\n","Epoch 00040: val_acc did not improve from 0.71429\n","Epoch 41/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0163 - acc: 0.9941 - val_loss: 2.2527 - val_acc: 0.6905\n","\n","Epoch 00041: val_acc did not improve from 0.71429\n","Epoch 42/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0158 - acc: 0.9951 - val_loss: 2.0760 - val_acc: 0.6667\n","\n","Epoch 00042: val_acc did not improve from 0.71429\n","Epoch 43/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0037 - acc: 0.9990 - val_loss: 1.8997 - val_acc: 0.6905\n","\n","Epoch 00043: val_acc did not improve from 0.71429\n","Epoch 44/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0097 - acc: 0.9960 - val_loss: 1.9726 - val_acc: 0.6429\n","\n","Epoch 00044: val_acc did not improve from 0.71429\n","Epoch 45/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0131 - acc: 0.9956 - val_loss: 2.3356 - val_acc: 0.6905\n","\n","Epoch 00045: val_acc did not improve from 0.71429\n","Epoch 46/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0379 - acc: 0.9889 - val_loss: 2.6432 - val_acc: 0.6786\n","\n","Epoch 00046: val_acc did not improve from 0.71429\n","Epoch 47/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0234 - acc: 0.9924 - val_loss: 2.4949 - val_acc: 0.6786\n","\n","Epoch 00047: val_acc did not improve from 0.71429\n","Epoch 48/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0279 - acc: 0.9916 - val_loss: 2.3734 - val_acc: 0.6429\n","\n","Epoch 00048: val_acc did not improve from 0.71429\n","Epoch 49/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0348 - acc: 0.9890 - val_loss: 2.4318 - val_acc: 0.6310\n","\n","Epoch 00049: val_acc did not improve from 0.71429\n","Epoch 50/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0371 - acc: 0.9914 - val_loss: 2.3052 - val_acc: 0.6667\n","\n","Epoch 00050: val_acc did not improve from 0.71429\n","Epoch 51/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0216 - acc: 0.9919 - val_loss: 2.1855 - val_acc: 0.7381\n","\n","Epoch 00051: val_acc improved from 0.71429 to 0.73810, saving model to result/all/five/new/OUR6-22/epoch-51-val-acc-0.7381.hdf5\n","Epoch 52/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0168 - acc: 0.9948 - val_loss: 2.1865 - val_acc: 0.6786\n","\n","Epoch 00052: val_acc did not improve from 0.73810\n","Epoch 53/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0214 - acc: 0.9933 - val_loss: 2.1225 - val_acc: 0.6905\n","\n","Epoch 00053: val_acc did not improve from 0.73810\n","Epoch 54/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0288 - acc: 0.9912 - val_loss: 1.8968 - val_acc: 0.6786\n","\n","Epoch 00054: val_acc did not improve from 0.73810\n","Epoch 55/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0275 - acc: 0.9932 - val_loss: 2.0801 - val_acc: 0.6905\n","\n","Epoch 00055: val_acc did not improve from 0.73810\n","Epoch 56/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0111 - acc: 0.9971 - val_loss: 1.9686 - val_acc: 0.6786\n","\n","Epoch 00056: val_acc did not improve from 0.73810\n","Epoch 57/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0138 - acc: 0.9953 - val_loss: 2.2871 - val_acc: 0.6548\n","\n","Epoch 00057: val_acc did not improve from 0.73810\n","Epoch 58/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0164 - acc: 0.9943 - val_loss: 2.2327 - val_acc: 0.6667\n","\n","Epoch 00058: val_acc did not improve from 0.73810\n","Epoch 59/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0093 - acc: 0.9958 - val_loss: 2.2297 - val_acc: 0.6667\n","\n","Epoch 00059: val_acc did not improve from 0.73810\n","Epoch 60/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0115 - acc: 0.9971 - val_loss: 2.4073 - val_acc: 0.6905\n","\n","Epoch 00060: val_acc did not improve from 0.73810\n","Epoch 61/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0112 - acc: 0.9973 - val_loss: 2.1377 - val_acc: 0.7024\n","\n","Epoch 00061: val_acc did not improve from 0.73810\n","Epoch 62/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0079 - acc: 0.9978 - val_loss: 2.0651 - val_acc: 0.7024\n","\n","Epoch 00062: val_acc did not improve from 0.73810\n","Epoch 63/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0062 - acc: 0.9972 - val_loss: 1.9426 - val_acc: 0.7262\n","\n","Epoch 00063: val_acc did not improve from 0.73810\n","Epoch 64/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0180 - acc: 0.9938 - val_loss: 2.0126 - val_acc: 0.6905\n","\n","Epoch 00064: val_acc did not improve from 0.73810\n","Epoch 65/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0547 - acc: 0.9879 - val_loss: 2.0901 - val_acc: 0.7262\n","\n","Epoch 00065: val_acc did not improve from 0.73810\n","Epoch 66/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0546 - acc: 0.9847 - val_loss: 1.8193 - val_acc: 0.7500\n","\n","Epoch 00066: val_acc improved from 0.73810 to 0.75000, saving model to result/all/five/new/OUR6-22/epoch-66-val-acc-0.7500.hdf5\n","Epoch 67/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0296 - acc: 0.9914 - val_loss: 2.1803 - val_acc: 0.7619\n","\n","Epoch 00067: val_acc improved from 0.75000 to 0.76190, saving model to result/all/five/new/OUR6-22/epoch-67-val-acc-0.7619.hdf5\n","Epoch 68/100\n","64/64 [==============================] - 3s 48ms/step - loss: 0.0305 - acc: 0.9924 - val_loss: 2.3580 - val_acc: 0.6786\n","\n","Epoch 00068: val_acc did not improve from 0.76190\n","Epoch 69/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0234 - acc: 0.9932 - val_loss: 2.3460 - val_acc: 0.7262\n","\n","Epoch 00069: val_acc did not improve from 0.76190\n","Epoch 70/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0127 - acc: 0.9951 - val_loss: 2.4218 - val_acc: 0.6905\n","\n","Epoch 00070: val_acc did not improve from 0.76190\n","Epoch 71/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0171 - acc: 0.9951 - val_loss: 2.3685 - val_acc: 0.6786\n","\n","Epoch 00071: val_acc did not improve from 0.76190\n","Epoch 72/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0372 - acc: 0.9914 - val_loss: 2.3303 - val_acc: 0.6667\n","\n","Epoch 00072: val_acc did not improve from 0.76190\n","Epoch 73/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0107 - acc: 0.9958 - val_loss: 2.0259 - val_acc: 0.7381\n","\n","Epoch 00073: val_acc did not improve from 0.76190\n","Epoch 74/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0106 - acc: 0.9966 - val_loss: 2.3047 - val_acc: 0.7262\n","\n","Epoch 00074: val_acc did not improve from 0.76190\n","Epoch 75/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0088 - acc: 0.9970 - val_loss: 2.4205 - val_acc: 0.7024\n","\n","Epoch 00075: val_acc did not improve from 0.76190\n","Epoch 76/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0043 - acc: 0.9990 - val_loss: 2.4672 - val_acc: 0.6429\n","\n","Epoch 00076: val_acc did not improve from 0.76190\n","Epoch 77/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0081 - acc: 0.9980 - val_loss: 2.4133 - val_acc: 0.6429\n","\n","Epoch 00077: val_acc did not improve from 0.76190\n","Epoch 78/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0159 - acc: 0.9953 - val_loss: 2.2227 - val_acc: 0.7024\n","\n","Epoch 00078: val_acc did not improve from 0.76190\n","Epoch 79/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0100 - acc: 0.9973 - val_loss: 2.5787 - val_acc: 0.6905\n","\n","Epoch 00079: val_acc did not improve from 0.76190\n","Epoch 80/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0186 - acc: 0.9944 - val_loss: 2.3989 - val_acc: 0.7143\n","\n","Epoch 00080: val_acc did not improve from 0.76190\n","Epoch 81/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0074 - acc: 0.9978 - val_loss: 2.7920 - val_acc: 0.7143\n","\n","Epoch 00081: val_acc did not improve from 0.76190\n","Epoch 82/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0282 - acc: 0.9923 - val_loss: 2.4549 - val_acc: 0.7143\n","\n","Epoch 00082: val_acc did not improve from 0.76190\n","Epoch 83/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0228 - acc: 0.9936 - val_loss: 2.2929 - val_acc: 0.7143\n","\n","Epoch 00083: val_acc did not improve from 0.76190\n","Epoch 84/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0102 - acc: 0.9968 - val_loss: 2.0905 - val_acc: 0.7381\n","\n","Epoch 00084: val_acc did not improve from 0.76190\n","Epoch 85/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0133 - acc: 0.9958 - val_loss: 1.9728 - val_acc: 0.7738\n","\n","Epoch 00085: val_acc improved from 0.76190 to 0.77381, saving model to result/all/five/new/OUR6-22/epoch-85-val-acc-0.7738.hdf5\n","Epoch 86/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0140 - acc: 0.9958 - val_loss: 2.3714 - val_acc: 0.6667\n","\n","Epoch 00086: val_acc did not improve from 0.77381\n","Epoch 87/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0126 - acc: 0.9970 - val_loss: 2.4614 - val_acc: 0.6905\n","\n","Epoch 00087: val_acc did not improve from 0.77381\n","Epoch 88/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0066 - acc: 0.9976 - val_loss: 2.0050 - val_acc: 0.7500\n","\n","Epoch 00088: val_acc did not improve from 0.77381\n","Epoch 89/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0291 - acc: 0.9935 - val_loss: 2.2504 - val_acc: 0.7619\n","\n","Epoch 00089: val_acc did not improve from 0.77381\n","Epoch 90/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0288 - acc: 0.9914 - val_loss: 2.0579 - val_acc: 0.6786\n","\n","Epoch 00090: val_acc did not improve from 0.77381\n","Epoch 91/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0408 - acc: 0.9898 - val_loss: 2.0609 - val_acc: 0.7024\n","\n","Epoch 00091: val_acc did not improve from 0.77381\n","Epoch 92/100\n","64/64 [==============================] - 3s 47ms/step - loss: 0.0125 - acc: 0.9956 - val_loss: 2.1785 - val_acc: 0.7500\n","\n","Epoch 00092: val_acc did not improve from 0.77381\n","Epoch 93/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0077 - acc: 0.9982 - val_loss: 2.3598 - val_acc: 0.7024\n","\n","Epoch 00093: val_acc did not improve from 0.77381\n","Epoch 94/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0186 - acc: 0.9951 - val_loss: 2.7578 - val_acc: 0.6786\n","\n","Epoch 00094: val_acc did not improve from 0.77381\n","Epoch 95/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0253 - acc: 0.9940 - val_loss: 1.8138 - val_acc: 0.7500\n","\n","Epoch 00095: val_acc did not improve from 0.77381\n","Epoch 96/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0327 - acc: 0.9908 - val_loss: 2.2365 - val_acc: 0.7024\n","\n","Epoch 00096: val_acc did not improve from 0.77381\n","Epoch 97/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0220 - acc: 0.9938 - val_loss: 2.2565 - val_acc: 0.7262\n","\n","Epoch 00097: val_acc did not improve from 0.77381\n","Epoch 98/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0285 - acc: 0.9925 - val_loss: 2.6735 - val_acc: 0.6905\n","\n","Epoch 00098: val_acc did not improve from 0.77381\n","Epoch 99/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0163 - acc: 0.9936 - val_loss: 2.3577 - val_acc: 0.6905\n","\n","Epoch 00099: val_acc did not improve from 0.77381\n","Epoch 100/100\n","64/64 [==============================] - 3s 46ms/step - loss: 0.0070 - acc: 0.9973 - val_loss: 2.2823 - val_acc: 0.7619\n","\n","Epoch 00100: val_acc did not improve from 0.77381\n","\n","<keras.callbacks.History at 0x7f93822c6438>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KUh0FH9MnmwN","colab_type":"code","colab":{}},"cell_type":"code","source":["five all 72.62\n","\n","\n","\n","Epoch 1/100\n","16/16 [==============================] - 1s 77ms/step - loss: 1.5885 - acc: 0.2639 - val_loss: 1.5954 - val_acc: 0.2619\n","\n","Epoch 00001: val_acc improved from -inf to 0.26190, saving model to result/all/five/new/OUR6-5/epoch-01-val-acc-0.2619.hdf5\n","Epoch 2/100\n","16/16 [==============================] - 1s 48ms/step - loss: 1.5697 - acc: 0.2654 - val_loss: 1.5876 - val_acc: 0.2619\n","\n","Epoch 00002: val_acc improved from 0.26190 to 0.26190, saving model to result/all/five/new/OUR6-5/epoch-02-val-acc-0.2619.hdf5\n","Epoch 3/100\n","16/16 [==============================] - 1s 51ms/step - loss: 1.5628 - acc: 0.2797 - val_loss: 1.5808 - val_acc: 0.2619\n","\n","Epoch 00003: val_acc did not improve from 0.26190\n","Epoch 4/100\n","16/16 [==============================] - 1s 46ms/step - loss: 1.5615 - acc: 0.2829 - val_loss: 1.5725 - val_acc: 0.2738\n","\n","Epoch 00004: val_acc improved from 0.26190 to 0.27381, saving model to result/all/five/new/OUR6-5/epoch-04-val-acc-0.2738.hdf5\n","Epoch 5/100\n","16/16 [==============================] - 1s 48ms/step - loss: 1.5553 - acc: 0.2686 - val_loss: 1.5785 - val_acc: 0.2738\n","\n","Epoch 00005: val_acc did not improve from 0.27381\n","Epoch 6/100\n","16/16 [==============================] - 1s 45ms/step - loss: 1.5553 - acc: 0.3036 - val_loss: 1.5824 - val_acc: 0.2619\n","\n","Epoch 00006: val_acc did not improve from 0.27381\n","Epoch 7/100\n","16/16 [==============================] - 1s 47ms/step - loss: 1.5505 - acc: 0.2938 - val_loss: 1.5610 - val_acc: 0.2738\n","\n","Epoch 00007: val_acc improved from 0.27381 to 0.27381, saving model to result/all/five/new/OUR6-5/epoch-07-val-acc-0.2738.hdf5\n","Epoch 8/100\n","16/16 [==============================] - 1s 45ms/step - loss: 1.5459 - acc: 0.3201 - val_loss: 1.5618 - val_acc: 0.2619\n","\n","Epoch 00008: val_acc did not improve from 0.27381\n","Epoch 9/100\n","16/16 [==============================] - 1s 48ms/step - loss: 1.5219 - acc: 0.3262 - val_loss: 1.5895 - val_acc: 0.2619\n","\n","Epoch 00009: val_acc did not improve from 0.27381\n","Epoch 10/100\n","16/16 [==============================] - 1s 44ms/step - loss: 1.5381 - acc: 0.2696 - val_loss: 1.5356 - val_acc: 0.3690\n","\n","Epoch 00010: val_acc improved from 0.27381 to 0.36905, saving model to result/all/five/new/OUR6-5/epoch-10-val-acc-0.3690.hdf5\n","Epoch 11/100\n","16/16 [==============================] - 1s 46ms/step - loss: 1.5342 - acc: 0.3181 - val_loss: 1.5110 - val_acc: 0.4167\n","\n","Epoch 00011: val_acc improved from 0.36905 to 0.41667, saving model to result/all/five/new/OUR6-5/epoch-11-val-acc-0.4167.hdf5\n","Epoch 12/100\n","16/16 [==============================] - 1s 47ms/step - loss: 1.5092 - acc: 0.3699 - val_loss: 1.4822 - val_acc: 0.4048\n","\n","Epoch 00012: val_acc did not improve from 0.41667\n","Epoch 13/100\n","16/16 [==============================] - 1s 45ms/step - loss: 1.4899 - acc: 0.3604 - val_loss: 1.4574 - val_acc: 0.3929\n","\n","Epoch 00013: val_acc did not improve from 0.41667\n","Epoch 14/100\n","16/16 [==============================] - 1s 48ms/step - loss: 1.4510 - acc: 0.4056 - val_loss: 1.4342 - val_acc: 0.4286\n","\n","Epoch 00014: val_acc improved from 0.41667 to 0.42857, saving model to result/all/five/new/OUR6-5/epoch-14-val-acc-0.4286.hdf5\n","Epoch 15/100\n","16/16 [==============================] - 1s 45ms/step - loss: 1.4453 - acc: 0.3783 - val_loss: 1.4383 - val_acc: 0.4048\n","\n","Epoch 00015: val_acc did not improve from 0.42857\n","Epoch 16/100\n","16/16 [==============================] - 1s 47ms/step - loss: 1.4037 - acc: 0.4105 - val_loss: 1.3348 - val_acc: 0.4881\n","\n","Epoch 00016: val_acc improved from 0.42857 to 0.48810, saving model to result/all/five/new/OUR6-5/epoch-16-val-acc-0.4881.hdf5\n","Epoch 17/100\n","16/16 [==============================] - 1s 48ms/step - loss: 1.3628 - acc: 0.4640 - val_loss: 1.4032 - val_acc: 0.4286\n","\n","Epoch 00017: val_acc did not improve from 0.48810\n","Epoch 18/100\n","16/16 [==============================] - 1s 47ms/step - loss: 1.3415 - acc: 0.4461 - val_loss: 1.4487 - val_acc: 0.3690\n","\n","Epoch 00018: val_acc did not improve from 0.48810\n","Epoch 19/100\n","16/16 [==============================] - 1s 45ms/step - loss: 1.3421 - acc: 0.4459 - val_loss: 1.2719 - val_acc: 0.5595\n","\n","Epoch 00019: val_acc improved from 0.48810 to 0.55952, saving model to result/all/five/new/OUR6-5/epoch-19-val-acc-0.5595.hdf5\n","Epoch 20/100\n","16/16 [==============================] - 1s 49ms/step - loss: 1.2835 - acc: 0.4961 - val_loss: 1.2055 - val_acc: 0.5595\n","\n","Epoch 00020: val_acc improved from 0.55952 to 0.55952, saving model to result/all/five/new/OUR6-5/epoch-20-val-acc-0.5595.hdf5\n","Epoch 21/100\n","16/16 [==============================] - 1s 45ms/step - loss: 1.2306 - acc: 0.5375 - val_loss: 1.1905 - val_acc: 0.5595\n","\n","Epoch 00021: val_acc did not improve from 0.55952\n","Epoch 22/100\n","16/16 [==============================] - 1s 44ms/step - loss: 1.2310 - acc: 0.5035 - val_loss: 1.1459 - val_acc: 0.5595\n","\n","Epoch 00022: val_acc did not improve from 0.55952\n","Epoch 23/100\n","16/16 [==============================] - 1s 47ms/step - loss: 1.1973 - acc: 0.5205 - val_loss: 1.1379 - val_acc: 0.5476\n","\n","Epoch 00023: val_acc did not improve from 0.55952\n","Epoch 24/100\n","16/16 [==============================] - 1s 47ms/step - loss: 1.2202 - acc: 0.5001 - val_loss: 1.2475 - val_acc: 0.4762\n","\n","Epoch 00024: val_acc did not improve from 0.55952\n","Epoch 25/100\n","16/16 [==============================] - 1s 48ms/step - loss: 1.1541 - acc: 0.5491 - val_loss: 1.1397 - val_acc: 0.5714\n","\n","Epoch 00025: val_acc improved from 0.55952 to 0.57143, saving model to result/all/five/new/OUR6-5/epoch-25-val-acc-0.5714.hdf5\n","Epoch 26/100\n","16/16 [==============================] - 1s 44ms/step - loss: 1.1370 - acc: 0.5684 - val_loss: 1.0591 - val_acc: 0.6310\n","\n","Epoch 00026: val_acc improved from 0.57143 to 0.63095, saving model to result/all/five/new/OUR6-5/epoch-26-val-acc-0.6310.hdf5\n","Epoch 27/100\n","16/16 [==============================] - 1s 48ms/step - loss: 1.0772 - acc: 0.6095 - val_loss: 1.0684 - val_acc: 0.6429\n","\n","Epoch 00027: val_acc improved from 0.63095 to 0.64286, saving model to result/all/five/new/OUR6-5/epoch-27-val-acc-0.6429.hdf5\n","Epoch 28/100\n","16/16 [==============================] - 1s 44ms/step - loss: 1.0537 - acc: 0.5964 - val_loss: 1.0508 - val_acc: 0.5952\n","\n","Epoch 00028: val_acc did not improve from 0.64286\n","Epoch 29/100\n","16/16 [==============================] - 1s 48ms/step - loss: 1.0117 - acc: 0.6261 - val_loss: 1.0586 - val_acc: 0.6071\n","\n","Epoch 00029: val_acc did not improve from 0.64286\n","Epoch 30/100\n","16/16 [==============================] - 1s 43ms/step - loss: 0.9890 - acc: 0.6319 - val_loss: 0.9963 - val_acc: 0.6190\n","\n","Epoch 00030: val_acc did not improve from 0.64286\n","Epoch 31/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.9686 - acc: 0.6433 - val_loss: 1.0377 - val_acc: 0.6071\n","\n","Epoch 00031: val_acc did not improve from 0.64286\n","Epoch 32/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.9811 - acc: 0.6198 - val_loss: 1.0028 - val_acc: 0.6071\n","\n","Epoch 00032: val_acc did not improve from 0.64286\n","Epoch 33/100\n","16/16 [==============================] - 1s 44ms/step - loss: 0.9610 - acc: 0.6312 - val_loss: 1.0255 - val_acc: 0.6071\n","\n","Epoch 00033: val_acc did not improve from 0.64286\n","Epoch 34/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.9402 - acc: 0.6449 - val_loss: 1.0352 - val_acc: 0.5952\n","\n","Epoch 00034: val_acc did not improve from 0.64286\n","Epoch 35/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.8858 - acc: 0.6749 - val_loss: 0.9800 - val_acc: 0.6071\n","\n","Epoch 00035: val_acc did not improve from 0.64286\n","Epoch 36/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.8748 - acc: 0.6675 - val_loss: 0.9920 - val_acc: 0.5952\n","\n","Epoch 00036: val_acc did not improve from 0.64286\n","Epoch 37/100\n","16/16 [==============================] - 1s 44ms/step - loss: 0.8638 - acc: 0.6727 - val_loss: 0.9791 - val_acc: 0.6190\n","\n","Epoch 00037: val_acc did not improve from 0.64286\n","Epoch 38/100\n","16/16 [==============================] - 1s 47ms/step - loss: 0.8690 - acc: 0.6835 - val_loss: 0.9723 - val_acc: 0.6071\n","\n","Epoch 00038: val_acc did not improve from 0.64286\n","Epoch 39/100\n","16/16 [==============================] - 1s 44ms/step - loss: 0.8927 - acc: 0.6407 - val_loss: 0.9739 - val_acc: 0.6190\n","\n","Epoch 00039: val_acc did not improve from 0.64286\n","Epoch 40/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.8434 - acc: 0.6761 - val_loss: 0.9648 - val_acc: 0.6548\n","\n","Epoch 00040: val_acc improved from 0.64286 to 0.65476, saving model to result/all/five/new/OUR6-5/epoch-40-val-acc-0.6548.hdf5\n","Epoch 41/100\n","16/16 [==============================] - 1s 46ms/step - loss: 0.8583 - acc: 0.6640 - val_loss: 1.0805 - val_acc: 0.5833\n","\n","Epoch 00041: val_acc did not improve from 0.65476\n","Epoch 42/100\n","16/16 [==============================] - 1s 47ms/step - loss: 0.8116 - acc: 0.6922 - val_loss: 1.0119 - val_acc: 0.6310\n","\n","Epoch 00042: val_acc did not improve from 0.65476\n","Epoch 43/100\n","16/16 [==============================] - 1s 44ms/step - loss: 0.8377 - acc: 0.6859 - val_loss: 0.9685 - val_acc: 0.6190\n","\n","Epoch 00043: val_acc did not improve from 0.65476\n","Epoch 44/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.7951 - acc: 0.6861 - val_loss: 0.9847 - val_acc: 0.6071\n","\n","Epoch 00044: val_acc did not improve from 0.65476\n","Epoch 45/100\n","16/16 [==============================] - 1s 46ms/step - loss: 0.7966 - acc: 0.6970 - val_loss: 0.9567 - val_acc: 0.6310\n","\n","Epoch 00045: val_acc did not improve from 0.65476\n","Epoch 46/100\n","16/16 [==============================] - 1s 46ms/step - loss: 0.7709 - acc: 0.6992 - val_loss: 0.9284 - val_acc: 0.6548\n","\n","Epoch 00046: val_acc did not improve from 0.65476\n","Epoch 47/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.7626 - acc: 0.6999 - val_loss: 0.9494 - val_acc: 0.6667\n","\n","Epoch 00047: val_acc improved from 0.65476 to 0.66667, saving model to result/all/five/new/OUR6-5/epoch-47-val-acc-0.6667.hdf5\n","Epoch 48/100\n","16/16 [==============================] - 1s 46ms/step - loss: 0.7128 - acc: 0.7445 - val_loss: 0.9397 - val_acc: 0.6190\n","\n","Epoch 00048: val_acc did not improve from 0.66667\n","Epoch 49/100\n","16/16 [==============================] - 1s 47ms/step - loss: 0.7262 - acc: 0.7304 - val_loss: 0.9336 - val_acc: 0.6429\n","\n","Epoch 00049: val_acc did not improve from 0.66667\n","Epoch 50/100\n","16/16 [==============================] - 1s 46ms/step - loss: 0.7142 - acc: 0.7295 - val_loss: 0.9328 - val_acc: 0.6310\n","\n","Epoch 00050: val_acc did not improve from 0.66667\n","Epoch 51/100\n","16/16 [==============================] - 1s 47ms/step - loss: 0.7120 - acc: 0.7350 - val_loss: 0.9190 - val_acc: 0.6190\n","\n","Epoch 00051: val_acc did not improve from 0.66667\n","Epoch 52/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.7124 - acc: 0.7368 - val_loss: 0.9524 - val_acc: 0.6548\n","\n","Epoch 00052: val_acc did not improve from 0.66667\n","Epoch 53/100\n","16/16 [==============================] - 1s 46ms/step - loss: 0.7047 - acc: 0.7369 - val_loss: 0.9718 - val_acc: 0.6548\n","\n","Epoch 00053: val_acc did not improve from 0.66667\n","Epoch 54/100\n","16/16 [==============================] - 1s 44ms/step - loss: 0.6733 - acc: 0.7521 - val_loss: 0.9434 - val_acc: 0.6548\n","\n","Epoch 00054: val_acc did not improve from 0.66667\n","Epoch 55/100\n","16/16 [==============================] - 1s 46ms/step - loss: 0.6707 - acc: 0.7403 - val_loss: 0.9289 - val_acc: 0.6667\n","\n","Epoch 00055: val_acc did not improve from 0.66667\n","Epoch 56/100\n","16/16 [==============================] - 1s 47ms/step - loss: 0.6727 - acc: 0.7336 - val_loss: 0.9363 - val_acc: 0.6310\n","\n","Epoch 00056: val_acc did not improve from 0.66667\n","Epoch 57/100\n","16/16 [==============================] - 1s 44ms/step - loss: 0.6442 - acc: 0.7510 - val_loss: 0.9800 - val_acc: 0.6190\n","\n","Epoch 00057: val_acc did not improve from 0.66667\n","Epoch 58/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.6468 - acc: 0.7607 - val_loss: 0.9387 - val_acc: 0.6548\n","\n","Epoch 00058: val_acc did not improve from 0.66667\n","Epoch 59/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.6785 - acc: 0.7396 - val_loss: 0.9041 - val_acc: 0.6667\n","\n","Epoch 00059: val_acc did not improve from 0.66667\n","Epoch 60/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.6249 - acc: 0.7625 - val_loss: 0.9235 - val_acc: 0.6667\n","\n","Epoch 00060: val_acc did not improve from 0.66667\n","Epoch 61/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.6282 - acc: 0.7527 - val_loss: 1.0166 - val_acc: 0.6548\n","\n","Epoch 00061: val_acc did not improve from 0.66667\n","Epoch 62/100\n","16/16 [==============================] - 1s 46ms/step - loss: 0.6607 - acc: 0.7599 - val_loss: 1.0042 - val_acc: 0.6548\n","\n","Epoch 00062: val_acc did not improve from 0.66667\n","Epoch 63/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.6163 - acc: 0.7678 - val_loss: 0.9919 - val_acc: 0.6786\n","\n","Epoch 00063: val_acc improved from 0.66667 to 0.67857, saving model to result/all/five/new/OUR6-5/epoch-63-val-acc-0.6786.hdf5\n","Epoch 64/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.6337 - acc: 0.7638 - val_loss: 0.9830 - val_acc: 0.6429\n","\n","Epoch 00064: val_acc did not improve from 0.67857\n","Epoch 65/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.5781 - acc: 0.7837 - val_loss: 0.8925 - val_acc: 0.6786\n","\n","Epoch 00065: val_acc improved from 0.67857 to 0.67857, saving model to result/all/five/new/OUR6-5/epoch-65-val-acc-0.6786.hdf5\n","Epoch 66/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.6044 - acc: 0.7749 - val_loss: 0.9314 - val_acc: 0.6548\n","\n","Epoch 00066: val_acc did not improve from 0.67857\n","Epoch 67/100\n","16/16 [==============================] - 1s 47ms/step - loss: 0.5561 - acc: 0.7943 - val_loss: 0.9010 - val_acc: 0.6786\n","\n","Epoch 00067: val_acc did not improve from 0.67857\n","Epoch 68/100\n","16/16 [==============================] - 1s 44ms/step - loss: 0.5810 - acc: 0.7686 - val_loss: 0.9246 - val_acc: 0.6786\n","\n","Epoch 00068: val_acc did not improve from 0.67857\n","Epoch 69/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.6011 - acc: 0.7810 - val_loss: 0.9027 - val_acc: 0.6786\n","\n","Epoch 00069: val_acc improved from 0.67857 to 0.67857, saving model to result/all/five/new/OUR6-5/epoch-69-val-acc-0.6786.hdf5\n","Epoch 70/100\n","16/16 [==============================] - 1s 44ms/step - loss: 0.5862 - acc: 0.7811 - val_loss: 1.0100 - val_acc: 0.6667\n","\n","Epoch 00070: val_acc did not improve from 0.67857\n","Epoch 71/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.5415 - acc: 0.8123 - val_loss: 0.9337 - val_acc: 0.7024\n","\n","Epoch 00071: val_acc improved from 0.67857 to 0.70238, saving model to result/all/five/new/OUR6-5/epoch-71-val-acc-0.7024.hdf5\n","Epoch 72/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.5468 - acc: 0.7796 - val_loss: 0.9098 - val_acc: 0.6786\n","\n","Epoch 00072: val_acc did not improve from 0.70238\n","Epoch 73/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.5240 - acc: 0.7926 - val_loss: 0.9037 - val_acc: 0.6905\n","\n","Epoch 00073: val_acc did not improve from 0.70238\n","Epoch 74/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.5430 - acc: 0.7927 - val_loss: 0.8998 - val_acc: 0.7143\n","\n","Epoch 00074: val_acc improved from 0.70238 to 0.71429, saving model to result/all/five/new/OUR6-5/epoch-74-val-acc-0.7143.hdf5\n","Epoch 75/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.5069 - acc: 0.8164 - val_loss: 0.9043 - val_acc: 0.6786\n","\n","Epoch 00075: val_acc did not improve from 0.71429\n","Epoch 76/100\n","16/16 [==============================] - 1s 46ms/step - loss: 0.4885 - acc: 0.8125 - val_loss: 0.9057 - val_acc: 0.6786\n","\n","Epoch 00076: val_acc did not improve from 0.71429\n","Epoch 77/100\n","16/16 [==============================] - 1s 44ms/step - loss: 0.4894 - acc: 0.8119 - val_loss: 0.9083 - val_acc: 0.6786\n","\n","Epoch 00077: val_acc did not improve from 0.71429\n","Epoch 78/100\n","16/16 [==============================] - 1s 47ms/step - loss: 0.4768 - acc: 0.8186 - val_loss: 0.9064 - val_acc: 0.7024\n","\n","Epoch 00078: val_acc did not improve from 0.71429\n","Epoch 79/100\n","16/16 [==============================] - 1s 44ms/step - loss: 0.4944 - acc: 0.7983 - val_loss: 0.9083 - val_acc: 0.6786\n","\n","Epoch 00079: val_acc did not improve from 0.71429\n","Epoch 80/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.5029 - acc: 0.8085 - val_loss: 0.9535 - val_acc: 0.6786\n","\n","Epoch 00080: val_acc did not improve from 0.71429\n","Epoch 81/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.4461 - acc: 0.8188 - val_loss: 0.9631 - val_acc: 0.6548\n","\n","Epoch 00081: val_acc did not improve from 0.71429\n","Epoch 82/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.4877 - acc: 0.8319 - val_loss: 0.8938 - val_acc: 0.6905\n","\n","Epoch 00082: val_acc did not improve from 0.71429\n","Epoch 83/100\n","16/16 [==============================] - 1s 44ms/step - loss: 0.4576 - acc: 0.8290 - val_loss: 0.9186 - val_acc: 0.7024\n","\n","Epoch 00083: val_acc did not improve from 0.71429\n","Epoch 84/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.4745 - acc: 0.8075 - val_loss: 0.8947 - val_acc: 0.7024\n","\n","Epoch 00084: val_acc did not improve from 0.71429\n","Epoch 85/100\n","16/16 [==============================] - 1s 44ms/step - loss: 0.4852 - acc: 0.8114 - val_loss: 0.9300 - val_acc: 0.6667\n","\n","Epoch 00085: val_acc did not improve from 0.71429\n","Epoch 86/100\n","16/16 [==============================] - 1s 47ms/step - loss: 0.4064 - acc: 0.8499 - val_loss: 0.9138 - val_acc: 0.7024\n","\n","Epoch 00086: val_acc did not improve from 0.71429\n","Epoch 87/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.4365 - acc: 0.8429 - val_loss: 0.9544 - val_acc: 0.6786\n","\n","Epoch 00087: val_acc did not improve from 0.71429\n","Epoch 88/100\n","16/16 [==============================] - 1s 44ms/step - loss: 0.4358 - acc: 0.8311 - val_loss: 0.9321 - val_acc: 0.6667\n","\n","Epoch 00088: val_acc did not improve from 0.71429\n","Epoch 89/100\n","16/16 [==============================] - 1s 46ms/step - loss: 0.4093 - acc: 0.8558 - val_loss: 0.9199 - val_acc: 0.6667\n","\n","Epoch 00089: val_acc did not improve from 0.71429\n","Epoch 90/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.4171 - acc: 0.8478 - val_loss: 0.9397 - val_acc: 0.7024\n","\n","Epoch 00090: val_acc did not improve from 0.71429\n","Epoch 91/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.4283 - acc: 0.8316 - val_loss: 0.9017 - val_acc: 0.7143\n","\n","Epoch 00091: val_acc improved from 0.71429 to 0.71429, saving model to result/all/five/new/OUR6-5/epoch-91-val-acc-0.7143.hdf5\n","Epoch 92/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.3890 - acc: 0.8609 - val_loss: 0.9322 - val_acc: 0.7024\n","\n","Epoch 00092: val_acc did not improve from 0.71429\n","Epoch 93/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.4233 - acc: 0.8368 - val_loss: 0.9683 - val_acc: 0.6905\n","\n","Epoch 00093: val_acc did not improve from 0.71429\n","Epoch 94/100\n","16/16 [==============================] - 1s 44ms/step - loss: 0.3678 - acc: 0.8683 - val_loss: 0.9008 - val_acc: 0.7143\n","\n","Epoch 00094: val_acc did not improve from 0.71429\n","Epoch 95/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.3714 - acc: 0.8496 - val_loss: 0.8913 - val_acc: 0.6786\n","\n","Epoch 00095: val_acc did not improve from 0.71429\n","Epoch 96/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.3715 - acc: 0.8569 - val_loss: 0.8741 - val_acc: 0.7024\n","\n","Epoch 00096: val_acc did not improve from 0.71429\n","Epoch 97/100\n","16/16 [==============================] - 1s 47ms/step - loss: 0.3534 - acc: 0.8749 - val_loss: 0.8758 - val_acc: 0.7024\n","\n","Epoch 00097: val_acc did not improve from 0.71429\n","Epoch 98/100\n","16/16 [==============================] - 1s 45ms/step - loss: 0.3486 - acc: 0.8674 - val_loss: 0.8886 - val_acc: 0.7024\n","\n","Epoch 00098: val_acc did not improve from 0.71429\n","Epoch 99/100\n","16/16 [==============================] - 1s 44ms/step - loss: 0.3474 - acc: 0.8699 - val_loss: 0.8985 - val_acc: 0.7024\n","\n","Epoch 00099: val_acc did not improve from 0.71429\n","Epoch 100/100\n","16/16 [==============================] - 1s 47ms/step - loss: 0.3707 - acc: 0.8606 - val_loss: 0.8918 - val_acc: 0.7262\n","\n","Epoch 00100: val_acc improved from 0.71429 to 0.72619, saving model to result/all/five/new/OUR6-5/epoch-100-val-acc-0.7262.hdf5\n","\n","<keras.callbacks.History at 0x7f91422c7940>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qk2MfyAag0mO","colab_type":"code","colab":{}},"cell_type":"code","source":["# left-right 90\n","\n","\n","Epoch 1/100\n","16/16 [==============================] - 1s 63ms/step - loss: 1.0286 - acc: 0.5190 - val_loss: 1.0249 - val_acc: 0.4889\n","\n","Epoch 00001: val_acc improved from -inf to 0.48889, saving model to result/left-right/OUR5-33/epoch-01-val-acc-0.4889.hdf5\n","Epoch 2/100\n","16/16 [==============================] - 1s 36ms/step - loss: 0.9518 - acc: 0.5395 - val_loss: 0.8769 - val_acc: 0.5444\n","\n","Epoch 00002: val_acc improved from 0.48889 to 0.54444, saving model to result/left-right/OUR5-33/epoch-02-val-acc-0.5444.hdf5\n","Epoch 3/100\n","16/16 [==============================] - 0s 28ms/step - loss: 0.7580 - acc: 0.6558 - val_loss: 0.6634 - val_acc: 0.7111\n","\n","Epoch 00003: val_acc improved from 0.54444 to 0.71111, saving model to result/left-right/OUR5-33/epoch-03-val-acc-0.7111.hdf5\n","Epoch 4/100\n","16/16 [==============================] - 1s 33ms/step - loss: 0.5790 - acc: 0.7645 - val_loss: 0.7042 - val_acc: 0.7000\n","\n","Epoch 00004: val_acc did not improve from 0.71111\n","Epoch 5/100\n","16/16 [==============================] - 1s 33ms/step - loss: 0.5009 - acc: 0.8093 - val_loss: 0.6161 - val_acc: 0.7556\n","\n","Epoch 00005: val_acc improved from 0.71111 to 0.75556, saving model to result/left-right/OUR5-33/epoch-05-val-acc-0.7556.hdf5\n","Epoch 6/100\n","16/16 [==============================] - 0s 28ms/step - loss: 0.3958 - acc: 0.8480 - val_loss: 0.6024 - val_acc: 0.7111\n","\n","Epoch 00006: val_acc did not improve from 0.75556\n","Epoch 7/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.3084 - acc: 0.8890 - val_loss: 0.5389 - val_acc: 0.7778\n","\n","Epoch 00007: val_acc improved from 0.75556 to 0.77778, saving model to result/left-right/OUR5-33/epoch-07-val-acc-0.7778.hdf5\n","Epoch 8/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.2671 - acc: 0.9005 - val_loss: 0.7028 - val_acc: 0.7333\n","\n","Epoch 00008: val_acc did not improve from 0.77778\n","Epoch 9/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.2183 - acc: 0.9283 - val_loss: 0.6396 - val_acc: 0.7778\n","\n","Epoch 00009: val_acc did not improve from 0.77778\n","Epoch 10/100\n","16/16 [==============================] - 1s 34ms/step - loss: 0.1393 - acc: 0.9531 - val_loss: 0.6142 - val_acc: 0.7556\n","\n","Epoch 00010: val_acc did not improve from 0.77778\n","Epoch 11/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0955 - acc: 0.9744 - val_loss: 0.7692 - val_acc: 0.7667\n","\n","Epoch 00011: val_acc did not improve from 0.77778\n","Epoch 12/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0699 - acc: 0.9873 - val_loss: 0.8314 - val_acc: 0.7778\n","\n","Epoch 00012: val_acc did not improve from 0.77778\n","Epoch 13/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0409 - acc: 0.9936 - val_loss: 0.6931 - val_acc: 0.8111\n","\n","Epoch 00013: val_acc improved from 0.77778 to 0.81111, saving model to result/left-right/OUR5-33/epoch-13-val-acc-0.8111.hdf5\n","Epoch 14/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0282 - acc: 0.9971 - val_loss: 0.6815 - val_acc: 0.7889\n","\n","Epoch 00014: val_acc did not improve from 0.81111\n","Epoch 15/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0255 - acc: 0.9941 - val_loss: 0.6499 - val_acc: 0.8333\n","\n","Epoch 00015: val_acc improved from 0.81111 to 0.83333, saving model to result/left-right/OUR5-33/epoch-15-val-acc-0.8333.hdf5\n","Epoch 16/100\n","16/16 [==============================] - 0s 31ms/step - loss: 0.0184 - acc: 0.9980 - val_loss: 0.7118 - val_acc: 0.7889\n","\n","Epoch 00016: val_acc did not improve from 0.83333\n","Epoch 17/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0287 - acc: 0.9951 - val_loss: 0.5384 - val_acc: 0.8556\n","\n","Epoch 00017: val_acc improved from 0.83333 to 0.85556, saving model to result/left-right/OUR5-33/epoch-17-val-acc-0.8556.hdf5\n","Epoch 18/100\n","16/16 [==============================] - 0s 29ms/step - loss: 0.0221 - acc: 0.9990 - val_loss: 0.8407 - val_acc: 0.8111\n","\n","Epoch 00018: val_acc did not improve from 0.85556\n","Epoch 19/100\n","16/16 [==============================] - 1s 33ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.7756 - val_acc: 0.8222\n","\n","Epoch 00019: val_acc did not improve from 0.85556\n","Epoch 20/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.9090 - val_acc: 0.8000\n","\n","Epoch 00020: val_acc did not improve from 0.85556\n","Epoch 21/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.8177 - val_acc: 0.8222\n","\n","Epoch 00021: val_acc did not improve from 0.85556\n","Epoch 22/100\n","16/16 [==============================] - 1s 36ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.7864 - val_acc: 0.8000\n","\n","Epoch 00022: val_acc did not improve from 0.85556\n","Epoch 23/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.7823 - val_acc: 0.8444\n","\n","Epoch 00023: val_acc did not improve from 0.85556\n","Epoch 24/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.8305 - val_acc: 0.8333\n","\n","Epoch 00024: val_acc did not improve from 0.85556\n","Epoch 25/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.9016 - val_acc: 0.8333\n","\n","Epoch 00025: val_acc did not improve from 0.85556\n","Epoch 26/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.8000\n","\n","Epoch 00026: val_acc did not improve from 0.85556\n","Epoch 27/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.8237 - val_acc: 0.8111\n","\n","Epoch 00027: val_acc did not improve from 0.85556\n","Epoch 28/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0065 - acc: 0.9990 - val_loss: 0.9287 - val_acc: 0.8000\n","\n","Epoch 00028: val_acc did not improve from 0.85556\n","Epoch 29/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0121 - acc: 0.9975 - val_loss: 0.6851 - val_acc: 0.8444\n","\n","Epoch 00029: val_acc did not improve from 0.85556\n","Epoch 30/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7483 - val_acc: 0.8556\n","\n","Epoch 00030: val_acc did not improve from 0.85556\n","Epoch 31/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.6847 - val_acc: 0.8444\n","\n","Epoch 00031: val_acc did not improve from 0.85556\n","Epoch 32/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 0.8556\n","\n","Epoch 00032: val_acc improved from 0.85556 to 0.85556, saving model to result/left-right/OUR5-33/epoch-32-val-acc-0.8556.hdf5\n","Epoch 33/100\n","16/16 [==============================] - 0s 28ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.8817 - val_acc: 0.8333\n","\n","Epoch 00033: val_acc did not improve from 0.85556\n","Epoch 34/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.7540 - val_acc: 0.8444\n","\n","Epoch 00034: val_acc did not improve from 0.85556\n","Epoch 35/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.8582 - val_acc: 0.8444\n","\n","Epoch 00035: val_acc did not improve from 0.85556\n","Epoch 36/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.9215 - val_acc: 0.8333\n","\n","Epoch 00036: val_acc did not improve from 0.85556\n","Epoch 37/100\n","16/16 [==============================] - 1s 32ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.8219 - val_acc: 0.8222\n","\n","Epoch 00037: val_acc did not improve from 0.85556\n","Epoch 38/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0055 - acc: 0.9990 - val_loss: 0.7405 - val_acc: 0.8222\n","\n","Epoch 00038: val_acc did not improve from 0.85556\n","Epoch 39/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.9821 - val_acc: 0.7889\n","\n","Epoch 00039: val_acc did not improve from 0.85556\n","Epoch 40/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.8452 - val_acc: 0.8111\n","\n","Epoch 00040: val_acc did not improve from 0.85556\n","Epoch 41/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0110 - acc: 0.9971 - val_loss: 0.8772 - val_acc: 0.8111\n","\n","Epoch 00041: val_acc did not improve from 0.85556\n","Epoch 42/100\n","16/16 [==============================] - 0s 31ms/step - loss: 0.0151 - acc: 0.9955 - val_loss: 0.9625 - val_acc: 0.8000\n","\n","Epoch 00042: val_acc did not improve from 0.85556\n","Epoch 43/100\n","16/16 [==============================] - 1s 34ms/step - loss: 0.0106 - acc: 0.9990 - val_loss: 0.8505 - val_acc: 0.8222\n","\n","Epoch 00043: val_acc did not improve from 0.85556\n","Epoch 44/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.8582 - val_acc: 0.8556\n","\n","Epoch 00044: val_acc did not improve from 0.85556\n","Epoch 45/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8206 - val_acc: 0.8444\n","\n","Epoch 00045: val_acc did not improve from 0.85556\n","Epoch 46/100\n","16/16 [==============================] - 1s 36ms/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.9099 - val_acc: 0.7889\n","\n","Epoch 00046: val_acc did not improve from 0.85556\n","Epoch 47/100\n","16/16 [==============================] - 1s 34ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.7388 - val_acc: 0.8444\n","\n","Epoch 00047: val_acc did not improve from 0.85556\n","Epoch 48/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9506 - val_acc: 0.8222\n","\n","Epoch 00048: val_acc did not improve from 0.85556\n","Epoch 49/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.0085 - val_acc: 0.8333\n","\n","Epoch 00049: val_acc did not improve from 0.85556\n","Epoch 50/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0093 - acc: 0.9980 - val_loss: 1.1954 - val_acc: 0.8111\n","\n","Epoch 00050: val_acc did not improve from 0.85556\n","Epoch 51/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.8993 - val_acc: 0.8556\n","\n","Epoch 00051: val_acc did not improve from 0.85556\n","Epoch 52/100\n","16/16 [==============================] - 1s 34ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9940 - val_acc: 0.8222\n","\n","Epoch 00052: val_acc did not improve from 0.85556\n","Epoch 53/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.9522 - val_acc: 0.8444\n","\n","Epoch 00053: val_acc did not improve from 0.85556\n","Epoch 54/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0060 - acc: 0.9975 - val_loss: 0.8570 - val_acc: 0.8444\n","\n","Epoch 00054: val_acc did not improve from 0.85556\n","Epoch 55/100\n","16/16 [==============================] - 1s 34ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.7545 - val_acc: 0.8667\n","\n","Epoch 00055: val_acc improved from 0.85556 to 0.86667, saving model to result/left-right/OUR5-33/epoch-55-val-acc-0.8667.hdf5\n","Epoch 56/100\n","16/16 [==============================] - 1s 36ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9421 - val_acc: 0.8444\n","\n","Epoch 00056: val_acc did not improve from 0.86667\n","Epoch 57/100\n","16/16 [==============================] - 0s 30ms/step - loss: 5.6947e-04 - acc: 1.0000 - val_loss: 0.9463 - val_acc: 0.8444\n","\n","Epoch 00057: val_acc did not improve from 0.86667\n","Epoch 58/100\n","16/16 [==============================] - 1s 35ms/step - loss: 5.4304e-04 - acc: 1.0000 - val_loss: 0.9509 - val_acc: 0.8444\n","\n","Epoch 00058: val_acc did not improve from 0.86667\n","Epoch 59/100\n","16/16 [==============================] - 1s 35ms/step - loss: 9.9493e-04 - acc: 1.0000 - val_loss: 0.9293 - val_acc: 0.8333\n","\n","Epoch 00059: val_acc did not improve from 0.86667\n","Epoch 60/100\n","16/16 [==============================] - 0s 30ms/step - loss: 2.6883e-04 - acc: 1.0000 - val_loss: 0.8543 - val_acc: 0.8667\n","\n","Epoch 00060: val_acc did not improve from 0.86667\n","Epoch 61/100\n","16/16 [==============================] - 1s 34ms/step - loss: 6.1757e-04 - acc: 1.0000 - val_loss: 0.9218 - val_acc: 0.8556\n","\n","Epoch 00061: val_acc did not improve from 0.86667\n","Epoch 62/100\n","16/16 [==============================] - 1s 35ms/step - loss: 2.3070e-04 - acc: 1.0000 - val_loss: 0.9895 - val_acc: 0.8333\n","\n","Epoch 00062: val_acc did not improve from 0.86667\n","Epoch 63/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.9298 - val_acc: 0.8667\n","\n","Epoch 00063: val_acc did not improve from 0.86667\n","Epoch 64/100\n","16/16 [==============================] - 1s 34ms/step - loss: 5.4541e-04 - acc: 1.0000 - val_loss: 0.9594 - val_acc: 0.8778\n","\n","Epoch 00064: val_acc improved from 0.86667 to 0.87778, saving model to result/left-right/OUR5-33/epoch-64-val-acc-0.8778.hdf5\n","Epoch 65/100\n","16/16 [==============================] - 1s 36ms/step - loss: 6.0262e-04 - acc: 1.0000 - val_loss: 1.1394 - val_acc: 0.8444\n","\n","Epoch 00065: val_acc did not improve from 0.87778\n","Epoch 66/100\n","16/16 [==============================] - 0s 31ms/step - loss: 4.8310e-04 - acc: 1.0000 - val_loss: 1.0676 - val_acc: 0.8444\n","\n","Epoch 00066: val_acc did not improve from 0.87778\n","Epoch 67/100\n","16/16 [==============================] - 1s 34ms/step - loss: 1.5085e-04 - acc: 1.0000 - val_loss: 0.9701 - val_acc: 0.8556\n","\n","Epoch 00067: val_acc did not improve from 0.87778\n","Epoch 68/100\n","16/16 [==============================] - 1s 35ms/step - loss: 2.0330e-04 - acc: 1.0000 - val_loss: 1.0134 - val_acc: 0.8556\n","\n","Epoch 00068: val_acc did not improve from 0.87778\n","Epoch 69/100\n","16/16 [==============================] - 0s 30ms/step - loss: 2.0504e-04 - acc: 1.0000 - val_loss: 1.0571 - val_acc: 0.8556\n","\n","Epoch 00069: val_acc did not improve from 0.87778\n","Epoch 70/100\n","16/16 [==============================] - 1s 35ms/step - loss: 5.5606e-04 - acc: 1.0000 - val_loss: 1.0537 - val_acc: 0.8333\n","\n","Epoch 00070: val_acc did not improve from 0.87778\n","Epoch 71/100\n","16/16 [==============================] - 1s 34ms/step - loss: 7.3805e-04 - acc: 1.0000 - val_loss: 1.1344 - val_acc: 0.8111\n","\n","Epoch 00071: val_acc did not improve from 0.87778\n","Epoch 72/100\n","16/16 [==============================] - 0s 31ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.9500 - val_acc: 0.8444\n","\n","Epoch 00072: val_acc did not improve from 0.87778\n","Epoch 73/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0021 - acc: 0.9990 - val_loss: 1.1187 - val_acc: 0.8111\n","\n","Epoch 00073: val_acc did not improve from 0.87778\n","Epoch 74/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0037 - acc: 0.9990 - val_loss: 1.4055 - val_acc: 0.7778\n","\n","Epoch 00074: val_acc did not improve from 0.87778\n","Epoch 75/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.8477 - val_acc: 0.8333\n","\n","Epoch 00075: val_acc did not improve from 0.87778\n","Epoch 76/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0092 - acc: 0.9961 - val_loss: 0.7390 - val_acc: 0.8556\n","\n","Epoch 00076: val_acc did not improve from 0.87778\n","Epoch 77/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.9509 - val_acc: 0.8667\n","\n","Epoch 00077: val_acc did not improve from 0.87778\n","Epoch 78/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.8058 - val_acc: 0.8667\n","\n","Epoch 00078: val_acc did not improve from 0.87778\n","Epoch 79/100\n","16/16 [==============================] - 1s 34ms/step - loss: 8.3519e-04 - acc: 1.0000 - val_loss: 0.9923 - val_acc: 0.8556\n","\n","Epoch 00079: val_acc did not improve from 0.87778\n","Epoch 80/100\n","16/16 [==============================] - 1s 35ms/step - loss: 4.2866e-04 - acc: 1.0000 - val_loss: 0.9793 - val_acc: 0.8667\n","\n","Epoch 00080: val_acc did not improve from 0.87778\n","Epoch 81/100\n","16/16 [==============================] - 0s 30ms/step - loss: 5.1218e-04 - acc: 1.0000 - val_loss: 1.1468 - val_acc: 0.8222\n","\n","Epoch 00081: val_acc did not improve from 0.87778\n","Epoch 82/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.8322 - val_acc: 0.9000\n","\n","Epoch 00082: val_acc improved from 0.87778 to 0.90000, saving model to result/left-right/OUR5-33/epoch-82-val-acc-0.9000.hdf5\n","Epoch 83/100\n","16/16 [==============================] - 1s 36ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.1411 - val_acc: 0.8222\n","\n","Epoch 00083: val_acc did not improve from 0.90000\n","Epoch 84/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0023 - acc: 0.9990 - val_loss: 0.6788 - val_acc: 0.8889\n","\n","Epoch 00084: val_acc did not improve from 0.90000\n","Epoch 85/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0023 - acc: 0.9990 - val_loss: 0.8523 - val_acc: 0.8444\n","\n","Epoch 00085: val_acc did not improve from 0.90000\n","Epoch 86/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0020 - acc: 0.9990 - val_loss: 1.0095 - val_acc: 0.8444\n","\n","Epoch 00086: val_acc did not improve from 0.90000\n","Epoch 87/100\n","16/16 [==============================] - 0s 30ms/step - loss: 7.4720e-04 - acc: 1.0000 - val_loss: 0.7911 - val_acc: 0.8667\n","\n","Epoch 00087: val_acc did not improve from 0.90000\n","Epoch 88/100\n","16/16 [==============================] - 1s 35ms/step - loss: 4.0182e-04 - acc: 1.0000 - val_loss: 0.8786 - val_acc: 0.8333\n","\n","Epoch 00088: val_acc did not improve from 0.90000\n","Epoch 89/100\n","16/16 [==============================] - 1s 35ms/step - loss: 4.0814e-04 - acc: 1.0000 - val_loss: 0.9154 - val_acc: 0.8444\n","\n","Epoch 00089: val_acc did not improve from 0.90000\n","Epoch 90/100\n","16/16 [==============================] - 0s 30ms/step - loss: 1.3945e-04 - acc: 1.0000 - val_loss: 0.8807 - val_acc: 0.8667\n","\n","Epoch 00090: val_acc did not improve from 0.90000\n","Epoch 91/100\n","16/16 [==============================] - 1s 34ms/step - loss: 2.5736e-04 - acc: 1.0000 - val_loss: 0.8676 - val_acc: 0.8667\n","\n","Epoch 00091: val_acc did not improve from 0.90000\n","Epoch 92/100\n","16/16 [==============================] - 1s 35ms/step - loss: 1.7742e-04 - acc: 1.0000 - val_loss: 0.8662 - val_acc: 0.8667\n","\n","Epoch 00092: val_acc did not improve from 0.90000\n","Epoch 93/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0293 - acc: 0.9920 - val_loss: 0.9911 - val_acc: 0.7778\n","\n","Epoch 00093: val_acc did not improve from 0.90000\n","Epoch 94/100\n","16/16 [==============================] - 1s 34ms/step - loss: 0.2797 - acc: 0.9031 - val_loss: 0.6015 - val_acc: 0.7778\n","\n","Epoch 00094: val_acc did not improve from 0.90000\n","Epoch 95/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.1015 - acc: 0.9618 - val_loss: 0.6575 - val_acc: 0.7778\n","\n","Epoch 00095: val_acc did not improve from 0.90000\n","Epoch 96/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0402 - acc: 0.9885 - val_loss: 0.6553 - val_acc: 0.8222\n","\n","Epoch 00096: val_acc did not improve from 0.90000\n","Epoch 97/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0137 - acc: 0.9965 - val_loss: 0.6713 - val_acc: 0.8333\n","\n","Epoch 00097: val_acc did not improve from 0.90000\n","Epoch 98/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.8596 - val_acc: 0.8333\n","\n","Epoch 00098: val_acc did not improve from 0.90000\n","Epoch 99/100\n","16/16 [==============================] - 0s 31ms/step - loss: 0.0052 - acc: 0.9980 - val_loss: 0.8635 - val_acc: 0.8333\n","\n","Epoch 00099: val_acc did not improve from 0.90000\n","Epoch 100/100\n","16/16 [==============================] - 1s 34ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.7938 - val_acc: 0.8111\n","\n","Epoch 00100: val_acc did not improve from 0.90000\n","\n","<keras.callbacks.History at 0x7f91a85c0f60>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5VhD4ls5SG2R","colab_type":"code","outputId":"df45bfb0-b297-4508-c640-16b6a73f44ab","executionInfo":{"status":"ok","timestamp":1539868077606,"user_tz":-180,"elapsed":687,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["from keras.callbacks import EarlyStopping\n","EarlyStopping(monitor='val_loss',\n","                              min_delta=0,\n","                              patience=0,\n","                              verbose=0, mode='auto')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.EarlyStopping at 0x7f8b208774e0>"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"hYM5d5_NP_6k","colab_type":"code","colab":{}},"cell_type":"code","source":["keras.callbacks.EarlyStopping(monitor='val_loss',\n","                              min_delta=0,\n","                              patience=2,\n","                              verbose=0, mode='auto')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hsj3lKtcTelC","colab_type":"code","outputId":"c3673ff9-c968-4a86-ab77-6e72d778df63","executionInfo":{"status":"ok","timestamp":1539868649388,"user_tz":-180,"elapsed":16095,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":1385}},"cell_type":"code","source":["filepath=\"result/intersection/OUR6-60/epoch-70-val-acc-0.9322.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n","\n","# check 5 epochs\n","early_stop = EarlyStopping(monitor='val_acc', patience=5, mode='max') \n","\n","callbacks_list = [checkpoint, early_stop]\n","\n","history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, callbacks=callbacks_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 235 samples, validate on 59 samples\n","Epoch 1/100\n","235/235 [==============================] - 0s 981us/step - loss: 0.0616 - acc: 0.9830 - val_loss: 0.2965 - val_acc: 0.8475\n","\n","Epoch 00001: val_acc improved from -inf to 0.84746, saving model to result/intersection/OUR6-60/epoch-70-val-acc-0.9322.hdf5\n","Epoch 2/100\n","235/235 [==============================] - 0s 1ms/step - loss: 0.0362 - acc: 0.9830 - val_loss: 0.4142 - val_acc: 0.8136\n","\n","Epoch 00002: val_acc did not improve from 0.84746\n","Epoch 3/100\n","235/235 [==============================] - 0s 1ms/step - loss: 0.0311 - acc: 0.9915 - val_loss: 0.7985 - val_acc: 0.7627\n","\n","Epoch 00003: val_acc did not improve from 0.84746\n","Epoch 4/100\n","235/235 [==============================] - 0s 1ms/step - loss: 0.0390 - acc: 0.9787 - val_loss: 0.3880 - val_acc: 0.8644\n","\n","Epoch 00004: val_acc improved from 0.84746 to 0.86441, saving model to result/intersection/OUR6-60/epoch-70-val-acc-0.9322.hdf5\n","Epoch 5/100\n","235/235 [==============================] - 0s 958us/step - loss: 0.0682 - acc: 0.9787 - val_loss: 0.5063 - val_acc: 0.8475\n","\n","Epoch 00005: val_acc did not improve from 0.86441\n","Epoch 6/100\n","235/235 [==============================] - 0s 948us/step - loss: 0.0160 - acc: 0.9915 - val_loss: 0.3738 - val_acc: 0.8644\n","\n","Epoch 00006: val_acc improved from 0.86441 to 0.86441, saving model to result/intersection/OUR6-60/epoch-70-val-acc-0.9322.hdf5\n","Epoch 7/100\n","235/235 [==============================] - 0s 1ms/step - loss: 0.0584 - acc: 0.9745 - val_loss: 0.4573 - val_acc: 0.8644\n","\n","Epoch 00007: val_acc did not improve from 0.86441\n","Epoch 8/100\n","235/235 [==============================] - 0s 1ms/step - loss: 0.0284 - acc: 0.9872 - val_loss: 0.3739 - val_acc: 0.8983\n","\n","Epoch 00008: val_acc improved from 0.86441 to 0.89831, saving model to result/intersection/OUR6-60/epoch-70-val-acc-0.9322.hdf5\n","Epoch 9/100\n","235/235 [==============================] - 0s 982us/step - loss: 0.0229 - acc: 0.9872 - val_loss: 0.4334 - val_acc: 0.8814\n","\n","Epoch 00009: val_acc did not improve from 0.89831\n","Epoch 10/100\n","235/235 [==============================] - 0s 974us/step - loss: 0.0808 - acc: 0.9702 - val_loss: 0.6879 - val_acc: 0.7966\n","\n","Epoch 00010: val_acc did not improve from 0.89831\n","Epoch 11/100\n","235/235 [==============================] - 0s 962us/step - loss: 0.0520 - acc: 0.9745 - val_loss: 0.3545 - val_acc: 0.8305\n","\n","Epoch 00011: val_acc did not improve from 0.89831\n","Epoch 12/100\n","235/235 [==============================] - 0s 976us/step - loss: 0.0337 - acc: 0.9915 - val_loss: 0.4052 - val_acc: 0.8305\n","\n","Epoch 00012: val_acc did not improve from 0.89831\n","Epoch 13/100\n","235/235 [==============================] - 0s 951us/step - loss: 0.0288 - acc: 0.9957 - val_loss: 0.3191 - val_acc: 0.8983\n","\n","Epoch 00013: val_acc improved from 0.89831 to 0.89831, saving model to result/intersection/OUR6-60/epoch-70-val-acc-0.9322.hdf5\n","Epoch 14/100\n","235/235 [==============================] - 0s 959us/step - loss: 0.0199 - acc: 0.9915 - val_loss: 0.3809 - val_acc: 0.8814\n","\n","Epoch 00014: val_acc did not improve from 0.89831\n","Epoch 15/100\n","235/235 [==============================] - 0s 974us/step - loss: 0.0425 - acc: 0.9830 - val_loss: 0.2248 - val_acc: 0.8983\n","\n","Epoch 00015: val_acc did not improve from 0.89831\n","Epoch 16/100\n","235/235 [==============================] - 0s 959us/step - loss: 0.0328 - acc: 0.9915 - val_loss: 0.3925 - val_acc: 0.8475\n","\n","Epoch 00016: val_acc did not improve from 0.89831\n","Epoch 17/100\n","235/235 [==============================] - 0s 961us/step - loss: 0.0192 - acc: 0.9915 - val_loss: 0.6509 - val_acc: 0.7966\n","\n","Epoch 00017: val_acc did not improve from 0.89831\n","Epoch 18/100\n","235/235 [==============================] - 0s 968us/step - loss: 0.0465 - acc: 0.9787 - val_loss: 0.4566 - val_acc: 0.8305\n","\n","Epoch 00018: val_acc did not improve from 0.89831\n"],"name":"stdout"}]},{"metadata":{"id":"Ir-GQl7ys3ZM","colab_type":"code","colab":{}},"cell_type":"code","source":["#left right 90\n","\n","\n","\n","Epoch 1/100\n","16/16 [==============================] - 1s 63ms/step - loss: 1.0286 - acc: 0.5190 - val_loss: 1.0249 - val_acc: 0.4889\n","\n","Epoch 00001: val_acc improved from -inf to 0.48889, saving model to result/left-right/OUR5-33/epoch-01-val-acc-0.4889.hdf5\n","Epoch 2/100\n","16/16 [==============================] - 1s 36ms/step - loss: 0.9518 - acc: 0.5395 - val_loss: 0.8769 - val_acc: 0.5444\n","\n","Epoch 00002: val_acc improved from 0.48889 to 0.54444, saving model to result/left-right/OUR5-33/epoch-02-val-acc-0.5444.hdf5\n","Epoch 3/100\n","16/16 [==============================] - 0s 28ms/step - loss: 0.7580 - acc: 0.6558 - val_loss: 0.6634 - val_acc: 0.7111\n","\n","Epoch 00003: val_acc improved from 0.54444 to 0.71111, saving model to result/left-right/OUR5-33/epoch-03-val-acc-0.7111.hdf5\n","Epoch 4/100\n","16/16 [==============================] - 1s 33ms/step - loss: 0.5790 - acc: 0.7645 - val_loss: 0.7042 - val_acc: 0.7000\n","\n","Epoch 00004: val_acc did not improve from 0.71111\n","Epoch 5/100\n","16/16 [==============================] - 1s 33ms/step - loss: 0.5009 - acc: 0.8093 - val_loss: 0.6161 - val_acc: 0.7556\n","\n","Epoch 00005: val_acc improved from 0.71111 to 0.75556, saving model to result/left-right/OUR5-33/epoch-05-val-acc-0.7556.hdf5\n","Epoch 6/100\n","16/16 [==============================] - 0s 28ms/step - loss: 0.3958 - acc: 0.8480 - val_loss: 0.6024 - val_acc: 0.7111\n","\n","Epoch 00006: val_acc did not improve from 0.75556\n","Epoch 7/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.3084 - acc: 0.8890 - val_loss: 0.5389 - val_acc: 0.7778\n","\n","Epoch 00007: val_acc improved from 0.75556 to 0.77778, saving model to result/left-right/OUR5-33/epoch-07-val-acc-0.7778.hdf5\n","Epoch 8/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.2671 - acc: 0.9005 - val_loss: 0.7028 - val_acc: 0.7333\n","\n","Epoch 00008: val_acc did not improve from 0.77778\n","Epoch 9/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.2183 - acc: 0.9283 - val_loss: 0.6396 - val_acc: 0.7778\n","\n","Epoch 00009: val_acc did not improve from 0.77778\n","Epoch 10/100\n","16/16 [==============================] - 1s 34ms/step - loss: 0.1393 - acc: 0.9531 - val_loss: 0.6142 - val_acc: 0.7556\n","\n","Epoch 00010: val_acc did not improve from 0.77778\n","Epoch 11/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0955 - acc: 0.9744 - val_loss: 0.7692 - val_acc: 0.7667\n","\n","Epoch 00011: val_acc did not improve from 0.77778\n","Epoch 12/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0699 - acc: 0.9873 - val_loss: 0.8314 - val_acc: 0.7778\n","\n","Epoch 00012: val_acc did not improve from 0.77778\n","Epoch 13/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0409 - acc: 0.9936 - val_loss: 0.6931 - val_acc: 0.8111\n","\n","Epoch 00013: val_acc improved from 0.77778 to 0.81111, saving model to result/left-right/OUR5-33/epoch-13-val-acc-0.8111.hdf5\n","Epoch 14/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0282 - acc: 0.9971 - val_loss: 0.6815 - val_acc: 0.7889\n","\n","Epoch 00014: val_acc did not improve from 0.81111\n","Epoch 15/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0255 - acc: 0.9941 - val_loss: 0.6499 - val_acc: 0.8333\n","\n","Epoch 00015: val_acc improved from 0.81111 to 0.83333, saving model to result/left-right/OUR5-33/epoch-15-val-acc-0.8333.hdf5\n","Epoch 16/100\n","16/16 [==============================] - 0s 31ms/step - loss: 0.0184 - acc: 0.9980 - val_loss: 0.7118 - val_acc: 0.7889\n","\n","Epoch 00016: val_acc did not improve from 0.83333\n","Epoch 17/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0287 - acc: 0.9951 - val_loss: 0.5384 - val_acc: 0.8556\n","\n","Epoch 00017: val_acc improved from 0.83333 to 0.85556, saving model to result/left-right/OUR5-33/epoch-17-val-acc-0.8556.hdf5\n","Epoch 18/100\n","16/16 [==============================] - 0s 29ms/step - loss: 0.0221 - acc: 0.9990 - val_loss: 0.8407 - val_acc: 0.8111\n","\n","Epoch 00018: val_acc did not improve from 0.85556\n","Epoch 19/100\n","16/16 [==============================] - 1s 33ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.7756 - val_acc: 0.8222\n","\n","Epoch 00019: val_acc did not improve from 0.85556\n","Epoch 20/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.9090 - val_acc: 0.8000\n","\n","Epoch 00020: val_acc did not improve from 0.85556\n","Epoch 21/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.8177 - val_acc: 0.8222\n","\n","Epoch 00021: val_acc did not improve from 0.85556\n","Epoch 22/100\n","16/16 [==============================] - 1s 36ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.7864 - val_acc: 0.8000\n","\n","Epoch 00022: val_acc did not improve from 0.85556\n","Epoch 23/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.7823 - val_acc: 0.8444\n","\n","Epoch 00023: val_acc did not improve from 0.85556\n","Epoch 24/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.8305 - val_acc: 0.8333\n","\n","Epoch 00024: val_acc did not improve from 0.85556\n","Epoch 25/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.9016 - val_acc: 0.8333\n","\n","Epoch 00025: val_acc did not improve from 0.85556\n","Epoch 26/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.8000\n","\n","Epoch 00026: val_acc did not improve from 0.85556\n","Epoch 27/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.8237 - val_acc: 0.8111\n","\n","Epoch 00027: val_acc did not improve from 0.85556\n","Epoch 28/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0065 - acc: 0.9990 - val_loss: 0.9287 - val_acc: 0.8000\n","\n","Epoch 00028: val_acc did not improve from 0.85556\n","Epoch 29/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0121 - acc: 0.9975 - val_loss: 0.6851 - val_acc: 0.8444\n","\n","Epoch 00029: val_acc did not improve from 0.85556\n","Epoch 30/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7483 - val_acc: 0.8556\n","\n","Epoch 00030: val_acc did not improve from 0.85556\n","Epoch 31/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.6847 - val_acc: 0.8444\n","\n","Epoch 00031: val_acc did not improve from 0.85556\n","Epoch 32/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 0.8556\n","\n","Epoch 00032: val_acc improved from 0.85556 to 0.85556, saving model to result/left-right/OUR5-33/epoch-32-val-acc-0.8556.hdf5\n","Epoch 33/100\n","16/16 [==============================] - 0s 28ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.8817 - val_acc: 0.8333\n","\n","Epoch 00033: val_acc did not improve from 0.85556\n","Epoch 34/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.7540 - val_acc: 0.8444\n","\n","Epoch 00034: val_acc did not improve from 0.85556\n","Epoch 35/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.8582 - val_acc: 0.8444\n","\n","Epoch 00035: val_acc did not improve from 0.85556\n","Epoch 36/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.9215 - val_acc: 0.8333\n","\n","Epoch 00036: val_acc did not improve from 0.85556\n","Epoch 37/100\n","16/16 [==============================] - 1s 32ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.8219 - val_acc: 0.8222\n","\n","Epoch 00037: val_acc did not improve from 0.85556\n","Epoch 38/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0055 - acc: 0.9990 - val_loss: 0.7405 - val_acc: 0.8222\n","\n","Epoch 00038: val_acc did not improve from 0.85556\n","Epoch 39/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.9821 - val_acc: 0.7889\n","\n","Epoch 00039: val_acc did not improve from 0.85556\n","Epoch 40/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.8452 - val_acc: 0.8111\n","\n","Epoch 00040: val_acc did not improve from 0.85556\n","Epoch 41/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0110 - acc: 0.9971 - val_loss: 0.8772 - val_acc: 0.8111\n","\n","Epoch 00041: val_acc did not improve from 0.85556\n","Epoch 42/100\n","16/16 [==============================] - 0s 31ms/step - loss: 0.0151 - acc: 0.9955 - val_loss: 0.9625 - val_acc: 0.8000\n","\n","Epoch 00042: val_acc did not improve from 0.85556\n","Epoch 43/100\n","16/16 [==============================] - 1s 34ms/step - loss: 0.0106 - acc: 0.9990 - val_loss: 0.8505 - val_acc: 0.8222\n","\n","Epoch 00043: val_acc did not improve from 0.85556\n","Epoch 44/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.8582 - val_acc: 0.8556\n","\n","Epoch 00044: val_acc did not improve from 0.85556\n","Epoch 45/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8206 - val_acc: 0.8444\n","\n","Epoch 00045: val_acc did not improve from 0.85556\n","Epoch 46/100\n","16/16 [==============================] - 1s 36ms/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.9099 - val_acc: 0.7889\n","\n","Epoch 00046: val_acc did not improve from 0.85556\n","Epoch 47/100\n","16/16 [==============================] - 1s 34ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.7388 - val_acc: 0.8444\n","\n","Epoch 00047: val_acc did not improve from 0.85556\n","Epoch 48/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9506 - val_acc: 0.8222\n","\n","Epoch 00048: val_acc did not improve from 0.85556\n","Epoch 49/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.0085 - val_acc: 0.8333\n","\n","Epoch 00049: val_acc did not improve from 0.85556\n","Epoch 50/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0093 - acc: 0.9980 - val_loss: 1.1954 - val_acc: 0.8111\n","\n","Epoch 00050: val_acc did not improve from 0.85556\n","Epoch 51/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.8993 - val_acc: 0.8556\n","\n","Epoch 00051: val_acc did not improve from 0.85556\n","Epoch 52/100\n","16/16 [==============================] - 1s 34ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9940 - val_acc: 0.8222\n","\n","Epoch 00052: val_acc did not improve from 0.85556\n","Epoch 53/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.9522 - val_acc: 0.8444\n","\n","Epoch 00053: val_acc did not improve from 0.85556\n","Epoch 54/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0060 - acc: 0.9975 - val_loss: 0.8570 - val_acc: 0.8444\n","\n","Epoch 00054: val_acc did not improve from 0.85556\n","Epoch 55/100\n","16/16 [==============================] - 1s 34ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.7545 - val_acc: 0.8667\n","\n","Epoch 00055: val_acc improved from 0.85556 to 0.86667, saving model to result/left-right/OUR5-33/epoch-55-val-acc-0.8667.hdf5\n","Epoch 56/100\n","16/16 [==============================] - 1s 36ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9421 - val_acc: 0.8444\n","\n","Epoch 00056: val_acc did not improve from 0.86667\n","Epoch 57/100\n","16/16 [==============================] - 0s 30ms/step - loss: 5.6947e-04 - acc: 1.0000 - val_loss: 0.9463 - val_acc: 0.8444\n","\n","Epoch 00057: val_acc did not improve from 0.86667\n","Epoch 58/100\n","16/16 [==============================] - 1s 35ms/step - loss: 5.4304e-04 - acc: 1.0000 - val_loss: 0.9509 - val_acc: 0.8444\n","\n","Epoch 00058: val_acc did not improve from 0.86667\n","Epoch 59/100\n","16/16 [==============================] - 1s 35ms/step - loss: 9.9493e-04 - acc: 1.0000 - val_loss: 0.9293 - val_acc: 0.8333\n","\n","Epoch 00059: val_acc did not improve from 0.86667\n","Epoch 60/100\n","16/16 [==============================] - 0s 30ms/step - loss: 2.6883e-04 - acc: 1.0000 - val_loss: 0.8543 - val_acc: 0.8667\n","\n","Epoch 00060: val_acc did not improve from 0.86667\n","Epoch 61/100\n","16/16 [==============================] - 1s 34ms/step - loss: 6.1757e-04 - acc: 1.0000 - val_loss: 0.9218 - val_acc: 0.8556\n","\n","Epoch 00061: val_acc did not improve from 0.86667\n","Epoch 62/100\n","16/16 [==============================] - 1s 35ms/step - loss: 2.3070e-04 - acc: 1.0000 - val_loss: 0.9895 - val_acc: 0.8333\n","\n","Epoch 00062: val_acc did not improve from 0.86667\n","Epoch 63/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.9298 - val_acc: 0.8667\n","\n","Epoch 00063: val_acc did not improve from 0.86667\n","Epoch 64/100\n","16/16 [==============================] - 1s 34ms/step - loss: 5.4541e-04 - acc: 1.0000 - val_loss: 0.9594 - val_acc: 0.8778\n","\n","Epoch 00064: val_acc improved from 0.86667 to 0.87778, saving model to result/left-right/OUR5-33/epoch-64-val-acc-0.8778.hdf5\n","Epoch 65/100\n","16/16 [==============================] - 1s 36ms/step - loss: 6.0262e-04 - acc: 1.0000 - val_loss: 1.1394 - val_acc: 0.8444\n","\n","Epoch 00065: val_acc did not improve from 0.87778\n","Epoch 66/100\n","16/16 [==============================] - 0s 31ms/step - loss: 4.8310e-04 - acc: 1.0000 - val_loss: 1.0676 - val_acc: 0.8444\n","\n","Epoch 00066: val_acc did not improve from 0.87778\n","Epoch 67/100\n","16/16 [==============================] - 1s 34ms/step - loss: 1.5085e-04 - acc: 1.0000 - val_loss: 0.9701 - val_acc: 0.8556\n","\n","Epoch 00067: val_acc did not improve from 0.87778\n","Epoch 68/100\n","16/16 [==============================] - 1s 35ms/step - loss: 2.0330e-04 - acc: 1.0000 - val_loss: 1.0134 - val_acc: 0.8556\n","\n","Epoch 00068: val_acc did not improve from 0.87778\n","Epoch 69/100\n","16/16 [==============================] - 0s 30ms/step - loss: 2.0504e-04 - acc: 1.0000 - val_loss: 1.0571 - val_acc: 0.8556\n","\n","Epoch 00069: val_acc did not improve from 0.87778\n","Epoch 70/100\n","16/16 [==============================] - 1s 35ms/step - loss: 5.5606e-04 - acc: 1.0000 - val_loss: 1.0537 - val_acc: 0.8333\n","\n","Epoch 00070: val_acc did not improve from 0.87778\n","Epoch 71/100\n","16/16 [==============================] - 1s 34ms/step - loss: 7.3805e-04 - acc: 1.0000 - val_loss: 1.1344 - val_acc: 0.8111\n","\n","Epoch 00071: val_acc did not improve from 0.87778\n","Epoch 72/100\n","16/16 [==============================] - 0s 31ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.9500 - val_acc: 0.8444\n","\n","Epoch 00072: val_acc did not improve from 0.87778\n","Epoch 73/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0021 - acc: 0.9990 - val_loss: 1.1187 - val_acc: 0.8111\n","\n","Epoch 00073: val_acc did not improve from 0.87778\n","Epoch 74/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0037 - acc: 0.9990 - val_loss: 1.4055 - val_acc: 0.7778\n","\n","Epoch 00074: val_acc did not improve from 0.87778\n","Epoch 75/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.8477 - val_acc: 0.8333\n","\n","Epoch 00075: val_acc did not improve from 0.87778\n","Epoch 76/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0092 - acc: 0.9961 - val_loss: 0.7390 - val_acc: 0.8556\n","\n","Epoch 00076: val_acc did not improve from 0.87778\n","Epoch 77/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.9509 - val_acc: 0.8667\n","\n","Epoch 00077: val_acc did not improve from 0.87778\n","Epoch 78/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.8058 - val_acc: 0.8667\n","\n","Epoch 00078: val_acc did not improve from 0.87778\n","Epoch 79/100\n","16/16 [==============================] - 1s 34ms/step - loss: 8.3519e-04 - acc: 1.0000 - val_loss: 0.9923 - val_acc: 0.8556\n","\n","Epoch 00079: val_acc did not improve from 0.87778\n","Epoch 80/100\n","16/16 [==============================] - 1s 35ms/step - loss: 4.2866e-04 - acc: 1.0000 - val_loss: 0.9793 - val_acc: 0.8667\n","\n","Epoch 00080: val_acc did not improve from 0.87778\n","Epoch 81/100\n","16/16 [==============================] - 0s 30ms/step - loss: 5.1218e-04 - acc: 1.0000 - val_loss: 1.1468 - val_acc: 0.8222\n","\n","Epoch 00081: val_acc did not improve from 0.87778\n","Epoch 82/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.8322 - val_acc: 0.9000\n","\n","Epoch 00082: val_acc improved from 0.87778 to 0.90000, saving model to result/left-right/OUR5-33/epoch-82-val-acc-0.9000.hdf5\n","Epoch 83/100\n","16/16 [==============================] - 1s 36ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.1411 - val_acc: 0.8222\n","\n","Epoch 00083: val_acc did not improve from 0.90000\n","Epoch 84/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0023 - acc: 0.9990 - val_loss: 0.6788 - val_acc: 0.8889\n","\n","Epoch 00084: val_acc did not improve from 0.90000\n","Epoch 85/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0023 - acc: 0.9990 - val_loss: 0.8523 - val_acc: 0.8444\n","\n","Epoch 00085: val_acc did not improve from 0.90000\n","Epoch 86/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0020 - acc: 0.9990 - val_loss: 1.0095 - val_acc: 0.8444\n","\n","Epoch 00086: val_acc did not improve from 0.90000\n","Epoch 87/100\n","16/16 [==============================] - 0s 30ms/step - loss: 7.4720e-04 - acc: 1.0000 - val_loss: 0.7911 - val_acc: 0.8667\n","\n","Epoch 00087: val_acc did not improve from 0.90000\n","Epoch 88/100\n","16/16 [==============================] - 1s 35ms/step - loss: 4.0182e-04 - acc: 1.0000 - val_loss: 0.8786 - val_acc: 0.8333\n","\n","Epoch 00088: val_acc did not improve from 0.90000\n","Epoch 89/100\n","16/16 [==============================] - 1s 35ms/step - loss: 4.0814e-04 - acc: 1.0000 - val_loss: 0.9154 - val_acc: 0.8444\n","\n","Epoch 00089: val_acc did not improve from 0.90000\n","Epoch 90/100\n","16/16 [==============================] - 0s 30ms/step - loss: 1.3945e-04 - acc: 1.0000 - val_loss: 0.8807 - val_acc: 0.8667\n","\n","Epoch 00090: val_acc did not improve from 0.90000\n","Epoch 91/100\n","16/16 [==============================] - 1s 34ms/step - loss: 2.5736e-04 - acc: 1.0000 - val_loss: 0.8676 - val_acc: 0.8667\n","\n","Epoch 00091: val_acc did not improve from 0.90000\n","Epoch 92/100\n","16/16 [==============================] - 1s 35ms/step - loss: 1.7742e-04 - acc: 1.0000 - val_loss: 0.8662 - val_acc: 0.8667\n","\n","Epoch 00092: val_acc did not improve from 0.90000\n","Epoch 93/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0293 - acc: 0.9920 - val_loss: 0.9911 - val_acc: 0.7778\n","\n","Epoch 00093: val_acc did not improve from 0.90000\n","Epoch 94/100\n","16/16 [==============================] - 1s 34ms/step - loss: 0.2797 - acc: 0.9031 - val_loss: 0.6015 - val_acc: 0.7778\n","\n","Epoch 00094: val_acc did not improve from 0.90000\n","Epoch 95/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.1015 - acc: 0.9618 - val_loss: 0.6575 - val_acc: 0.7778\n","\n","Epoch 00095: val_acc did not improve from 0.90000\n","Epoch 96/100\n","16/16 [==============================] - 0s 30ms/step - loss: 0.0402 - acc: 0.9885 - val_loss: 0.6553 - val_acc: 0.8222\n","\n","Epoch 00096: val_acc did not improve from 0.90000\n","Epoch 97/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0137 - acc: 0.9965 - val_loss: 0.6713 - val_acc: 0.8333\n","\n","Epoch 00097: val_acc did not improve from 0.90000\n","Epoch 98/100\n","16/16 [==============================] - 1s 35ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.8596 - val_acc: 0.8333\n","\n","Epoch 00098: val_acc did not improve from 0.90000\n","Epoch 99/100\n","16/16 [==============================] - 0s 31ms/step - loss: 0.0052 - acc: 0.9980 - val_loss: 0.8635 - val_acc: 0.8333\n","\n","Epoch 00099: val_acc did not improve from 0.90000\n","Epoch 100/100\n","16/16 [==============================] - 1s 34ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.7938 - val_acc: 0.8111\n","\n","Epoch 00100: val_acc did not improve from 0.90000\n","\n","<keras.callbacks.History at 0x7f91a85c0f60>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pV03s6x2iE1-","colab_type":"code","colab":{}},"cell_type":"code","source":["#intersection\n","#our 6-60\n","\n","\n","\n","\n","Epoch 1/100\n","16/16 [==============================] - 2s 104ms/step - loss: 0.6716 - acc: 0.6379 - val_loss: 0.6577 - val_acc: 0.6271\n","\n","Epoch 00001: val_acc improved from -inf to 0.62712, saving model to result/intersection/OUR6-60/epoch-01-val-acc-0.6271.hdf5\n","Epoch 2/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.6546 - acc: 0.6505 - val_loss: 0.6517 - val_acc: 0.6271\n","\n","Epoch 00002: val_acc did not improve from 0.62712\n","Epoch 3/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.6257 - acc: 0.6712 - val_loss: 0.6066 - val_acc: 0.6441\n","\n","Epoch 00003: val_acc improved from 0.62712 to 0.64407, saving model to result/intersection/OUR6-60/epoch-03-val-acc-0.6441.hdf5\n","Epoch 4/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.4871 - acc: 0.7557 - val_loss: 0.5067 - val_acc: 0.7627\n","\n","Epoch 00004: val_acc improved from 0.64407 to 0.76271, saving model to result/intersection/OUR6-60/epoch-04-val-acc-0.7627.hdf5\n","Epoch 5/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.3597 - acc: 0.8381 - val_loss: 0.4046 - val_acc: 0.8305\n","\n","Epoch 00005: val_acc improved from 0.76271 to 0.83051, saving model to result/intersection/OUR6-60/epoch-05-val-acc-0.8305.hdf5\n","Epoch 6/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.2075 - acc: 0.9180 - val_loss: 0.4349 - val_acc: 0.8136\n","\n","Epoch 00006: val_acc did not improve from 0.83051\n","Epoch 7/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.1128 - acc: 0.9662 - val_loss: 0.3020 - val_acc: 0.8983\n","\n","Epoch 00007: val_acc improved from 0.83051 to 0.89831, saving model to result/intersection/OUR6-60/epoch-07-val-acc-0.8983.hdf5\n","Epoch 8/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0920 - acc: 0.9620 - val_loss: 0.2654 - val_acc: 0.8983\n","\n","Epoch 00008: val_acc did not improve from 0.89831\n","Epoch 9/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0606 - acc: 0.9805 - val_loss: 0.5250 - val_acc: 0.8644\n","\n","Epoch 00009: val_acc did not improve from 0.89831\n","Epoch 10/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0361 - acc: 0.9912 - val_loss: 0.4713 - val_acc: 0.8983\n","\n","Epoch 00010: val_acc did not improve from 0.89831\n","Epoch 11/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0430 - acc: 0.9850 - val_loss: 0.4420 - val_acc: 0.8983\n","\n","Epoch 00011: val_acc improved from 0.89831 to 0.89831, saving model to result/intersection/OUR6-60/epoch-11-val-acc-0.8983.hdf5\n","Epoch 12/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0287 - acc: 0.9863 - val_loss: 0.5667 - val_acc: 0.8644\n","\n","Epoch 00012: val_acc did not improve from 0.89831\n","Epoch 13/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0394 - acc: 0.9831 - val_loss: 0.5526 - val_acc: 0.8814\n","\n","Epoch 00013: val_acc did not improve from 0.89831\n","Epoch 14/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0314 - acc: 0.9921 - val_loss: 0.5248 - val_acc: 0.9153\n","\n","Epoch 00014: val_acc improved from 0.89831 to 0.91525, saving model to result/intersection/OUR6-60/epoch-14-val-acc-0.9153.hdf5\n","Epoch 15/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0321 - acc: 0.9873 - val_loss: 0.5541 - val_acc: 0.9153\n","\n","Epoch 00015: val_acc did not improve from 0.91525\n","Epoch 16/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0144 - acc: 0.9951 - val_loss: 0.6444 - val_acc: 0.8644\n","\n","Epoch 00016: val_acc did not improve from 0.91525\n","Epoch 17/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0110 - acc: 0.9971 - val_loss: 0.7179 - val_acc: 0.8983\n","\n","Epoch 00017: val_acc did not improve from 0.91525\n","Epoch 18/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0207 - acc: 0.9937 - val_loss: 0.5463 - val_acc: 0.9153\n","\n","Epoch 00018: val_acc did not improve from 0.91525\n","Epoch 19/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0099 - acc: 0.9951 - val_loss: 0.6515 - val_acc: 0.8983\n","\n","Epoch 00019: val_acc did not improve from 0.91525\n","Epoch 20/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0163 - acc: 0.9961 - val_loss: 0.7470 - val_acc: 0.8644\n","\n","Epoch 00020: val_acc did not improve from 0.91525\n","Epoch 21/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0083 - acc: 0.9966 - val_loss: 0.7308 - val_acc: 0.8644\n","\n","Epoch 00021: val_acc did not improve from 0.91525\n","Epoch 22/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0086 - acc: 0.9976 - val_loss: 0.7427 - val_acc: 0.8644\n","\n","Epoch 00022: val_acc did not improve from 0.91525\n","Epoch 23/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0114 - acc: 0.9990 - val_loss: 0.7314 - val_acc: 0.8983\n","\n","Epoch 00023: val_acc did not improve from 0.91525\n","Epoch 24/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8384 - val_acc: 0.8814\n","\n","Epoch 00024: val_acc did not improve from 0.91525\n","Epoch 25/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0089 - acc: 0.9971 - val_loss: 0.9369 - val_acc: 0.8644\n","\n","Epoch 00025: val_acc did not improve from 0.91525\n","Epoch 26/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.0402 - val_acc: 0.8475\n","\n","Epoch 00026: val_acc did not improve from 0.91525\n","Epoch 27/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0109 - acc: 0.9961 - val_loss: 0.6426 - val_acc: 0.8644\n","\n","Epoch 00027: val_acc did not improve from 0.91525\n","Epoch 28/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.7643 - val_acc: 0.8644\n","\n","Epoch 00028: val_acc did not improve from 0.91525\n","Epoch 29/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8978 - val_acc: 0.8644\n","\n","Epoch 00029: val_acc did not improve from 0.91525\n","Epoch 30/100\n","16/16 [==============================] - 1s 49ms/step - loss: 5.7785e-04 - acc: 1.0000 - val_loss: 0.9282 - val_acc: 0.8644\n","\n","Epoch 00030: val_acc did not improve from 0.91525\n","Epoch 31/100\n","16/16 [==============================] - 1s 50ms/step - loss: 7.4373e-04 - acc: 1.0000 - val_loss: 0.9357 - val_acc: 0.8644\n","\n","Epoch 00031: val_acc did not improve from 0.91525\n","Epoch 32/100\n","16/16 [==============================] - 1s 50ms/step - loss: 9.2383e-04 - acc: 1.0000 - val_loss: 0.8507 - val_acc: 0.8644\n","\n","Epoch 00032: val_acc did not improve from 0.91525\n","Epoch 33/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0016 - acc: 0.9990 - val_loss: 0.7855 - val_acc: 0.8983\n","\n","Epoch 00033: val_acc did not improve from 0.91525\n","Epoch 34/100\n","16/16 [==============================] - 1s 49ms/step - loss: 5.9383e-04 - acc: 1.0000 - val_loss: 0.6700 - val_acc: 0.8983\n","\n","Epoch 00034: val_acc did not improve from 0.91525\n","Epoch 35/100\n","16/16 [==============================] - 1s 50ms/step - loss: 7.5669e-04 - acc: 1.0000 - val_loss: 0.7742 - val_acc: 0.8983\n","\n","Epoch 00035: val_acc did not improve from 0.91525\n","Epoch 36/100\n","16/16 [==============================] - 1s 50ms/step - loss: 3.3613e-04 - acc: 1.0000 - val_loss: 0.8332 - val_acc: 0.8983\n","\n","Epoch 00036: val_acc did not improve from 0.91525\n","Epoch 37/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.8558e-04 - acc: 1.0000 - val_loss: 0.9014 - val_acc: 0.8814\n","\n","Epoch 00037: val_acc did not improve from 0.91525\n","Epoch 38/100\n","16/16 [==============================] - 1s 50ms/step - loss: 5.5694e-05 - acc: 1.0000 - val_loss: 0.9062 - val_acc: 0.8814\n","\n","Epoch 00038: val_acc did not improve from 0.91525\n","Epoch 39/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.0377e-04 - acc: 1.0000 - val_loss: 0.8935 - val_acc: 0.8983\n","\n","Epoch 00039: val_acc did not improve from 0.91525\n","Epoch 40/100\n","16/16 [==============================] - 1s 50ms/step - loss: 8.3422e-05 - acc: 1.0000 - val_loss: 0.8923 - val_acc: 0.8983\n","\n","Epoch 00040: val_acc did not improve from 0.91525\n","Epoch 41/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.8290e-04 - acc: 1.0000 - val_loss: 0.8290 - val_acc: 0.8983\n","\n","Epoch 00041: val_acc did not improve from 0.91525\n","Epoch 42/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.0200e-04 - acc: 1.0000 - val_loss: 0.8980 - val_acc: 0.8814\n","\n","Epoch 00042: val_acc did not improve from 0.91525\n","Epoch 43/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.3232e-04 - acc: 1.0000 - val_loss: 0.8818 - val_acc: 0.8814\n","\n","Epoch 00043: val_acc did not improve from 0.91525\n","Epoch 44/100\n","16/16 [==============================] - 1s 49ms/step - loss: 2.9530e-04 - acc: 1.0000 - val_loss: 0.8522 - val_acc: 0.8814\n","\n","Epoch 00044: val_acc did not improve from 0.91525\n","Epoch 45/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.5182e-04 - acc: 1.0000 - val_loss: 0.8368 - val_acc: 0.8814\n","\n","Epoch 00045: val_acc did not improve from 0.91525\n","Epoch 46/100\n","16/16 [==============================] - 1s 50ms/step - loss: 5.6731e-05 - acc: 1.0000 - val_loss: 0.8628 - val_acc: 0.8814\n","\n","Epoch 00046: val_acc did not improve from 0.91525\n","Epoch 47/100\n","16/16 [==============================] - 1s 50ms/step - loss: 5.8438e-05 - acc: 1.0000 - val_loss: 0.8788 - val_acc: 0.8814\n","\n","Epoch 00047: val_acc did not improve from 0.91525\n","Epoch 48/100\n","16/16 [==============================] - 1s 50ms/step - loss: 6.7971e-04 - acc: 1.0000 - val_loss: 0.8451 - val_acc: 0.8983\n","\n","Epoch 00048: val_acc did not improve from 0.91525\n","Epoch 49/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.1614e-04 - acc: 1.0000 - val_loss: 0.9862 - val_acc: 0.8814\n","\n","Epoch 00049: val_acc did not improve from 0.91525\n","Epoch 50/100\n","16/16 [==============================] - 1s 50ms/step - loss: 6.0773e-05 - acc: 1.0000 - val_loss: 0.9668 - val_acc: 0.8814\n","\n","Epoch 00050: val_acc did not improve from 0.91525\n","Epoch 51/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.3250e-04 - acc: 1.0000 - val_loss: 0.8558 - val_acc: 0.8983\n","\n","Epoch 00051: val_acc did not improve from 0.91525\n","Epoch 52/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0327 - acc: 0.9918 - val_loss: 0.9529 - val_acc: 0.8475\n","\n","Epoch 00052: val_acc did not improve from 0.91525\n","Epoch 53/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0548 - acc: 0.9882 - val_loss: 0.7098 - val_acc: 0.8644\n","\n","Epoch 00053: val_acc did not improve from 0.91525\n","Epoch 54/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0178 - acc: 0.9922 - val_loss: 0.7977 - val_acc: 0.9153\n","\n","Epoch 00054: val_acc did not improve from 0.91525\n","Epoch 55/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0176 - acc: 0.9951 - val_loss: 1.2356 - val_acc: 0.8305\n","\n","Epoch 00055: val_acc did not improve from 0.91525\n","Epoch 56/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0446 - acc: 0.9843 - val_loss: 0.8580 - val_acc: 0.7966\n","\n","Epoch 00056: val_acc did not improve from 0.91525\n","Epoch 57/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0648 - acc: 0.9781 - val_loss: 0.8473 - val_acc: 0.8983\n","\n","Epoch 00057: val_acc did not improve from 0.91525\n","Epoch 58/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0833 - acc: 0.9729 - val_loss: 0.8254 - val_acc: 0.8305\n","\n","Epoch 00058: val_acc did not improve from 0.91525\n","Epoch 59/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0303 - acc: 0.9907 - val_loss: 0.5835 - val_acc: 0.8814\n","\n","Epoch 00059: val_acc did not improve from 0.91525\n","Epoch 60/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0084 - acc: 0.9951 - val_loss: 0.6294 - val_acc: 0.8983\n","\n","Epoch 00060: val_acc did not improve from 0.91525\n","Epoch 61/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0015 - acc: 0.9990 - val_loss: 0.7775 - val_acc: 0.8644\n","\n","Epoch 00061: val_acc did not improve from 0.91525\n","Epoch 62/100\n","16/16 [==============================] - 1s 50ms/step - loss: 5.7995e-04 - acc: 1.0000 - val_loss: 0.7126 - val_acc: 0.8983\n","\n","Epoch 00062: val_acc did not improve from 0.91525\n","Epoch 63/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0079 - acc: 0.9976 - val_loss: 0.8168 - val_acc: 0.8644\n","\n","Epoch 00063: val_acc did not improve from 0.91525\n","Epoch 64/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.8514 - val_acc: 0.8814\n","\n","Epoch 00064: val_acc did not improve from 0.91525\n","Epoch 65/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0047 - acc: 0.9976 - val_loss: 1.0550 - val_acc: 0.8814\n","\n","Epoch 00065: val_acc did not improve from 0.91525\n","Epoch 66/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0032 - acc: 0.9990 - val_loss: 1.0856 - val_acc: 0.8814\n","\n","Epoch 00066: val_acc did not improve from 0.91525\n","Epoch 67/100\n","16/16 [==============================] - 1s 50ms/step - loss: 8.1651e-04 - acc: 1.0000 - val_loss: 1.0313 - val_acc: 0.8814\n","\n","Epoch 00067: val_acc did not improve from 0.91525\n","Epoch 68/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.8562e-04 - acc: 1.0000 - val_loss: 1.0284 - val_acc: 0.8983\n","\n","Epoch 00068: val_acc did not improve from 0.91525\n","Epoch 69/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.8928 - val_acc: 0.9153\n","\n","Epoch 00069: val_acc did not improve from 0.91525\n","Epoch 70/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.1766e-04 - acc: 1.0000 - val_loss: 0.9379 - val_acc: 0.9322\n","\n","Epoch 00070: val_acc improved from 0.91525 to 0.93220, saving model to result/intersection/OUR6-60/epoch-70-val-acc-0.9322.hdf5\n","Epoch 71/100\n","16/16 [==============================] - 1s 49ms/step - loss: 7.4875e-04 - acc: 1.0000 - val_loss: 0.9379 - val_acc: 0.9322\n","\n","Epoch 00071: val_acc did not improve from 0.93220\n","Epoch 72/100\n","16/16 [==============================] - 1s 49ms/step - loss: 5.8317e-04 - acc: 1.0000 - val_loss: 1.1228 - val_acc: 0.8814\n","\n","Epoch 00072: val_acc did not improve from 0.93220\n","Epoch 73/100\n","16/16 [==============================] - 1s 50ms/step - loss: 4.6474e-04 - acc: 1.0000 - val_loss: 0.9350 - val_acc: 0.9153\n","\n","Epoch 00073: val_acc did not improve from 0.93220\n","Epoch 74/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0039 - acc: 0.9980 - val_loss: 1.0790 - val_acc: 0.8983\n","\n","Epoch 00074: val_acc did not improve from 0.93220\n","Epoch 75/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0045 - acc: 0.9990 - val_loss: 1.2481 - val_acc: 0.8644\n","\n","Epoch 00075: val_acc did not improve from 0.93220\n","Epoch 76/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0210 - acc: 0.9947 - val_loss: 1.1154 - val_acc: 0.8475\n","\n","Epoch 00076: val_acc did not improve from 0.93220\n","Epoch 77/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0342 - acc: 0.9927 - val_loss: 0.9903 - val_acc: 0.8136\n","\n","Epoch 00077: val_acc did not improve from 0.93220\n","Epoch 78/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0176 - acc: 0.9931 - val_loss: 1.2690 - val_acc: 0.8305\n","\n","Epoch 00078: val_acc did not improve from 0.93220\n","Epoch 79/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0086 - acc: 0.9971 - val_loss: 1.1911 - val_acc: 0.8305\n","\n","Epoch 00079: val_acc did not improve from 0.93220\n","Epoch 80/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0061 - acc: 0.9980 - val_loss: 1.1323 - val_acc: 0.8644\n","\n","Epoch 00080: val_acc did not improve from 0.93220\n","Epoch 81/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0041 - acc: 0.9980 - val_loss: 1.0810 - val_acc: 0.8475\n","\n","Epoch 00081: val_acc did not improve from 0.93220\n","Epoch 82/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0050 - acc: 0.9980 - val_loss: 1.0843 - val_acc: 0.8475\n","\n","Epoch 00082: val_acc did not improve from 0.93220\n","Epoch 83/100\n","16/16 [==============================] - 1s 50ms/step - loss: 9.6748e-04 - acc: 1.0000 - val_loss: 1.0218 - val_acc: 0.8475\n","\n","Epoch 00083: val_acc did not improve from 0.93220\n","Epoch 84/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0058 - acc: 0.9990 - val_loss: 0.7811 - val_acc: 0.8814\n","\n","Epoch 00084: val_acc did not improve from 0.93220\n","Epoch 85/100\n","16/16 [==============================] - 1s 50ms/step - loss: 3.1299e-04 - acc: 1.0000 - val_loss: 0.7973 - val_acc: 0.8814\n","\n","Epoch 00085: val_acc did not improve from 0.93220\n","Epoch 86/100\n","16/16 [==============================] - 1s 50ms/step - loss: 7.0096e-04 - acc: 1.0000 - val_loss: 0.8016 - val_acc: 0.8814\n","\n","Epoch 00086: val_acc did not improve from 0.93220\n","Epoch 87/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.6404e-04 - acc: 1.0000 - val_loss: 0.8295 - val_acc: 0.8983\n","\n","Epoch 00087: val_acc did not improve from 0.93220\n","Epoch 88/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.9313e-04 - acc: 1.0000 - val_loss: 0.8557 - val_acc: 0.8814\n","\n","Epoch 00088: val_acc did not improve from 0.93220\n","Epoch 89/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.4094e-04 - acc: 1.0000 - val_loss: 0.8634 - val_acc: 0.8814\n","\n","Epoch 00089: val_acc did not improve from 0.93220\n","Epoch 90/100\n","16/16 [==============================] - 1s 50ms/step - loss: 7.6526e-05 - acc: 1.0000 - val_loss: 0.8786 - val_acc: 0.8814\n","\n","Epoch 00090: val_acc did not improve from 0.93220\n","Epoch 91/100\n","16/16 [==============================] - 1s 50ms/step - loss: 7.5778e-05 - acc: 1.0000 - val_loss: 0.8699 - val_acc: 0.8814\n","\n","Epoch 00091: val_acc did not improve from 0.93220\n","Epoch 92/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.3247e-04 - acc: 1.0000 - val_loss: 0.8041 - val_acc: 0.8983\n","\n","Epoch 00092: val_acc did not improve from 0.93220\n","Epoch 93/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.1892e-04 - acc: 1.0000 - val_loss: 0.8025 - val_acc: 0.8983\n","\n","Epoch 00093: val_acc did not improve from 0.93220\n","Epoch 94/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.0574e-04 - acc: 1.0000 - val_loss: 0.8087 - val_acc: 0.8983\n","\n","Epoch 00094: val_acc did not improve from 0.93220\n","Epoch 95/100\n","16/16 [==============================] - 1s 50ms/step - loss: 4.3506e-05 - acc: 1.0000 - val_loss: 0.8144 - val_acc: 0.8983\n","\n","Epoch 00095: val_acc did not improve from 0.93220\n","Epoch 96/100\n","16/16 [==============================] - 1s 50ms/step - loss: 9.5422e-05 - acc: 1.0000 - val_loss: 0.8296 - val_acc: 0.8983\n","\n","Epoch 00096: val_acc did not improve from 0.93220\n","Epoch 97/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.6130e-05 - acc: 1.0000 - val_loss: 0.8397 - val_acc: 0.8983\n","\n","Epoch 00097: val_acc did not improve from 0.93220\n","Epoch 98/100\n","16/16 [==============================] - 1s 50ms/step - loss: 4.1492e-05 - acc: 1.0000 - val_loss: 0.8568 - val_acc: 0.9153\n","\n","Epoch 00098: val_acc did not improve from 0.93220\n","Epoch 99/100\n","16/16 [==============================] - 1s 50ms/step - loss: 5.5095e-05 - acc: 1.0000 - val_loss: 0.8677 - val_acc: 0.9153\n","\n","Epoch 00099: val_acc did not improve from 0.93220\n","Epoch 100/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.3765e-05 - acc: 1.0000 - val_loss: 0.8850 - val_acc: 0.9153\n","\n","Epoch 00100: val_acc did not improve from 0.93220\n","\n","<keras.callbacks.History at 0x7f4c20db10b8>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HluslTN5Yfmo","colab_type":"code","colab":{}},"cell_type":"code","source":["# intersectin 89\n","#our 6-55 moment=0.5\n","\n","Epoch 1/100\n","16/16 [==============================] - 1s 81ms/step - loss: 0.6654 - acc: 0.6261 - val_loss: 0.6351 - val_acc: 0.6271\n","\n","Epoch 00001: val_acc improved from -inf to 0.62712, saving model to result/intersection/OUR6-46/epoch-01-val-acc-0.6271.hdf5\n","Epoch 2/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.6286 - acc: 0.6688 - val_loss: 0.5978 - val_acc: 0.7627\n","\n","Epoch 00002: val_acc improved from 0.62712 to 0.76271, saving model to result/intersection/OUR6-46/epoch-02-val-acc-0.7627.hdf5\n","Epoch 3/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.4704 - acc: 0.7722 - val_loss: 0.5930 - val_acc: 0.6780\n","\n","Epoch 00003: val_acc did not improve from 0.76271\n","Epoch 4/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.2652 - acc: 0.8763 - val_loss: 0.3849 - val_acc: 0.8136\n","\n","Epoch 00004: val_acc improved from 0.76271 to 0.81356, saving model to result/intersection/OUR6-46/epoch-04-val-acc-0.8136.hdf5\n","Epoch 5/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.1676 - acc: 0.9283 - val_loss: 0.5133 - val_acc: 0.8644\n","\n","Epoch 00005: val_acc improved from 0.81356 to 0.86441, saving model to result/intersection/OUR6-46/epoch-05-val-acc-0.8644.hdf5\n","Epoch 6/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.1447 - acc: 0.9438 - val_loss: 0.3910 - val_acc: 0.8644\n","\n","Epoch 00006: val_acc did not improve from 0.86441\n","Epoch 7/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0721 - acc: 0.9718 - val_loss: 0.4875 - val_acc: 0.8475\n","\n","Epoch 00007: val_acc did not improve from 0.86441\n","Epoch 8/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0313 - acc: 0.9882 - val_loss: 0.7337 - val_acc: 0.8305\n","\n","Epoch 00008: val_acc did not improve from 0.86441\n","Epoch 9/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0188 - acc: 0.9937 - val_loss: 0.8816 - val_acc: 0.8644\n","\n","Epoch 00009: val_acc improved from 0.86441 to 0.86441, saving model to result/intersection/OUR6-46/epoch-09-val-acc-0.8644.hdf5\n","Epoch 10/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0201 - acc: 0.9922 - val_loss: 0.7918 - val_acc: 0.8644\n","\n","Epoch 00010: val_acc did not improve from 0.86441\n","Epoch 11/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0121 - acc: 0.9946 - val_loss: 1.3000 - val_acc: 0.8136\n","\n","Epoch 00011: val_acc did not improve from 0.86441\n","Epoch 12/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0410 - acc: 0.9800 - val_loss: 0.7596 - val_acc: 0.8475\n","\n","Epoch 00012: val_acc did not improve from 0.86441\n","Epoch 13/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0304 - acc: 0.9854 - val_loss: 0.8026 - val_acc: 0.8644\n","\n","Epoch 00013: val_acc did not improve from 0.86441\n","Epoch 14/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0165 - acc: 0.9941 - val_loss: 0.6962 - val_acc: 0.8644\n","\n","Epoch 00014: val_acc did not improve from 0.86441\n","Epoch 15/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0049 - acc: 0.9990 - val_loss: 0.9024 - val_acc: 0.8305\n","\n","Epoch 00015: val_acc did not improve from 0.86441\n","Epoch 16/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0096 - acc: 0.9980 - val_loss: 0.7740 - val_acc: 0.8644\n","\n","Epoch 00016: val_acc did not improve from 0.86441\n","Epoch 17/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8201 - val_acc: 0.8644\n","\n","Epoch 00017: val_acc did not improve from 0.86441\n","Epoch 18/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0052 - acc: 0.9990 - val_loss: 0.8927 - val_acc: 0.8475\n","\n","Epoch 00018: val_acc did not improve from 0.86441\n","Epoch 19/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0078 - acc: 0.9980 - val_loss: 0.8295 - val_acc: 0.8644\n","\n","Epoch 00019: val_acc did not improve from 0.86441\n","Epoch 20/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.7565 - val_acc: 0.8475\n","\n","Epoch 00020: val_acc did not improve from 0.86441\n","Epoch 21/100\n","16/16 [==============================] - 1s 50ms/step - loss: 5.6706e-04 - acc: 1.0000 - val_loss: 0.7636 - val_acc: 0.8644\n","\n","Epoch 00021: val_acc did not improve from 0.86441\n","Epoch 22/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0022 - acc: 0.9986 - val_loss: 0.9871 - val_acc: 0.8136\n","\n","Epoch 00022: val_acc did not improve from 0.86441\n","Epoch 23/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0311 - val_acc: 0.8305\n","\n","Epoch 00023: val_acc did not improve from 0.86441\n","Epoch 24/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.2405 - val_acc: 0.8136\n","\n","Epoch 00024: val_acc did not improve from 0.86441\n","Epoch 25/100\n","16/16 [==============================] - 1s 50ms/step - loss: 3.1844e-04 - acc: 1.0000 - val_loss: 1.1958 - val_acc: 0.8475\n","\n","Epoch 00025: val_acc did not improve from 0.86441\n","Epoch 26/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0018 - acc: 0.9986 - val_loss: 0.8960 - val_acc: 0.8814\n","\n","Epoch 00026: val_acc improved from 0.86441 to 0.88136, saving model to result/intersection/OUR6-46/epoch-26-val-acc-0.8814.hdf5\n","Epoch 27/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0062 - acc: 0.9980 - val_loss: 1.3711 - val_acc: 0.8136\n","\n","Epoch 00027: val_acc did not improve from 0.88136\n","Epoch 28/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0065 - acc: 0.9980 - val_loss: 0.7735 - val_acc: 0.8644\n","\n","Epoch 00028: val_acc did not improve from 0.88136\n","Epoch 29/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0153 - acc: 0.9922 - val_loss: 1.4683 - val_acc: 0.8305\n","\n","Epoch 00029: val_acc did not improve from 0.88136\n","Epoch 30/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.1266 - acc: 0.9738 - val_loss: 0.7664 - val_acc: 0.8475\n","\n","Epoch 00030: val_acc did not improve from 0.88136\n","Epoch 31/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0367 - acc: 0.9858 - val_loss: 0.9432 - val_acc: 0.8305\n","\n","Epoch 00031: val_acc did not improve from 0.88136\n","Epoch 32/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0560 - acc: 0.9820 - val_loss: 0.8969 - val_acc: 0.8305\n","\n","Epoch 00032: val_acc did not improve from 0.88136\n","Epoch 33/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0108 - acc: 0.9956 - val_loss: 0.9544 - val_acc: 0.8305\n","\n","Epoch 00033: val_acc did not improve from 0.88136\n","Epoch 34/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.1289 - val_acc: 0.7966\n","\n","Epoch 00034: val_acc did not improve from 0.88136\n","Epoch 35/100\n","16/16 [==============================] - 1s 50ms/step - loss: 4.3271e-04 - acc: 1.0000 - val_loss: 1.1426 - val_acc: 0.7966\n","\n","Epoch 00035: val_acc did not improve from 0.88136\n","Epoch 36/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.4748 - val_acc: 0.7797\n","\n","Epoch 00036: val_acc did not improve from 0.88136\n","Epoch 37/100\n","16/16 [==============================] - 1s 50ms/step - loss: 6.6571e-04 - acc: 1.0000 - val_loss: 1.1398 - val_acc: 0.7797\n","\n","Epoch 00037: val_acc did not improve from 0.88136\n","Epoch 38/100\n","16/16 [==============================] - 1s 50ms/step - loss: 6.1551e-04 - acc: 1.0000 - val_loss: 0.9440 - val_acc: 0.8644\n","\n","Epoch 00038: val_acc did not improve from 0.88136\n","Epoch 39/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.4623e-04 - acc: 1.0000 - val_loss: 1.0142 - val_acc: 0.8305\n","\n","Epoch 00039: val_acc did not improve from 0.88136\n","Epoch 40/100\n","16/16 [==============================] - 1s 50ms/step - loss: 9.5317e-05 - acc: 1.0000 - val_loss: 1.0586 - val_acc: 0.8475\n","\n","Epoch 00040: val_acc did not improve from 0.88136\n","Epoch 41/100\n","16/16 [==============================] - 1s 50ms/step - loss: 4.8496e-05 - acc: 1.0000 - val_loss: 1.0880 - val_acc: 0.8305\n","\n","Epoch 00041: val_acc did not improve from 0.88136\n","Epoch 42/100\n","16/16 [==============================] - 1s 50ms/step - loss: 7.8134e-05 - acc: 1.0000 - val_loss: 1.1117 - val_acc: 0.8305\n","\n","Epoch 00042: val_acc did not improve from 0.88136\n","Epoch 43/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.3914e-04 - acc: 1.0000 - val_loss: 1.1385 - val_acc: 0.8305\n","\n","Epoch 00043: val_acc did not improve from 0.88136\n","Epoch 44/100\n","16/16 [==============================] - 1s 50ms/step - loss: 5.0643e-04 - acc: 1.0000 - val_loss: 1.4062 - val_acc: 0.8136\n","\n","Epoch 00044: val_acc did not improve from 0.88136\n","Epoch 45/100\n","16/16 [==============================] - 1s 50ms/step - loss: 6.3605e-04 - acc: 1.0000 - val_loss: 1.2070 - val_acc: 0.8305\n","\n","Epoch 00045: val_acc did not improve from 0.88136\n","Epoch 46/100\n","16/16 [==============================] - 1s 50ms/step - loss: 3.4124e-05 - acc: 1.0000 - val_loss: 1.1029 - val_acc: 0.8136\n","\n","Epoch 00046: val_acc did not improve from 0.88136\n","Epoch 47/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.0934e-04 - acc: 1.0000 - val_loss: 1.1337 - val_acc: 0.8136\n","\n","Epoch 00047: val_acc did not improve from 0.88136\n","Epoch 48/100\n","16/16 [==============================] - 1s 50ms/step - loss: 7.3064e-05 - acc: 1.0000 - val_loss: 1.1626 - val_acc: 0.8305\n","\n","Epoch 00048: val_acc did not improve from 0.88136\n","Epoch 49/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.0980e-05 - acc: 1.0000 - val_loss: 1.1701 - val_acc: 0.8305\n","\n","Epoch 00049: val_acc did not improve from 0.88136\n","Epoch 50/100\n","16/16 [==============================] - 1s 50ms/step - loss: 7.8451e-04 - acc: 0.9990 - val_loss: 1.1690 - val_acc: 0.8305\n","\n","Epoch 00050: val_acc did not improve from 0.88136\n","Epoch 51/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.1790e-04 - acc: 1.0000 - val_loss: 1.0462 - val_acc: 0.8475\n","\n","Epoch 00051: val_acc did not improve from 0.88136\n","Epoch 52/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0024 - acc: 0.9986 - val_loss: 1.2157 - val_acc: 0.8475\n","\n","Epoch 00052: val_acc did not improve from 0.88136\n","Epoch 53/100\n","16/16 [==============================] - 1s 50ms/step - loss: 7.1690e-04 - acc: 1.0000 - val_loss: 0.8956 - val_acc: 0.8475\n","\n","Epoch 00053: val_acc did not improve from 0.88136\n","Epoch 54/100\n","16/16 [==============================] - 1s 50ms/step - loss: 5.4155e-05 - acc: 1.0000 - val_loss: 0.8926 - val_acc: 0.8644\n","\n","Epoch 00054: val_acc did not improve from 0.88136\n","Epoch 55/100\n","16/16 [==============================] - 1s 50ms/step - loss: 7.7029e-05 - acc: 1.0000 - val_loss: 0.9151 - val_acc: 0.8475\n","\n","Epoch 00055: val_acc did not improve from 0.88136\n","Epoch 56/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.6718e-04 - acc: 1.0000 - val_loss: 0.9703 - val_acc: 0.8136\n","\n","Epoch 00056: val_acc did not improve from 0.88136\n","Epoch 57/100\n","16/16 [==============================] - 1s 51ms/step - loss: 6.5578e-05 - acc: 1.0000 - val_loss: 1.0271 - val_acc: 0.8136\n","\n","Epoch 00057: val_acc did not improve from 0.88136\n","Epoch 58/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0061 - acc: 0.9980 - val_loss: 1.6155 - val_acc: 0.8136\n","\n","Epoch 00058: val_acc did not improve from 0.88136\n","Epoch 59/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0015 - acc: 0.9986 - val_loss: 1.4249 - val_acc: 0.8136\n","\n","Epoch 00059: val_acc did not improve from 0.88136\n","Epoch 60/100\n","16/16 [==============================] - 1s 50ms/step - loss: 6.8488e-04 - acc: 1.0000 - val_loss: 1.4655 - val_acc: 0.8136\n","\n","Epoch 00060: val_acc did not improve from 0.88136\n","Epoch 61/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0013 - acc: 0.9990 - val_loss: 1.1622 - val_acc: 0.8814\n","\n","Epoch 00061: val_acc did not improve from 0.88136\n","Epoch 62/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0149 - acc: 0.9961 - val_loss: 1.1358 - val_acc: 0.8136\n","\n","Epoch 00062: val_acc did not improve from 0.88136\n","Epoch 63/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0037 - acc: 0.9990 - val_loss: 2.5948 - val_acc: 0.7797\n","\n","Epoch 00063: val_acc did not improve from 0.88136\n","Epoch 64/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0283 - acc: 0.9928 - val_loss: 1.2359 - val_acc: 0.8644\n","\n","Epoch 00064: val_acc did not improve from 0.88136\n","Epoch 65/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0993 - acc: 0.9859 - val_loss: 1.1204 - val_acc: 0.8644\n","\n","Epoch 00065: val_acc did not improve from 0.88136\n","Epoch 66/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0322 - acc: 0.9898 - val_loss: 1.4027 - val_acc: 0.8305\n","\n","Epoch 00066: val_acc did not improve from 0.88136\n","Epoch 67/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.1160 - acc: 0.9762 - val_loss: 0.9451 - val_acc: 0.8983\n","\n","Epoch 00067: val_acc improved from 0.88136 to 0.89831, saving model to result/intersection/OUR6-46/epoch-67-val-acc-0.8983.hdf5\n","Epoch 68/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.1689 - acc: 0.9728 - val_loss: 1.2560 - val_acc: 0.8475\n","\n","Epoch 00068: val_acc did not improve from 0.89831\n","Epoch 69/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0693 - acc: 0.9800 - val_loss: 1.5831 - val_acc: 0.8305\n","\n","Epoch 00069: val_acc did not improve from 0.89831\n","Epoch 70/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0606 - acc: 0.9907 - val_loss: 1.1248 - val_acc: 0.8644\n","\n","Epoch 00070: val_acc did not improve from 0.89831\n","Epoch 71/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0119 - acc: 0.9951 - val_loss: 0.9948 - val_acc: 0.8644\n","\n","Epoch 00071: val_acc did not improve from 0.89831\n","Epoch 72/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0047 - acc: 0.9976 - val_loss: 0.9113 - val_acc: 0.8814\n","\n","Epoch 00072: val_acc did not improve from 0.89831\n","Epoch 73/100\n","16/16 [==============================] - 1s 50ms/step - loss: 8.2767e-04 - acc: 1.0000 - val_loss: 1.2260 - val_acc: 0.8814\n","\n","Epoch 00073: val_acc did not improve from 0.89831\n","Epoch 74/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.9621e-05 - acc: 1.0000 - val_loss: 1.2564 - val_acc: 0.8814\n","\n","Epoch 00074: val_acc did not improve from 0.89831\n","Epoch 75/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0061 - acc: 0.9986 - val_loss: 1.2240 - val_acc: 0.8644\n","\n","Epoch 00075: val_acc did not improve from 0.89831\n","Epoch 76/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0014 - acc: 0.9990 - val_loss: 1.2320 - val_acc: 0.8644\n","\n","Epoch 00076: val_acc did not improve from 0.89831\n","Epoch 77/100\n","16/16 [==============================] - 1s 50ms/step - loss: 5.2010e-04 - acc: 1.0000 - val_loss: 0.9163 - val_acc: 0.8814\n","\n","Epoch 00077: val_acc did not improve from 0.89831\n","Epoch 78/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0020 - acc: 0.9986 - val_loss: 0.9220 - val_acc: 0.8814\n","\n","Epoch 00078: val_acc did not improve from 0.89831\n","Epoch 79/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0066 - acc: 0.9990 - val_loss: 1.1049 - val_acc: 0.8814\n","\n","Epoch 00079: val_acc did not improve from 0.89831\n","Epoch 80/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0015 - acc: 0.9990 - val_loss: 0.9273 - val_acc: 0.8814\n","\n","Epoch 00080: val_acc did not improve from 0.89831\n","Epoch 81/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.3269e-05 - acc: 1.0000 - val_loss: 0.8171 - val_acc: 0.8644\n","\n","Epoch 00081: val_acc did not improve from 0.89831\n","Epoch 82/100\n","16/16 [==============================] - 1s 50ms/step - loss: 7.7850e-06 - acc: 1.0000 - val_loss: 0.8043 - val_acc: 0.8644\n","\n","Epoch 00082: val_acc did not improve from 0.89831\n","Epoch 83/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.3109e-06 - acc: 1.0000 - val_loss: 0.8038 - val_acc: 0.8644\n","\n","Epoch 00083: val_acc did not improve from 0.89831\n","Epoch 84/100\n","16/16 [==============================] - 1s 49ms/step - loss: 6.4393e-06 - acc: 1.0000 - val_loss: 0.8028 - val_acc: 0.8644\n","\n","Epoch 00084: val_acc did not improve from 0.89831\n","Epoch 85/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.2678e-05 - acc: 1.0000 - val_loss: 0.8022 - val_acc: 0.8644\n","\n","Epoch 00085: val_acc did not improve from 0.89831\n","Epoch 86/100\n","16/16 [==============================] - 1s 50ms/step - loss: 5.2858e-06 - acc: 1.0000 - val_loss: 0.8032 - val_acc: 0.8644\n","\n","Epoch 00086: val_acc did not improve from 0.89831\n","Epoch 87/100\n","16/16 [==============================] - 1s 50ms/step - loss: 7.4268e-06 - acc: 1.0000 - val_loss: 0.8044 - val_acc: 0.8644\n","\n","Epoch 00087: val_acc did not improve from 0.89831\n","Epoch 88/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.2505e-06 - acc: 1.0000 - val_loss: 0.8046 - val_acc: 0.8644\n","\n","Epoch 00088: val_acc did not improve from 0.89831\n","Epoch 89/100\n","16/16 [==============================] - 1s 50ms/step - loss: 3.9369e-07 - acc: 1.0000 - val_loss: 0.8050 - val_acc: 0.8644\n","\n","Epoch 00089: val_acc did not improve from 0.89831\n","Epoch 90/100\n","16/16 [==============================] - 1s 50ms/step - loss: 9.4234e-06 - acc: 1.0000 - val_loss: 0.8050 - val_acc: 0.8644\n","\n","Epoch 00090: val_acc did not improve from 0.89831\n","Epoch 91/100\n","16/16 [==============================] - 1s 50ms/step - loss: 3.5531e-05 - acc: 1.0000 - val_loss: 0.8010 - val_acc: 0.8644\n","\n","Epoch 00091: val_acc did not improve from 0.89831\n","Epoch 92/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.6999e-06 - acc: 1.0000 - val_loss: 0.8036 - val_acc: 0.8644\n","\n","Epoch 00092: val_acc did not improve from 0.89831\n","Epoch 93/100\n","16/16 [==============================] - 1s 50ms/step - loss: 6.2532e-06 - acc: 1.0000 - val_loss: 0.8080 - val_acc: 0.8644\n","\n","Epoch 00093: val_acc did not improve from 0.89831\n","Epoch 94/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.3543e-04 - acc: 1.0000 - val_loss: 0.8179 - val_acc: 0.8644\n","\n","Epoch 00094: val_acc did not improve from 0.89831\n","Epoch 95/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.3124e-04 - acc: 1.0000 - val_loss: 0.8488 - val_acc: 0.8814\n","\n","Epoch 00095: val_acc did not improve from 0.89831\n","Epoch 96/100\n","16/16 [==============================] - 1s 50ms/step - loss: 7.2824e-06 - acc: 1.0000 - val_loss: 0.8987 - val_acc: 0.8814\n","\n","Epoch 00096: val_acc did not improve from 0.89831\n","Epoch 97/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.8114e-07 - acc: 1.0000 - val_loss: 0.9090 - val_acc: 0.8814\n","\n","Epoch 00097: val_acc did not improve from 0.89831\n","Epoch 98/100\n","16/16 [==============================] - 1s 50ms/step - loss: 5.1583e-06 - acc: 1.0000 - val_loss: 0.9101 - val_acc: 0.8814\n","\n","Epoch 00098: val_acc did not improve from 0.89831\n","Epoch 99/100\n","16/16 [==============================] - 1s 49ms/step - loss: 6.7236e-06 - acc: 1.0000 - val_loss: 0.9104 - val_acc: 0.8814\n","\n","Epoch 00099: val_acc did not improve from 0.89831\n","Epoch 100/100\n","16/16 [==============================] - 1s 50ms/step - loss: 4.2454e-05 - acc: 1.0000 - val_loss: 0.8932 - val_acc: 0.8814\n","\n","Epoch 00100: val_acc did not improve from 0.89831\n","\n","<keras.callbacks.History at 0x7f4c27f2a320>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"g8avIfF3Nk6T","colab_type":"code","colab":{}},"cell_type":"code","source":["# intersection 91.52\n","\n","\n","\n","Epoch 1/100\n","16/16 [==============================] - 1s 74ms/step - loss: 0.6789 - acc: 0.6194 - val_loss: 0.6762 - val_acc: 0.6949\n","\n","Epoch 00001: val_acc improved from -inf to 0.69492, saving model to result/intersection/OUR6-41/epoch-01-val-acc-0.6949.hdf5\n","Epoch 2/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.6311 - acc: 0.6526 - val_loss: 0.6216 - val_acc: 0.6271\n","\n","Epoch 00002: val_acc did not improve from 0.69492\n","Epoch 3/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.5489 - acc: 0.7301 - val_loss: 0.4733 - val_acc: 0.7797\n","\n","Epoch 00003: val_acc improved from 0.69492 to 0.77966, saving model to result/intersection/OUR6-41/epoch-03-val-acc-0.7797.hdf5\n","Epoch 4/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.3472 - acc: 0.8542 - val_loss: 0.4586 - val_acc: 0.7797\n","\n","Epoch 00004: val_acc did not improve from 0.77966\n","Epoch 5/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.2391 - acc: 0.9072 - val_loss: 0.4367 - val_acc: 0.8305\n","\n","Epoch 00005: val_acc improved from 0.77966 to 0.83051, saving model to result/intersection/OUR6-41/epoch-05-val-acc-0.8305.hdf5\n","Epoch 6/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.1460 - acc: 0.9439 - val_loss: 0.5183 - val_acc: 0.8644\n","\n","Epoch 00006: val_acc improved from 0.83051 to 0.86441, saving model to result/intersection/OUR6-41/epoch-06-val-acc-0.8644.hdf5\n","Epoch 7/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0823 - acc: 0.9654 - val_loss: 0.6000 - val_acc: 0.8644\n","\n","Epoch 00007: val_acc did not improve from 0.86441\n","Epoch 8/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0515 - acc: 0.9805 - val_loss: 0.7330 - val_acc: 0.8305\n","\n","Epoch 00008: val_acc did not improve from 0.86441\n","Epoch 9/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0244 - acc: 0.9912 - val_loss: 0.7974 - val_acc: 0.8475\n","\n","Epoch 00009: val_acc did not improve from 0.86441\n","Epoch 10/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0130 - acc: 0.9980 - val_loss: 0.8897 - val_acc: 0.8475\n","\n","Epoch 00010: val_acc did not improve from 0.86441\n","Epoch 11/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0242 - acc: 0.9921 - val_loss: 0.9046 - val_acc: 0.8475\n","\n","Epoch 00011: val_acc did not improve from 0.86441\n","Epoch 12/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0121 - acc: 0.9980 - val_loss: 0.9384 - val_acc: 0.8475\n","\n","Epoch 00012: val_acc did not improve from 0.86441\n","Epoch 13/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0182 - acc: 0.9966 - val_loss: 1.1783 - val_acc: 0.8475\n","\n","Epoch 00013: val_acc did not improve from 0.86441\n","Epoch 14/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0067 - acc: 0.9986 - val_loss: 1.3190 - val_acc: 0.8475\n","\n","Epoch 00014: val_acc did not improve from 0.86441\n","Epoch 15/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0442 - acc: 0.9882 - val_loss: 1.0439 - val_acc: 0.8475\n","\n","Epoch 00015: val_acc did not improve from 0.86441\n","Epoch 16/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0237 - acc: 0.9927 - val_loss: 1.0898 - val_acc: 0.8136\n","\n","Epoch 00016: val_acc did not improve from 0.86441\n","Epoch 17/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0086 - acc: 0.9971 - val_loss: 1.3626 - val_acc: 0.8305\n","\n","Epoch 00017: val_acc did not improve from 0.86441\n","Epoch 18/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0175 - acc: 0.9951 - val_loss: 1.1930 - val_acc: 0.8475\n","\n","Epoch 00018: val_acc did not improve from 0.86441\n","Epoch 19/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 1.1506 - val_acc: 0.8475\n","\n","Epoch 00019: val_acc did not improve from 0.86441\n","Epoch 20/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.4140 - val_acc: 0.8475\n","\n","Epoch 00020: val_acc did not improve from 0.86441\n","Epoch 21/100\n","16/16 [==============================] - 1s 50ms/step - loss: 5.1184e-04 - acc: 1.0000 - val_loss: 1.4467 - val_acc: 0.8475\n","\n","Epoch 00021: val_acc did not improve from 0.86441\n","Epoch 22/100\n","16/16 [==============================] - 1s 50ms/step - loss: 5.6341e-04 - acc: 1.0000 - val_loss: 1.4980 - val_acc: 0.8475\n","\n","Epoch 00022: val_acc did not improve from 0.86441\n","Epoch 23/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.6416e-04 - acc: 1.0000 - val_loss: 1.5259 - val_acc: 0.8475\n","\n","Epoch 00023: val_acc did not improve from 0.86441\n","Epoch 24/100\n","16/16 [==============================] - 1s 50ms/step - loss: 6.0165e-04 - acc: 1.0000 - val_loss: 1.5282 - val_acc: 0.8475\n","\n","Epoch 00024: val_acc did not improve from 0.86441\n","Epoch 25/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.7503e-04 - acc: 1.0000 - val_loss: 1.5266 - val_acc: 0.8475\n","\n","Epoch 00025: val_acc did not improve from 0.86441\n","Epoch 26/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.6965e-04 - acc: 1.0000 - val_loss: 1.5411 - val_acc: 0.8475\n","\n","Epoch 00026: val_acc did not improve from 0.86441\n","Epoch 27/100\n","16/16 [==============================] - 1s 50ms/step - loss: 6.1486e-04 - acc: 1.0000 - val_loss: 1.4108 - val_acc: 0.8475\n","\n","Epoch 00027: val_acc did not improve from 0.86441\n","Epoch 28/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.3792e-04 - acc: 1.0000 - val_loss: 1.4804 - val_acc: 0.8475\n","\n","Epoch 00028: val_acc did not improve from 0.86441\n","Epoch 29/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.3445e-04 - acc: 1.0000 - val_loss: 1.5133 - val_acc: 0.8475\n","\n","Epoch 00029: val_acc did not improve from 0.86441\n","Epoch 30/100\n","16/16 [==============================] - 1s 51ms/step - loss: 3.5591e-04 - acc: 1.0000 - val_loss: 1.5295 - val_acc: 0.8475\n","\n","Epoch 00030: val_acc did not improve from 0.86441\n","Epoch 31/100\n","16/16 [==============================] - 1s 49ms/step - loss: 2.3646e-04 - acc: 1.0000 - val_loss: 1.4967 - val_acc: 0.8475\n","\n","Epoch 00031: val_acc did not improve from 0.86441\n","Epoch 32/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.7322e-04 - acc: 1.0000 - val_loss: 1.5592 - val_acc: 0.8475\n","\n","Epoch 00032: val_acc did not improve from 0.86441\n","Epoch 33/100\n","16/16 [==============================] - 1s 50ms/step - loss: 3.5506e-04 - acc: 1.0000 - val_loss: 1.6984 - val_acc: 0.8475\n","\n","Epoch 00033: val_acc did not improve from 0.86441\n","Epoch 34/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.6254 - val_acc: 0.8475\n","\n","Epoch 00034: val_acc did not improve from 0.86441\n","Epoch 35/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0028 - acc: 0.9980 - val_loss: 1.4574 - val_acc: 0.8475\n","\n","Epoch 00035: val_acc did not improve from 0.86441\n","Epoch 36/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0135 - acc: 0.9961 - val_loss: 1.2922 - val_acc: 0.8475\n","\n","Epoch 00036: val_acc did not improve from 0.86441\n","Epoch 37/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0586 - acc: 0.9800 - val_loss: 1.7796 - val_acc: 0.7966\n","\n","Epoch 00037: val_acc did not improve from 0.86441\n","Epoch 38/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0919 - acc: 0.9776 - val_loss: 0.8282 - val_acc: 0.8136\n","\n","Epoch 00038: val_acc did not improve from 0.86441\n","Epoch 39/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0397 - acc: 0.9849 - val_loss: 0.8443 - val_acc: 0.8475\n","\n","Epoch 00039: val_acc did not improve from 0.86441\n","Epoch 40/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0257 - acc: 0.9903 - val_loss: 0.9273 - val_acc: 0.8814\n","\n","Epoch 00040: val_acc improved from 0.86441 to 0.88136, saving model to result/intersection/OUR6-41/epoch-40-val-acc-0.8814.hdf5\n","Epoch 41/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0105 - acc: 0.9976 - val_loss: 0.8686 - val_acc: 0.8983\n","\n","Epoch 00041: val_acc improved from 0.88136 to 0.89831, saving model to result/intersection/OUR6-41/epoch-41-val-acc-0.8983.hdf5\n","Epoch 42/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.7895 - val_acc: 0.8814\n","\n","Epoch 00042: val_acc did not improve from 0.89831\n","Epoch 43/100\n","16/16 [==============================] - 1s 50ms/step - loss: 8.2948e-04 - acc: 1.0000 - val_loss: 0.7477 - val_acc: 0.8814\n","\n","Epoch 00043: val_acc did not improve from 0.89831\n","Epoch 44/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0067 - acc: 0.9976 - val_loss: 0.8172 - val_acc: 0.8814\n","\n","Epoch 00044: val_acc did not improve from 0.89831\n","Epoch 45/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0014 - acc: 0.9990 - val_loss: 0.8562 - val_acc: 0.8814\n","\n","Epoch 00045: val_acc did not improve from 0.89831\n","Epoch 46/100\n","16/16 [==============================] - 1s 49ms/step - loss: 6.3828e-04 - acc: 1.0000 - val_loss: 0.8868 - val_acc: 0.8644\n","\n","Epoch 00046: val_acc did not improve from 0.89831\n","Epoch 47/100\n","16/16 [==============================] - 1s 50ms/step - loss: 3.3115e-04 - acc: 1.0000 - val_loss: 0.8869 - val_acc: 0.8644\n","\n","Epoch 00047: val_acc did not improve from 0.89831\n","Epoch 48/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0043 - acc: 0.9976 - val_loss: 0.7893 - val_acc: 0.8983\n","\n","Epoch 00048: val_acc did not improve from 0.89831\n","Epoch 49/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0075 - acc: 0.9971 - val_loss: 1.1207 - val_acc: 0.8475\n","\n","Epoch 00049: val_acc did not improve from 0.89831\n","Epoch 50/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0042 - acc: 0.9990 - val_loss: 1.2468 - val_acc: 0.8475\n","\n","Epoch 00050: val_acc did not improve from 0.89831\n","Epoch 51/100\n","16/16 [==============================] - 1s 50ms/step - loss: 6.6952e-04 - acc: 1.0000 - val_loss: 1.2531 - val_acc: 0.8644\n","\n","Epoch 00051: val_acc did not improve from 0.89831\n","Epoch 52/100\n","16/16 [==============================] - 1s 50ms/step - loss: 9.0240e-04 - acc: 1.0000 - val_loss: 1.0726 - val_acc: 0.8644\n","\n","Epoch 00052: val_acc did not improve from 0.89831\n","Epoch 53/100\n","16/16 [==============================] - 1s 50ms/step - loss: 7.8136e-04 - acc: 1.0000 - val_loss: 1.3248 - val_acc: 0.8475\n","\n","Epoch 00053: val_acc did not improve from 0.89831\n","Epoch 54/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.6978e-04 - acc: 1.0000 - val_loss: 1.3459 - val_acc: 0.8475\n","\n","Epoch 00054: val_acc did not improve from 0.89831\n","Epoch 55/100\n","16/16 [==============================] - 1s 50ms/step - loss: 7.4571e-05 - acc: 1.0000 - val_loss: 1.3343 - val_acc: 0.8475\n","\n","Epoch 00055: val_acc did not improve from 0.89831\n","Epoch 56/100\n","16/16 [==============================] - 1s 50ms/step - loss: 6.1859e-04 - acc: 1.0000 - val_loss: 1.1791 - val_acc: 0.8644\n","\n","Epoch 00056: val_acc did not improve from 0.89831\n","Epoch 57/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.0389e-04 - acc: 1.0000 - val_loss: 1.1756 - val_acc: 0.8644\n","\n","Epoch 00057: val_acc did not improve from 0.89831\n","Epoch 58/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.9155e-04 - acc: 1.0000 - val_loss: 1.2182 - val_acc: 0.8644\n","\n","Epoch 00058: val_acc did not improve from 0.89831\n","Epoch 59/100\n","16/16 [==============================] - 1s 50ms/step - loss: 5.4716e-04 - acc: 1.0000 - val_loss: 1.3561 - val_acc: 0.8644\n","\n","Epoch 00059: val_acc did not improve from 0.89831\n","Epoch 60/100\n","16/16 [==============================] - 1s 50ms/step - loss: 3.0412e-05 - acc: 1.0000 - val_loss: 1.5154 - val_acc: 0.8475\n","\n","Epoch 00060: val_acc did not improve from 0.89831\n","Epoch 61/100\n","16/16 [==============================] - 1s 50ms/step - loss: 6.9473e-05 - acc: 1.0000 - val_loss: 1.5384 - val_acc: 0.8475\n","\n","Epoch 00061: val_acc did not improve from 0.89831\n","Epoch 62/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.3870e-04 - acc: 1.0000 - val_loss: 1.5227 - val_acc: 0.8475\n","\n","Epoch 00062: val_acc did not improve from 0.89831\n","Epoch 63/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.0400e-05 - acc: 1.0000 - val_loss: 1.5224 - val_acc: 0.8475\n","\n","Epoch 00063: val_acc did not improve from 0.89831\n","Epoch 64/100\n","16/16 [==============================] - 1s 50ms/step - loss: 6.6735e-05 - acc: 1.0000 - val_loss: 1.5165 - val_acc: 0.8644\n","\n","Epoch 00064: val_acc did not improve from 0.89831\n","Epoch 65/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.4265e-05 - acc: 1.0000 - val_loss: 1.5040 - val_acc: 0.8644\n","\n","Epoch 00065: val_acc did not improve from 0.89831\n","Epoch 66/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0015 - acc: 0.9990 - val_loss: 1.5678 - val_acc: 0.8644\n","\n","Epoch 00066: val_acc did not improve from 0.89831\n","Epoch 67/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0106 - acc: 0.9956 - val_loss: 1.3933 - val_acc: 0.8814\n","\n","Epoch 00067: val_acc did not improve from 0.89831\n","Epoch 68/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.2307 - acc: 0.9580 - val_loss: 1.6924 - val_acc: 0.7966\n","\n","Epoch 00068: val_acc did not improve from 0.89831\n","Epoch 69/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0900 - acc: 0.9809 - val_loss: 0.7657 - val_acc: 0.8644\n","\n","Epoch 00069: val_acc did not improve from 0.89831\n","Epoch 70/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0458 - acc: 0.9791 - val_loss: 0.9910 - val_acc: 0.8475\n","\n","Epoch 00070: val_acc did not improve from 0.89831\n","Epoch 71/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0128 - acc: 0.9966 - val_loss: 1.2764 - val_acc: 0.8475\n","\n","Epoch 00071: val_acc did not improve from 0.89831\n","Epoch 72/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0154 - acc: 0.9952 - val_loss: 0.9894 - val_acc: 0.8644\n","\n","Epoch 00072: val_acc did not improve from 0.89831\n","Epoch 73/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0252 - acc: 0.9913 - val_loss: 1.2959 - val_acc: 0.8475\n","\n","Epoch 00073: val_acc did not improve from 0.89831\n","Epoch 74/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0063 - acc: 0.9951 - val_loss: 1.5665 - val_acc: 0.8475\n","\n","Epoch 00074: val_acc did not improve from 0.89831\n","Epoch 75/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0242 - acc: 0.9941 - val_loss: 0.8543 - val_acc: 0.9153\n","\n","Epoch 00075: val_acc improved from 0.89831 to 0.91525, saving model to result/intersection/OUR6-41/epoch-75-val-acc-0.9153.hdf5\n","Epoch 76/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0106 - acc: 0.9971 - val_loss: 0.9966 - val_acc: 0.8475\n","\n","Epoch 00076: val_acc did not improve from 0.91525\n","Epoch 77/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0177 - acc: 0.9980 - val_loss: 1.4199 - val_acc: 0.8136\n","\n","Epoch 00077: val_acc did not improve from 0.91525\n","Epoch 78/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0015 - acc: 0.9990 - val_loss: 1.2922 - val_acc: 0.8475\n","\n","Epoch 00078: val_acc did not improve from 0.91525\n","Epoch 79/100\n","16/16 [==============================] - 1s 50ms/step - loss: 9.3891e-04 - acc: 1.0000 - val_loss: 1.2639 - val_acc: 0.8475\n","\n","Epoch 00079: val_acc did not improve from 0.91525\n","Epoch 80/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.4774e-04 - acc: 1.0000 - val_loss: 1.4519 - val_acc: 0.8475\n","\n","Epoch 00080: val_acc did not improve from 0.91525\n","Epoch 81/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.0998e-04 - acc: 1.0000 - val_loss: 1.4738 - val_acc: 0.8475\n","\n","Epoch 00081: val_acc did not improve from 0.91525\n","Epoch 82/100\n","16/16 [==============================] - 1s 50ms/step - loss: 3.3564e-05 - acc: 1.0000 - val_loss: 1.4609 - val_acc: 0.8475\n","\n","Epoch 00082: val_acc did not improve from 0.91525\n","Epoch 83/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0021 - acc: 0.9990 - val_loss: 1.2920 - val_acc: 0.8475\n","\n","Epoch 00083: val_acc did not improve from 0.91525\n","Epoch 84/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0026 - acc: 0.9990 - val_loss: 1.2562 - val_acc: 0.8814\n","\n","Epoch 00084: val_acc did not improve from 0.91525\n","Epoch 85/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 1.0495 - val_acc: 0.8814\n","\n","Epoch 00085: val_acc did not improve from 0.91525\n","Epoch 86/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.2095 - val_acc: 0.8644\n","\n","Epoch 00086: val_acc did not improve from 0.91525\n","Epoch 87/100\n","16/16 [==============================] - 1s 50ms/step - loss: 6.1244e-05 - acc: 1.0000 - val_loss: 1.3092 - val_acc: 0.8644\n","\n","Epoch 00087: val_acc did not improve from 0.91525\n","Epoch 88/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0018 - acc: 0.9990 - val_loss: 1.2728 - val_acc: 0.8644\n","\n","Epoch 00088: val_acc did not improve from 0.91525\n","Epoch 89/100\n","16/16 [==============================] - 1s 50ms/step - loss: 3.6836e-04 - acc: 1.0000 - val_loss: 1.0308 - val_acc: 0.8814\n","\n","Epoch 00089: val_acc did not improve from 0.91525\n","Epoch 90/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.1887e-04 - acc: 1.0000 - val_loss: 1.0319 - val_acc: 0.8814\n","\n","Epoch 00090: val_acc did not improve from 0.91525\n","Epoch 91/100\n","16/16 [==============================] - 1s 51ms/step - loss: 6.7068e-04 - acc: 1.0000 - val_loss: 1.1731 - val_acc: 0.8475\n","\n","Epoch 00091: val_acc did not improve from 0.91525\n","Epoch 92/100\n","16/16 [==============================] - 1s 50ms/step - loss: 3.5323e-06 - acc: 1.0000 - val_loss: 1.3233 - val_acc: 0.8644\n","\n","Epoch 00092: val_acc did not improve from 0.91525\n","Epoch 93/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.6877e-05 - acc: 1.0000 - val_loss: 1.3409 - val_acc: 0.8644\n","\n","Epoch 00093: val_acc did not improve from 0.91525\n","Epoch 94/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.9726e-04 - acc: 1.0000 - val_loss: 1.2481 - val_acc: 0.8644\n","\n","Epoch 00094: val_acc did not improve from 0.91525\n","Epoch 95/100\n","16/16 [==============================] - 1s 51ms/step - loss: 2.7017e-04 - acc: 1.0000 - val_loss: 1.2079 - val_acc: 0.8475\n","\n","Epoch 00095: val_acc did not improve from 0.91525\n","Epoch 96/100\n","16/16 [==============================] - 1s 50ms/step - loss: 3.6975e-06 - acc: 1.0000 - val_loss: 1.2043 - val_acc: 0.8475\n","\n","Epoch 00096: val_acc did not improve from 0.91525\n","Epoch 97/100\n","16/16 [==============================] - 1s 50ms/step - loss: 6.3121e-06 - acc: 1.0000 - val_loss: 1.2068 - val_acc: 0.8475\n","\n","Epoch 00097: val_acc did not improve from 0.91525\n","Epoch 98/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.5293e-05 - acc: 1.0000 - val_loss: 1.2222 - val_acc: 0.8475\n","\n","Epoch 00098: val_acc did not improve from 0.91525\n","Epoch 99/100\n","16/16 [==============================] - 1s 50ms/step - loss: 3.2215e-06 - acc: 1.0000 - val_loss: 1.2448 - val_acc: 0.8475\n","\n","Epoch 00099: val_acc did not improve from 0.91525\n","Epoch 100/100\n","16/16 [==============================] - 1s 50ms/step - loss: 5.1455e-05 - acc: 1.0000 - val_loss: 1.2647 - val_acc: 0.8475\n","\n","Epoch 00100: val_acc did not improve from 0.91525\n","\n","<keras.callbacks.History at 0x7f4c298f1978>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"x7R-3p0uiQZ4","colab_type":"code","colab":{}},"cell_type":"code","source":["our 6 82.43\n","\n","\n","Epoch 1/100\n","16/16 [==============================] - 2s 108ms/step - loss: 1.3952 - acc: 0.2707 - val_loss: 1.3992 - val_acc: 0.2432\n","\n","Epoch 00001: val_acc improved from -inf to 0.24324, saving model to result/all/four/two/OUR6-2/epoch-01-val-acc-0.2432.hdf5\n","Epoch 2/100\n","16/16 [==============================] - 1s 65ms/step - loss: 1.3640 - acc: 0.3215 - val_loss: 1.3534 - val_acc: 0.4730\n","\n","Epoch 00002: val_acc improved from 0.24324 to 0.47297, saving model to result/all/four/two/OUR6-2/epoch-02-val-acc-0.4730.hdf5\n","Epoch 3/100\n","16/16 [==============================] - 1s 51ms/step - loss: 1.3057 - acc: 0.3808 - val_loss: 1.2823 - val_acc: 0.4189\n","\n","Epoch 00003: val_acc did not improve from 0.47297\n","Epoch 4/100\n","16/16 [==============================] - 1s 53ms/step - loss: 1.3185 - acc: 0.4119 - val_loss: 1.4282 - val_acc: 0.2432\n","\n","Epoch 00004: val_acc did not improve from 0.47297\n","Epoch 5/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.3050 - acc: 0.3857 - val_loss: 1.2630 - val_acc: 0.4459\n","\n","Epoch 00005: val_acc did not improve from 0.47297\n","Epoch 6/100\n","16/16 [==============================] - 1s 55ms/step - loss: 1.2266 - acc: 0.4351 - val_loss: 1.2212 - val_acc: 0.4730\n","\n","Epoch 00006: val_acc did not improve from 0.47297\n","Epoch 7/100\n","16/16 [==============================] - 1s 55ms/step - loss: 1.0390 - acc: 0.5840 - val_loss: 1.1211 - val_acc: 0.4730\n","\n","Epoch 00007: val_acc did not improve from 0.47297\n","Epoch 8/100\n","16/16 [==============================] - 1s 56ms/step - loss: 1.0393 - acc: 0.6039 - val_loss: 1.0637 - val_acc: 0.6081\n","\n","Epoch 00008: val_acc improved from 0.47297 to 0.60811, saving model to result/all/four/two/OUR6-2/epoch-08-val-acc-0.6081.hdf5\n","Epoch 9/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.8214 - acc: 0.6833 - val_loss: 0.8781 - val_acc: 0.6216\n","\n","Epoch 00009: val_acc improved from 0.60811 to 0.62162, saving model to result/all/four/two/OUR6-2/epoch-09-val-acc-0.6216.hdf5\n","Epoch 10/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.7477 - acc: 0.7019 - val_loss: 0.9311 - val_acc: 0.6486\n","\n","Epoch 00010: val_acc improved from 0.62162 to 0.64865, saving model to result/all/four/two/OUR6-2/epoch-10-val-acc-0.6486.hdf5\n","Epoch 11/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.7037 - acc: 0.7323 - val_loss: 0.9390 - val_acc: 0.6486\n","\n","Epoch 00011: val_acc did not improve from 0.64865\n","Epoch 12/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.6408 - acc: 0.7431 - val_loss: 0.8357 - val_acc: 0.6757\n","\n","Epoch 00012: val_acc improved from 0.64865 to 0.67568, saving model to result/all/four/two/OUR6-2/epoch-12-val-acc-0.6757.hdf5\n","Epoch 13/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.5532 - acc: 0.7893 - val_loss: 0.8116 - val_acc: 0.7297\n","\n","Epoch 00013: val_acc improved from 0.67568 to 0.72973, saving model to result/all/four/two/OUR6-2/epoch-13-val-acc-0.7297.hdf5\n","Epoch 14/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.4590 - acc: 0.8368 - val_loss: 0.8766 - val_acc: 0.6757\n","\n","Epoch 00014: val_acc did not improve from 0.72973\n","Epoch 15/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.3915 - acc: 0.8482 - val_loss: 0.7691 - val_acc: 0.7297\n","\n","Epoch 00015: val_acc did not improve from 0.72973\n","Epoch 16/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.3449 - acc: 0.8744 - val_loss: 0.8709 - val_acc: 0.7297\n","\n","Epoch 00016: val_acc improved from 0.72973 to 0.72973, saving model to result/all/four/two/OUR6-2/epoch-16-val-acc-0.7297.hdf5\n","Epoch 17/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.3247 - acc: 0.8730 - val_loss: 0.9963 - val_acc: 0.7027\n","\n","Epoch 00017: val_acc did not improve from 0.72973\n","Epoch 18/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.2662 - acc: 0.8997 - val_loss: 0.8936 - val_acc: 0.6757\n","\n","Epoch 00018: val_acc did not improve from 0.72973\n","Epoch 19/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.2683 - acc: 0.8932 - val_loss: 0.9299 - val_acc: 0.7568\n","\n","Epoch 00019: val_acc improved from 0.72973 to 0.75676, saving model to result/all/four/two/OUR6-2/epoch-19-val-acc-0.7568.hdf5\n","Epoch 20/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.2749 - acc: 0.8819 - val_loss: 0.9925 - val_acc: 0.7027\n","\n","Epoch 00020: val_acc did not improve from 0.75676\n","Epoch 21/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.2103 - acc: 0.9262 - val_loss: 0.9948 - val_acc: 0.7027\n","\n","Epoch 00021: val_acc did not improve from 0.75676\n","Epoch 22/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.2278 - acc: 0.9104 - val_loss: 1.0924 - val_acc: 0.6757\n","\n","Epoch 00022: val_acc did not improve from 0.75676\n","Epoch 23/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.1578 - acc: 0.9412 - val_loss: 1.1100 - val_acc: 0.6622\n","\n","Epoch 00023: val_acc did not improve from 0.75676\n","Epoch 24/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.1569 - acc: 0.9538 - val_loss: 1.0778 - val_acc: 0.7432\n","\n","Epoch 00024: val_acc did not improve from 0.75676\n","Epoch 25/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.1388 - acc: 0.9401 - val_loss: 1.5147 - val_acc: 0.6216\n","\n","Epoch 00025: val_acc did not improve from 0.75676\n","Epoch 26/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.1176 - acc: 0.9539 - val_loss: 1.3835 - val_acc: 0.7162\n","\n","Epoch 00026: val_acc did not improve from 0.75676\n","Epoch 27/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.1272 - acc: 0.9616 - val_loss: 1.3638 - val_acc: 0.7297\n","\n","Epoch 00027: val_acc did not improve from 0.75676\n","Epoch 28/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.1155 - acc: 0.9666 - val_loss: 1.1886 - val_acc: 0.7027\n","\n","Epoch 00028: val_acc did not improve from 0.75676\n","Epoch 29/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0771 - acc: 0.9734 - val_loss: 1.2139 - val_acc: 0.7297\n","\n","Epoch 00029: val_acc did not improve from 0.75676\n","Epoch 30/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0718 - acc: 0.9715 - val_loss: 1.2847 - val_acc: 0.7162\n","\n","Epoch 00030: val_acc did not improve from 0.75676\n","Epoch 31/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.0678 - acc: 0.9754 - val_loss: 1.4156 - val_acc: 0.7162\n","\n","Epoch 00031: val_acc did not improve from 0.75676\n","Epoch 32/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0635 - acc: 0.9824 - val_loss: 1.5098 - val_acc: 0.6892\n","\n","Epoch 00032: val_acc did not improve from 0.75676\n","Epoch 33/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0526 - acc: 0.9823 - val_loss: 1.5097 - val_acc: 0.7297\n","\n","Epoch 00033: val_acc did not improve from 0.75676\n","Epoch 34/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0374 - acc: 0.9892 - val_loss: 1.4905 - val_acc: 0.6892\n","\n","Epoch 00034: val_acc did not improve from 0.75676\n","Epoch 35/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0786 - acc: 0.9784 - val_loss: 2.1439 - val_acc: 0.6351\n","\n","Epoch 00035: val_acc did not improve from 0.75676\n","Epoch 36/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.1950 - acc: 0.9390 - val_loss: 1.4729 - val_acc: 0.7703\n","\n","Epoch 00036: val_acc improved from 0.75676 to 0.77027, saving model to result/all/four/two/OUR6-2/epoch-36-val-acc-0.7703.hdf5\n","Epoch 37/100\n","16/16 [==============================] - 1s 64ms/step - loss: 0.1444 - acc: 0.9498 - val_loss: 1.5019 - val_acc: 0.7297\n","\n","Epoch 00037: val_acc did not improve from 0.77027\n","Epoch 38/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0941 - acc: 0.9677 - val_loss: 1.5635 - val_acc: 0.7162\n","\n","Epoch 00038: val_acc did not improve from 0.77027\n","Epoch 39/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0938 - acc: 0.9647 - val_loss: 1.6044 - val_acc: 0.6892\n","\n","Epoch 00039: val_acc did not improve from 0.77027\n","Epoch 40/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0745 - acc: 0.9675 - val_loss: 1.3416 - val_acc: 0.7432\n","\n","Epoch 00040: val_acc did not improve from 0.77027\n","Epoch 41/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0499 - acc: 0.9862 - val_loss: 1.3567 - val_acc: 0.7568\n","\n","Epoch 00041: val_acc did not improve from 0.77027\n","Epoch 42/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0691 - acc: 0.9843 - val_loss: 1.5127 - val_acc: 0.7027\n","\n","Epoch 00042: val_acc did not improve from 0.77027\n","Epoch 43/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0370 - acc: 0.9873 - val_loss: 1.5888 - val_acc: 0.7297\n","\n","Epoch 00043: val_acc did not improve from 0.77027\n","Epoch 44/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0258 - acc: 0.9951 - val_loss: 1.5308 - val_acc: 0.7162\n","\n","Epoch 00044: val_acc did not improve from 0.77027\n","Epoch 45/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0456 - acc: 0.9843 - val_loss: 1.6127 - val_acc: 0.6622\n","\n","Epoch 00045: val_acc did not improve from 0.77027\n","Epoch 46/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0370 - acc: 0.9902 - val_loss: 1.5753 - val_acc: 0.6892\n","\n","Epoch 00046: val_acc did not improve from 0.77027\n","Epoch 47/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0300 - acc: 0.9882 - val_loss: 1.5600 - val_acc: 0.6757\n","\n","Epoch 00047: val_acc did not improve from 0.77027\n","Epoch 48/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0322 - acc: 0.9931 - val_loss: 1.7127 - val_acc: 0.7297\n","\n","Epoch 00048: val_acc did not improve from 0.77027\n","Epoch 49/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0384 - acc: 0.9843 - val_loss: 1.6502 - val_acc: 0.7027\n","\n","Epoch 00049: val_acc did not improve from 0.77027\n","Epoch 50/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0571 - acc: 0.9753 - val_loss: 1.9069 - val_acc: 0.6486\n","\n","Epoch 00050: val_acc did not improve from 0.77027\n","Epoch 51/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0661 - acc: 0.9784 - val_loss: 2.1453 - val_acc: 0.7162\n","\n","Epoch 00051: val_acc did not improve from 0.77027\n","Epoch 52/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0501 - acc: 0.9852 - val_loss: 1.9693 - val_acc: 0.6486\n","\n","Epoch 00052: val_acc did not improve from 0.77027\n","Epoch 53/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0465 - acc: 0.9853 - val_loss: 1.5582 - val_acc: 0.6892\n","\n","Epoch 00053: val_acc did not improve from 0.77027\n","Epoch 54/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0383 - acc: 0.9892 - val_loss: 1.6595 - val_acc: 0.7027\n","\n","Epoch 00054: val_acc did not improve from 0.77027\n","Epoch 55/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.1023 - acc: 0.9714 - val_loss: 1.6082 - val_acc: 0.6486\n","\n","Epoch 00055: val_acc did not improve from 0.77027\n","Epoch 56/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0436 - acc: 0.9853 - val_loss: 2.1291 - val_acc: 0.6486\n","\n","Epoch 00056: val_acc did not improve from 0.77027\n","Epoch 57/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0660 - acc: 0.9753 - val_loss: 1.9438 - val_acc: 0.6351\n","\n","Epoch 00057: val_acc did not improve from 0.77027\n","Epoch 58/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.1133 - acc: 0.9696 - val_loss: 1.8197 - val_acc: 0.6486\n","\n","Epoch 00058: val_acc did not improve from 0.77027\n","Epoch 59/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0544 - acc: 0.9833 - val_loss: 1.8201 - val_acc: 0.6486\n","\n","Epoch 00059: val_acc did not improve from 0.77027\n","Epoch 60/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0377 - acc: 0.9882 - val_loss: 1.8436 - val_acc: 0.6622\n","\n","Epoch 00060: val_acc did not improve from 0.77027\n","Epoch 61/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0285 - acc: 0.9921 - val_loss: 1.8238 - val_acc: 0.6351\n","\n","Epoch 00061: val_acc did not improve from 0.77027\n","Epoch 62/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0388 - acc: 0.9852 - val_loss: 2.2143 - val_acc: 0.6486\n","\n","Epoch 00062: val_acc did not improve from 0.77027\n","Epoch 63/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0301 - acc: 0.9872 - val_loss: 1.7589 - val_acc: 0.6622\n","\n","Epoch 00063: val_acc did not improve from 0.77027\n","Epoch 64/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0553 - acc: 0.9823 - val_loss: 1.9596 - val_acc: 0.7027\n","\n","Epoch 00064: val_acc did not improve from 0.77027\n","Epoch 65/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0333 - acc: 0.9862 - val_loss: 1.8422 - val_acc: 0.6892\n","\n","Epoch 00065: val_acc did not improve from 0.77027\n","Epoch 66/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0217 - acc: 0.9941 - val_loss: 2.1650 - val_acc: 0.6486\n","\n","Epoch 00066: val_acc did not improve from 0.77027\n","Epoch 67/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0448 - acc: 0.9911 - val_loss: 2.0598 - val_acc: 0.6351\n","\n","Epoch 00067: val_acc did not improve from 0.77027\n","Epoch 68/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.1304 - acc: 0.9656 - val_loss: 2.7177 - val_acc: 0.6216\n","\n","Epoch 00068: val_acc did not improve from 0.77027\n","Epoch 69/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.1227 - acc: 0.9618 - val_loss: 2.3810 - val_acc: 0.6892\n","\n","Epoch 00069: val_acc did not improve from 0.77027\n","Epoch 70/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.1096 - acc: 0.9617 - val_loss: 2.2228 - val_acc: 0.6622\n","\n","Epoch 00070: val_acc did not improve from 0.77027\n","Epoch 71/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0668 - acc: 0.9764 - val_loss: 1.9278 - val_acc: 0.6757\n","\n","Epoch 00071: val_acc did not improve from 0.77027\n","Epoch 72/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0583 - acc: 0.9843 - val_loss: 2.0380 - val_acc: 0.7297\n","\n","Epoch 00072: val_acc did not improve from 0.77027\n","Epoch 73/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0365 - acc: 0.9882 - val_loss: 2.0858 - val_acc: 0.6757\n","\n","Epoch 00073: val_acc did not improve from 0.77027\n","Epoch 74/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0537 - acc: 0.9804 - val_loss: 2.0798 - val_acc: 0.7162\n","\n","Epoch 00074: val_acc did not improve from 0.77027\n","Epoch 75/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0451 - acc: 0.9823 - val_loss: 1.9481 - val_acc: 0.6622\n","\n","Epoch 00075: val_acc did not improve from 0.77027\n","Epoch 76/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0121 - acc: 0.9971 - val_loss: 2.1706 - val_acc: 0.6892\n","\n","Epoch 00076: val_acc did not improve from 0.77027\n","Epoch 77/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0239 - acc: 0.9901 - val_loss: 2.3986 - val_acc: 0.6081\n","\n","Epoch 00077: val_acc did not improve from 0.77027\n","Epoch 78/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.1219 - acc: 0.9596 - val_loss: 2.3215 - val_acc: 0.6486\n","\n","Epoch 00078: val_acc did not improve from 0.77027\n","Epoch 79/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.2310 - acc: 0.9481 - val_loss: 1.9006 - val_acc: 0.6892\n","\n","Epoch 00079: val_acc did not improve from 0.77027\n","Epoch 80/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.1256 - acc: 0.9607 - val_loss: 2.2450 - val_acc: 0.6486\n","\n","Epoch 00080: val_acc did not improve from 0.77027\n","Epoch 81/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0531 - acc: 0.9813 - val_loss: 2.0826 - val_acc: 0.6486\n","\n","Epoch 00081: val_acc did not improve from 0.77027\n","Epoch 82/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0383 - acc: 0.9833 - val_loss: 2.4297 - val_acc: 0.6216\n","\n","Epoch 00082: val_acc did not improve from 0.77027\n","Epoch 83/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0305 - acc: 0.9843 - val_loss: 2.1611 - val_acc: 0.6486\n","\n","Epoch 00083: val_acc did not improve from 0.77027\n","Epoch 84/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0355 - acc: 0.9902 - val_loss: 1.9958 - val_acc: 0.6486\n","\n","Epoch 00084: val_acc did not improve from 0.77027\n","Epoch 85/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0151 - acc: 0.9931 - val_loss: 1.9852 - val_acc: 0.6622\n","\n","Epoch 00085: val_acc did not improve from 0.77027\n","Epoch 86/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0123 - acc: 0.9971 - val_loss: 2.2037 - val_acc: 0.6622\n","\n","Epoch 00086: val_acc did not improve from 0.77027\n","Epoch 87/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0105 - acc: 0.9971 - val_loss: 2.1776 - val_acc: 0.6892\n","\n","Epoch 00087: val_acc did not improve from 0.77027\n","Epoch 88/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0162 - acc: 0.9941 - val_loss: 2.1248 - val_acc: 0.7027\n","\n","Epoch 00088: val_acc did not improve from 0.77027\n","Epoch 89/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0077 - acc: 0.9971 - val_loss: 2.0898 - val_acc: 0.7027\n","\n","Epoch 00089: val_acc did not improve from 0.77027\n","Epoch 90/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0083 - acc: 0.9980 - val_loss: 2.0998 - val_acc: 0.6892\n","\n","Epoch 00090: val_acc did not improve from 0.77027\n","Epoch 91/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0169 - acc: 0.9951 - val_loss: 2.0933 - val_acc: 0.6892\n","\n","Epoch 00091: val_acc did not improve from 0.77027\n","Epoch 92/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0094 - acc: 0.9980 - val_loss: 1.8560 - val_acc: 0.6892\n","\n","Epoch 00092: val_acc did not improve from 0.77027\n","Epoch 93/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0057 - acc: 0.9980 - val_loss: 1.8528 - val_acc: 0.6622\n","\n","Epoch 00093: val_acc did not improve from 0.77027\n","Epoch 94/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0451 - acc: 0.9892 - val_loss: 1.8367 - val_acc: 0.6486\n","\n","Epoch 00094: val_acc did not improve from 0.77027\n","Epoch 95/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0411 - acc: 0.9862 - val_loss: 2.0219 - val_acc: 0.6757\n","\n","Epoch 00095: val_acc did not improve from 0.77027\n","Epoch 96/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0613 - acc: 0.9814 - val_loss: 2.3906 - val_acc: 0.6216\n","\n","Epoch 00096: val_acc did not improve from 0.77027\n","Epoch 97/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0390 - acc: 0.9882 - val_loss: 1.8687 - val_acc: 0.6757\n","\n","Epoch 00097: val_acc did not improve from 0.77027\n","Epoch 98/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0976 - acc: 0.9833 - val_loss: 2.1106 - val_acc: 0.6622\n","\n","Epoch 00098: val_acc did not improve from 0.77027\n","Epoch 99/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0200 - acc: 0.9931 - val_loss: 2.0695 - val_acc: 0.7027\n","\n","Epoch 00099: val_acc did not improve from 0.77027\n","Epoch 100/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0230 - acc: 0.9931 - val_loss: 1.9401 - val_acc: 0.7027\n","\n","Epoch 00100: val_acc did not improve from 0.77027\n","\n","<keras.callbacks.History at 0x7fd780829a20>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DSu8xayWhY4h","colab_type":"code","colab":{}},"cell_type":"code","source":["our 1-6\n","\n","\n","\n","Epoch 1/100\n","16/16 [==============================] - 2s 130ms/step - loss: 1.3744 - acc: 0.2960 - val_loss: 1.4071 - val_acc: 0.1892\n","\n","Epoch 00001: val_acc improved from -inf to 0.18919, saving model to result/all/four/two/OUR6-8/epoch-01-val-acc-0.1892.hdf5\n","Epoch 2/100\n","16/16 [==============================] - 1s 64ms/step - loss: 1.3648 - acc: 0.3231 - val_loss: 1.3412 - val_acc: 0.2027\n","\n","Epoch 00002: val_acc improved from 0.18919 to 0.20270, saving model to result/all/four/two/OUR6-8/epoch-02-val-acc-0.2027.hdf5\n","Epoch 3/100\n","16/16 [==============================] - 1s 56ms/step - loss: 1.3329 - acc: 0.3531 - val_loss: 1.3412 - val_acc: 0.4189\n","\n","Epoch 00003: val_acc improved from 0.20270 to 0.41892, saving model to result/all/four/two/OUR6-8/epoch-03-val-acc-0.4189.hdf5\n","Epoch 4/100\n","16/16 [==============================] - 1s 56ms/step - loss: 1.2825 - acc: 0.4225 - val_loss: 1.2007 - val_acc: 0.4730\n","\n","Epoch 00004: val_acc improved from 0.41892 to 0.47297, saving model to result/all/four/two/OUR6-8/epoch-04-val-acc-0.4730.hdf5\n","Epoch 5/100\n","16/16 [==============================] - 1s 54ms/step - loss: 1.1853 - acc: 0.4844 - val_loss: 1.1062 - val_acc: 0.5541\n","\n","Epoch 00005: val_acc improved from 0.47297 to 0.55405, saving model to result/all/four/two/OUR6-8/epoch-05-val-acc-0.5541.hdf5\n","Epoch 6/100\n","16/16 [==============================] - 1s 54ms/step - loss: 1.1419 - acc: 0.5226 - val_loss: 1.1495 - val_acc: 0.5135\n","\n","Epoch 00006: val_acc did not improve from 0.55405\n","Epoch 7/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.9281 - acc: 0.6038 - val_loss: 1.2545 - val_acc: 0.5000\n","\n","Epoch 00007: val_acc did not improve from 0.55405\n","Epoch 8/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.9288 - acc: 0.6417 - val_loss: 0.8675 - val_acc: 0.6486\n","\n","Epoch 00008: val_acc improved from 0.55405 to 0.64865, saving model to result/all/four/two/OUR6-8/epoch-08-val-acc-0.6486.hdf5\n","Epoch 9/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.7536 - acc: 0.7148 - val_loss: 0.9214 - val_acc: 0.6351\n","\n","Epoch 00009: val_acc did not improve from 0.64865\n","Epoch 10/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.7139 - acc: 0.7265 - val_loss: 0.8488 - val_acc: 0.7027\n","\n","Epoch 00010: val_acc improved from 0.64865 to 0.70270, saving model to result/all/four/two/OUR6-8/epoch-10-val-acc-0.7027.hdf5\n","Epoch 11/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.6842 - acc: 0.7334 - val_loss: 0.8360 - val_acc: 0.7027\n","\n","Epoch 00011: val_acc improved from 0.70270 to 0.70270, saving model to result/all/four/two/OUR6-8/epoch-11-val-acc-0.7027.hdf5\n","Epoch 12/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.5060 - acc: 0.8190 - val_loss: 0.8751 - val_acc: 0.6622\n","\n","Epoch 00012: val_acc did not improve from 0.70270\n","Epoch 13/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.4992 - acc: 0.8081 - val_loss: 0.7930 - val_acc: 0.7162\n","\n","Epoch 00013: val_acc improved from 0.70270 to 0.71622, saving model to result/all/four/two/OUR6-8/epoch-13-val-acc-0.7162.hdf5\n","Epoch 14/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.4577 - acc: 0.8068 - val_loss: 0.8826 - val_acc: 0.7297\n","\n","Epoch 00014: val_acc improved from 0.71622 to 0.72973, saving model to result/all/four/two/OUR6-8/epoch-14-val-acc-0.7297.hdf5\n","Epoch 15/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.3326 - acc: 0.8721 - val_loss: 0.7827 - val_acc: 0.7568\n","\n","Epoch 00015: val_acc improved from 0.72973 to 0.75676, saving model to result/all/four/two/OUR6-8/epoch-15-val-acc-0.7568.hdf5\n","Epoch 16/100\n","16/16 [==============================] - 1s 62ms/step - loss: 0.3035 - acc: 0.8844 - val_loss: 0.9380 - val_acc: 0.7297\n","\n","Epoch 00016: val_acc did not improve from 0.75676\n","Epoch 17/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.2393 - acc: 0.9125 - val_loss: 0.7761 - val_acc: 0.7838\n","\n","Epoch 00017: val_acc improved from 0.75676 to 0.78378, saving model to result/all/four/two/OUR6-8/epoch-17-val-acc-0.7838.hdf5\n","Epoch 18/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.1739 - acc: 0.9351 - val_loss: 0.9719 - val_acc: 0.7432\n","\n","Epoch 00018: val_acc did not improve from 0.78378\n","Epoch 19/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.1176 - acc: 0.9618 - val_loss: 0.9345 - val_acc: 0.7703\n","\n","Epoch 00019: val_acc did not improve from 0.78378\n","Epoch 20/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.1202 - acc: 0.9488 - val_loss: 0.9927 - val_acc: 0.7568\n","\n","Epoch 00020: val_acc did not improve from 0.78378\n","Epoch 21/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.2014 - acc: 0.9242 - val_loss: 0.8773 - val_acc: 0.7703\n","\n","Epoch 00021: val_acc did not improve from 0.78378\n","Epoch 22/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.1569 - acc: 0.9392 - val_loss: 0.9194 - val_acc: 0.7027\n","\n","Epoch 00022: val_acc did not improve from 0.78378\n","Epoch 23/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.2169 - acc: 0.9153 - val_loss: 1.1668 - val_acc: 0.7432\n","\n","Epoch 00023: val_acc did not improve from 0.78378\n","Epoch 24/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.2243 - acc: 0.9243 - val_loss: 1.1984 - val_acc: 0.7432\n","\n","Epoch 00024: val_acc did not improve from 0.78378\n","Epoch 25/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.1281 - acc: 0.9549 - val_loss: 1.0368 - val_acc: 0.7568\n","\n","Epoch 00025: val_acc did not improve from 0.78378\n","Epoch 26/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0760 - acc: 0.9843 - val_loss: 0.9819 - val_acc: 0.8108\n","\n","Epoch 00026: val_acc improved from 0.78378 to 0.81081, saving model to result/all/four/two/OUR6-8/epoch-26-val-acc-0.8108.hdf5\n","Epoch 27/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0759 - acc: 0.9744 - val_loss: 1.0781 - val_acc: 0.7838\n","\n","Epoch 00027: val_acc did not improve from 0.81081\n","Epoch 28/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0454 - acc: 0.9882 - val_loss: 1.0337 - val_acc: 0.7838\n","\n","Epoch 00028: val_acc did not improve from 0.81081\n","Epoch 29/100\n","16/16 [==============================] - 1s 59ms/step - loss: 0.0435 - acc: 0.9833 - val_loss: 1.1318 - val_acc: 0.7973\n","\n","Epoch 00029: val_acc did not improve from 0.81081\n","Epoch 30/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0587 - acc: 0.9823 - val_loss: 1.1998 - val_acc: 0.7703\n","\n","Epoch 00030: val_acc did not improve from 0.81081\n","Epoch 31/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0722 - acc: 0.9823 - val_loss: 1.0584 - val_acc: 0.7568\n","\n","Epoch 00031: val_acc did not improve from 0.81081\n","Epoch 32/100\n","16/16 [==============================] - 1s 61ms/step - loss: 0.0578 - acc: 0.9793 - val_loss: 1.1763 - val_acc: 0.7297\n","\n","Epoch 00032: val_acc did not improve from 0.81081\n","Epoch 33/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0860 - acc: 0.9687 - val_loss: 0.9833 - val_acc: 0.8243\n","\n","Epoch 00033: val_acc improved from 0.81081 to 0.82432, saving model to result/all/four/two/OUR6-8/epoch-33-val-acc-0.8243.hdf5\n","Epoch 34/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0825 - acc: 0.9745 - val_loss: 1.2047 - val_acc: 0.7568\n","\n","Epoch 00034: val_acc did not improve from 0.82432\n","Epoch 35/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0485 - acc: 0.9843 - val_loss: 1.2996 - val_acc: 0.7703\n","\n","Epoch 00035: val_acc did not improve from 0.82432\n","Epoch 36/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0360 - acc: 0.9892 - val_loss: 1.2687 - val_acc: 0.7568\n","\n","Epoch 00036: val_acc did not improve from 0.82432\n","Epoch 37/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0488 - acc: 0.9853 - val_loss: 1.3743 - val_acc: 0.7568\n","\n","Epoch 00037: val_acc did not improve from 0.82432\n","Epoch 38/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0330 - acc: 0.9872 - val_loss: 1.2425 - val_acc: 0.7703\n","\n","Epoch 00038: val_acc did not improve from 0.82432\n","Epoch 39/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0320 - acc: 0.9892 - val_loss: 1.2775 - val_acc: 0.7432\n","\n","Epoch 00039: val_acc did not improve from 0.82432\n","Epoch 40/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0208 - acc: 0.9941 - val_loss: 1.1982 - val_acc: 0.7432\n","\n","Epoch 00040: val_acc did not improve from 0.82432\n","Epoch 41/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0464 - acc: 0.9852 - val_loss: 1.5517 - val_acc: 0.7432\n","\n","Epoch 00041: val_acc did not improve from 0.82432\n","Epoch 42/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0573 - acc: 0.9775 - val_loss: 1.2588 - val_acc: 0.7838\n","\n","Epoch 00042: val_acc did not improve from 0.82432\n","Epoch 43/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.1338 - acc: 0.9557 - val_loss: 1.7119 - val_acc: 0.7162\n","\n","Epoch 00043: val_acc did not improve from 0.82432\n","Epoch 44/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.1078 - acc: 0.9596 - val_loss: 1.2078 - val_acc: 0.7568\n","\n","Epoch 00044: val_acc did not improve from 0.82432\n","Epoch 45/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.1170 - acc: 0.9677 - val_loss: 1.2828 - val_acc: 0.7703\n","\n","Epoch 00045: val_acc did not improve from 0.82432\n","Epoch 46/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0671 - acc: 0.9744 - val_loss: 1.5561 - val_acc: 0.7568\n","\n","Epoch 00046: val_acc did not improve from 0.82432\n","Epoch 47/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0459 - acc: 0.9833 - val_loss: 1.4775 - val_acc: 0.8108\n","\n","Epoch 00047: val_acc did not improve from 0.82432\n","Epoch 48/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0320 - acc: 0.9902 - val_loss: 1.2793 - val_acc: 0.7838\n","\n","Epoch 00048: val_acc did not improve from 0.82432\n","Epoch 49/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0361 - acc: 0.9862 - val_loss: 1.6189 - val_acc: 0.7568\n","\n","Epoch 00049: val_acc did not improve from 0.82432\n","Epoch 50/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0320 - acc: 0.9892 - val_loss: 1.3406 - val_acc: 0.7703\n","\n","Epoch 00050: val_acc did not improve from 0.82432\n","Epoch 51/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0217 - acc: 0.9901 - val_loss: 1.6238 - val_acc: 0.7703\n","\n","Epoch 00051: val_acc did not improve from 0.82432\n","Epoch 52/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.1177 - acc: 0.9647 - val_loss: 1.8871 - val_acc: 0.6757\n","\n","Epoch 00052: val_acc did not improve from 0.82432\n","Epoch 53/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.1017 - acc: 0.9647 - val_loss: 1.6352 - val_acc: 0.7432\n","\n","Epoch 00053: val_acc did not improve from 0.82432\n","Epoch 54/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0938 - acc: 0.9715 - val_loss: 1.6207 - val_acc: 0.7432\n","\n","Epoch 00054: val_acc did not improve from 0.82432\n","Epoch 55/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0713 - acc: 0.9803 - val_loss: 1.5859 - val_acc: 0.7297\n","\n","Epoch 00055: val_acc did not improve from 0.82432\n","Epoch 56/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0413 - acc: 0.9843 - val_loss: 1.6177 - val_acc: 0.7297\n","\n","Epoch 00056: val_acc did not improve from 0.82432\n","Epoch 57/100\n","16/16 [==============================] - 1s 61ms/step - loss: 0.0535 - acc: 0.9783 - val_loss: 1.7711 - val_acc: 0.6892\n","\n","Epoch 00057: val_acc did not improve from 0.82432\n","Epoch 58/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0550 - acc: 0.9853 - val_loss: 1.3580 - val_acc: 0.7568\n","\n","Epoch 00058: val_acc did not improve from 0.82432\n","Epoch 59/100\n","16/16 [==============================] - 1s 59ms/step - loss: 0.0257 - acc: 0.9912 - val_loss: 1.2771 - val_acc: 0.7432\n","\n","Epoch 00059: val_acc did not improve from 0.82432\n","Epoch 60/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0105 - acc: 0.9961 - val_loss: 1.5826 - val_acc: 0.7703\n","\n","Epoch 00060: val_acc did not improve from 0.82432\n","Epoch 61/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0153 - acc: 0.9961 - val_loss: 1.2921 - val_acc: 0.7838\n","\n","Epoch 00061: val_acc did not improve from 0.82432\n","Epoch 62/100\n","16/16 [==============================] - 1s 61ms/step - loss: 0.0175 - acc: 0.9961 - val_loss: 1.2003 - val_acc: 0.7297\n","\n","Epoch 00062: val_acc did not improve from 0.82432\n","Epoch 63/100\n","16/16 [==============================] - 1s 60ms/step - loss: 0.0200 - acc: 0.9971 - val_loss: 1.3736 - val_acc: 0.7432\n","\n","Epoch 00063: val_acc did not improve from 0.82432\n","Epoch 64/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0108 - acc: 0.9961 - val_loss: 1.4074 - val_acc: 0.7838\n","\n","Epoch 00064: val_acc did not improve from 0.82432\n","Epoch 65/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0164 - acc: 0.9951 - val_loss: 1.3992 - val_acc: 0.7703\n","\n","Epoch 00065: val_acc did not improve from 0.82432\n","Epoch 66/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0083 - acc: 0.9980 - val_loss: 1.3944 - val_acc: 0.7973\n","\n","Epoch 00066: val_acc did not improve from 0.82432\n","Epoch 67/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0104 - acc: 0.9971 - val_loss: 1.5332 - val_acc: 0.7432\n","\n","Epoch 00067: val_acc did not improve from 0.82432\n","Epoch 68/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0082 - acc: 0.9990 - val_loss: 1.6945 - val_acc: 0.7297\n","\n","Epoch 00068: val_acc did not improve from 0.82432\n","Epoch 69/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0056 - acc: 0.9980 - val_loss: 1.6918 - val_acc: 0.7568\n","\n","Epoch 00069: val_acc did not improve from 0.82432\n","Epoch 70/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0081 - acc: 0.9980 - val_loss: 1.7489 - val_acc: 0.7432\n","\n","Epoch 00070: val_acc did not improve from 0.82432\n","Epoch 71/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0221 - acc: 0.9931 - val_loss: 1.7664 - val_acc: 0.7568\n","\n","Epoch 00071: val_acc did not improve from 0.82432\n","Epoch 72/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0248 - acc: 0.9921 - val_loss: 1.6916 - val_acc: 0.7838\n","\n","Epoch 00072: val_acc did not improve from 0.82432\n","Epoch 73/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0193 - acc: 0.9941 - val_loss: 1.6096 - val_acc: 0.7568\n","\n","Epoch 00073: val_acc did not improve from 0.82432\n","Epoch 74/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0202 - acc: 0.9941 - val_loss: 1.6159 - val_acc: 0.7568\n","\n","Epoch 00074: val_acc did not improve from 0.82432\n","Epoch 75/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0144 - acc: 0.9951 - val_loss: 1.7998 - val_acc: 0.7027\n","\n","Epoch 00075: val_acc did not improve from 0.82432\n","Epoch 76/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0147 - acc: 0.9951 - val_loss: 2.1437 - val_acc: 0.7027\n","\n","Epoch 00076: val_acc did not improve from 0.82432\n","Epoch 77/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0139 - acc: 0.9941 - val_loss: 1.8864 - val_acc: 0.7432\n","\n","Epoch 00077: val_acc did not improve from 0.82432\n","Epoch 78/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0206 - acc: 0.9901 - val_loss: 1.5715 - val_acc: 0.7568\n","\n","Epoch 00078: val_acc did not improve from 0.82432\n","Epoch 79/100\n","16/16 [==============================] - 1s 59ms/step - loss: 0.0379 - acc: 0.9882 - val_loss: 1.8673 - val_acc: 0.6892\n","\n","Epoch 00079: val_acc did not improve from 0.82432\n","Epoch 80/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0898 - acc: 0.9685 - val_loss: 2.0744 - val_acc: 0.6892\n","\n","Epoch 00080: val_acc did not improve from 0.82432\n","Epoch 81/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.1432 - acc: 0.9655 - val_loss: 1.4910 - val_acc: 0.7162\n","\n","Epoch 00081: val_acc did not improve from 0.82432\n","Epoch 82/100\n","16/16 [==============================] - 1s 63ms/step - loss: 0.1066 - acc: 0.9608 - val_loss: 1.5040 - val_acc: 0.7568\n","\n","Epoch 00082: val_acc did not improve from 0.82432\n","Epoch 83/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0509 - acc: 0.9833 - val_loss: 1.3129 - val_acc: 0.7703\n","\n","Epoch 00083: val_acc did not improve from 0.82432\n","Epoch 84/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0459 - acc: 0.9863 - val_loss: 1.2423 - val_acc: 0.7703\n","\n","Epoch 00084: val_acc did not improve from 0.82432\n","Epoch 85/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0254 - acc: 0.9931 - val_loss: 1.0891 - val_acc: 0.7838\n","\n","Epoch 00085: val_acc did not improve from 0.82432\n","Epoch 86/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0116 - acc: 0.9961 - val_loss: 1.2529 - val_acc: 0.7838\n","\n","Epoch 00086: val_acc did not improve from 0.82432\n","Epoch 87/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0145 - acc: 0.9941 - val_loss: 1.2611 - val_acc: 0.7703\n","\n","Epoch 00087: val_acc did not improve from 0.82432\n","Epoch 88/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0123 - acc: 0.9951 - val_loss: 1.4471 - val_acc: 0.7432\n","\n","Epoch 00088: val_acc did not improve from 0.82432\n","Epoch 89/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0109 - acc: 0.9980 - val_loss: 1.6233 - val_acc: 0.7703\n","\n","Epoch 00089: val_acc did not improve from 0.82432\n","Epoch 90/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0431 - acc: 0.9852 - val_loss: 1.7558 - val_acc: 0.7703\n","\n","Epoch 00090: val_acc did not improve from 0.82432\n","Epoch 91/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0173 - acc: 0.9941 - val_loss: 1.2677 - val_acc: 0.7973\n","\n","Epoch 00091: val_acc did not improve from 0.82432\n","Epoch 92/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0182 - acc: 0.9931 - val_loss: 1.3828 - val_acc: 0.7703\n","\n","Epoch 00092: val_acc did not improve from 0.82432\n","Epoch 93/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0392 - acc: 0.9872 - val_loss: 1.7048 - val_acc: 0.7432\n","\n","Epoch 00093: val_acc did not improve from 0.82432\n","Epoch 94/100\n","16/16 [==============================] - 1s 62ms/step - loss: 0.0221 - acc: 0.9912 - val_loss: 1.8505 - val_acc: 0.7027\n","\n","Epoch 00094: val_acc did not improve from 0.82432\n","Epoch 95/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0297 - acc: 0.9892 - val_loss: 1.6541 - val_acc: 0.7568\n","\n","Epoch 00095: val_acc did not improve from 0.82432\n","Epoch 96/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0210 - acc: 0.9941 - val_loss: 1.2176 - val_acc: 0.8108\n","\n","Epoch 00096: val_acc did not improve from 0.82432\n","Epoch 97/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0228 - acc: 0.9901 - val_loss: 1.7050 - val_acc: 0.7432\n","\n","Epoch 00097: val_acc did not improve from 0.82432\n","Epoch 98/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0485 - acc: 0.9833 - val_loss: 2.5811 - val_acc: 0.6757\n","\n","Epoch 00098: val_acc did not improve from 0.82432\n","Epoch 99/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.1298 - acc: 0.9606 - val_loss: 2.2427 - val_acc: 0.7297\n","\n","Epoch 00099: val_acc did not improve from 0.82432\n","Epoch 100/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.2107 - acc: 0.9363 - val_loss: 2.0278 - val_acc: 0.6757\n","\n","Epoch 00100: val_acc did not improve from 0.82432\n","\n","<keras.callbacks.History at 0x7fd77dea9ba8>\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"caEieoa_UT9j","colab_type":"code","colab":{}},"cell_type":"code","source":["#our 6 our6-9 80.95 all four best\n","\n","\n","\n","Epoch 1/100\n","16/16 [==============================] - 2s 122ms/step - loss: 1.3783 - acc: 0.3279 - val_loss: 1.3638 - val_acc: 0.2721\n","\n","Epoch 00001: val_acc improved from -inf to 0.27211, saving model to result/all/four/OUR6-9/epoch-01-val-acc-0.2721.hdf5\n","Epoch 2/100\n","16/16 [==============================] - 1s 67ms/step - loss: 1.3519 - acc: 0.3532 - val_loss: 1.3418 - val_acc: 0.3469\n","\n","Epoch 00002: val_acc improved from 0.27211 to 0.34694, saving model to result/all/four/OUR6-9/epoch-02-val-acc-0.3469.hdf5\n","Epoch 3/100\n","16/16 [==============================] - 1s 53ms/step - loss: 1.3196 - acc: 0.3485 - val_loss: 1.2922 - val_acc: 0.3946\n","\n","Epoch 00003: val_acc improved from 0.34694 to 0.39456, saving model to result/all/four/OUR6-9/epoch-03-val-acc-0.3946.hdf5\n","Epoch 4/100\n","16/16 [==============================] - 1s 53ms/step - loss: 1.3902 - acc: 0.3246 - val_loss: 1.3699 - val_acc: 0.2449\n","\n","Epoch 00004: val_acc did not improve from 0.39456\n","Epoch 5/100\n","16/16 [==============================] - 1s 49ms/step - loss: 1.3227 - acc: 0.3718 - val_loss: 1.3104 - val_acc: 0.3401\n","\n","Epoch 00005: val_acc did not improve from 0.39456\n","Epoch 6/100\n","16/16 [==============================] - 1s 52ms/step - loss: 1.1635 - acc: 0.5214 - val_loss: 1.1401 - val_acc: 0.5578\n","\n","Epoch 00006: val_acc improved from 0.39456 to 0.55782, saving model to result/all/four/OUR6-9/epoch-06-val-acc-0.5578.hdf5\n","Epoch 7/100\n","16/16 [==============================] - 1s 55ms/step - loss: 1.0930 - acc: 0.5504 - val_loss: 1.1072 - val_acc: 0.5578\n","\n","Epoch 00007: val_acc did not improve from 0.55782\n","Epoch 8/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.9168 - acc: 0.6354 - val_loss: 0.9684 - val_acc: 0.6463\n","\n","Epoch 00008: val_acc improved from 0.55782 to 0.64626, saving model to result/all/four/OUR6-9/epoch-08-val-acc-0.6463.hdf5\n","Epoch 9/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.8824 - acc: 0.6380 - val_loss: 0.8917 - val_acc: 0.6803\n","\n","Epoch 00009: val_acc improved from 0.64626 to 0.68027, saving model to result/all/four/OUR6-9/epoch-09-val-acc-0.6803.hdf5\n","Epoch 10/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.7270 - acc: 0.7383 - val_loss: 0.9237 - val_acc: 0.6803\n","\n","Epoch 00010: val_acc improved from 0.68027 to 0.68027, saving model to result/all/four/OUR6-9/epoch-10-val-acc-0.6803.hdf5\n","Epoch 11/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.7231 - acc: 0.7225 - val_loss: 0.8629 - val_acc: 0.6939\n","\n","Epoch 00011: val_acc improved from 0.68027 to 0.69388, saving model to result/all/four/OUR6-9/epoch-11-val-acc-0.6939.hdf5\n","Epoch 12/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.6962 - acc: 0.7354 - val_loss: 0.8664 - val_acc: 0.7075\n","\n","Epoch 00012: val_acc improved from 0.69388 to 0.70748, saving model to result/all/four/OUR6-9/epoch-12-val-acc-0.7075.hdf5\n","Epoch 13/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.6538 - acc: 0.7509 - val_loss: 0.8306 - val_acc: 0.7143\n","\n","Epoch 00013: val_acc improved from 0.70748 to 0.71429, saving model to result/all/four/OUR6-9/epoch-13-val-acc-0.7143.hdf5\n","Epoch 14/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.5457 - acc: 0.7975 - val_loss: 0.7900 - val_acc: 0.7347\n","\n","Epoch 00014: val_acc improved from 0.71429 to 0.73469, saving model to result/all/four/OUR6-9/epoch-14-val-acc-0.7347.hdf5\n","Epoch 15/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.4476 - acc: 0.8107 - val_loss: 0.7728 - val_acc: 0.7279\n","\n","Epoch 00015: val_acc did not improve from 0.73469\n","Epoch 16/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.4054 - acc: 0.8524 - val_loss: 0.8650 - val_acc: 0.6599\n","\n","Epoch 00016: val_acc did not improve from 0.73469\n","Epoch 17/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.3666 - acc: 0.8721 - val_loss: 0.7046 - val_acc: 0.7483\n","\n","Epoch 00017: val_acc improved from 0.73469 to 0.74830, saving model to result/all/four/OUR6-9/epoch-17-val-acc-0.7483.hdf5\n","Epoch 18/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.2870 - acc: 0.8892 - val_loss: 0.7458 - val_acc: 0.7347\n","\n","Epoch 00018: val_acc did not improve from 0.74830\n","Epoch 19/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.2555 - acc: 0.9006 - val_loss: 0.7874 - val_acc: 0.7415\n","\n","Epoch 00019: val_acc did not improve from 0.74830\n","Epoch 20/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.2365 - acc: 0.9138 - val_loss: 0.8401 - val_acc: 0.7483\n","\n","Epoch 00020: val_acc improved from 0.74830 to 0.74830, saving model to result/all/four/OUR6-9/epoch-20-val-acc-0.7483.hdf5\n","Epoch 21/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.3248 - acc: 0.8941 - val_loss: 0.7441 - val_acc: 0.7551\n","\n","Epoch 00021: val_acc improved from 0.74830 to 0.75510, saving model to result/all/four/OUR6-9/epoch-21-val-acc-0.7551.hdf5\n","Epoch 22/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.2019 - acc: 0.9233 - val_loss: 0.9012 - val_acc: 0.7211\n","\n","Epoch 00022: val_acc did not improve from 0.75510\n","Epoch 23/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.1759 - acc: 0.9370 - val_loss: 0.7941 - val_acc: 0.7551\n","\n","Epoch 00023: val_acc did not improve from 0.75510\n","Epoch 24/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.1151 - acc: 0.9636 - val_loss: 0.9085 - val_acc: 0.7891\n","\n","Epoch 00024: val_acc improved from 0.75510 to 0.78912, saving model to result/all/four/OUR6-9/epoch-24-val-acc-0.7891.hdf5\n","Epoch 25/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.1103 - acc: 0.9618 - val_loss: 0.8854 - val_acc: 0.7823\n","\n","Epoch 00025: val_acc did not improve from 0.78912\n","Epoch 26/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.1609 - acc: 0.9450 - val_loss: 1.0726 - val_acc: 0.7279\n","\n","Epoch 00026: val_acc did not improve from 0.78912\n","Epoch 27/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.1377 - acc: 0.9508 - val_loss: 0.9083 - val_acc: 0.7279\n","\n","Epoch 00027: val_acc did not improve from 0.78912\n","Epoch 28/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.1122 - acc: 0.9547 - val_loss: 0.9635 - val_acc: 0.7551\n","\n","Epoch 00028: val_acc did not improve from 0.78912\n","Epoch 29/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0885 - acc: 0.9638 - val_loss: 0.8881 - val_acc: 0.7687\n","\n","Epoch 00029: val_acc did not improve from 0.78912\n","Epoch 30/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0778 - acc: 0.9705 - val_loss: 1.0116 - val_acc: 0.7143\n","\n","Epoch 00030: val_acc did not improve from 0.78912\n","Epoch 31/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0594 - acc: 0.9784 - val_loss: 1.0389 - val_acc: 0.7959\n","\n","Epoch 00031: val_acc improved from 0.78912 to 0.79592, saving model to result/all/four/OUR6-9/epoch-31-val-acc-0.7959.hdf5\n","Epoch 32/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0511 - acc: 0.9814 - val_loss: 1.0971 - val_acc: 0.7551\n","\n","Epoch 00032: val_acc did not improve from 0.79592\n","Epoch 33/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0857 - acc: 0.9705 - val_loss: 0.9962 - val_acc: 0.7755\n","\n","Epoch 00033: val_acc did not improve from 0.79592\n","Epoch 34/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0681 - acc: 0.9755 - val_loss: 1.1323 - val_acc: 0.7415\n","\n","Epoch 00034: val_acc did not improve from 0.79592\n","Epoch 35/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.1074 - acc: 0.9695 - val_loss: 1.0764 - val_acc: 0.7483\n","\n","Epoch 00035: val_acc did not improve from 0.79592\n","Epoch 36/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.1519 - acc: 0.9370 - val_loss: 1.4177 - val_acc: 0.7007\n","\n","Epoch 00036: val_acc did not improve from 0.79592\n","Epoch 37/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.1616 - acc: 0.9440 - val_loss: 1.3101 - val_acc: 0.7211\n","\n","Epoch 00037: val_acc did not improve from 0.79592\n","Epoch 38/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0856 - acc: 0.9765 - val_loss: 0.9694 - val_acc: 0.7755\n","\n","Epoch 00038: val_acc did not improve from 0.79592\n","Epoch 39/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0458 - acc: 0.9853 - val_loss: 0.9695 - val_acc: 0.7823\n","\n","Epoch 00039: val_acc did not improve from 0.79592\n","Epoch 40/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0515 - acc: 0.9823 - val_loss: 0.9958 - val_acc: 0.7891\n","\n","Epoch 00040: val_acc did not improve from 0.79592\n","Epoch 41/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0560 - acc: 0.9814 - val_loss: 1.2167 - val_acc: 0.7415\n","\n","Epoch 00041: val_acc did not improve from 0.79592\n","Epoch 42/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0352 - acc: 0.9902 - val_loss: 1.1661 - val_acc: 0.7687\n","\n","Epoch 00042: val_acc did not improve from 0.79592\n","Epoch 43/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0315 - acc: 0.9902 - val_loss: 1.2126 - val_acc: 0.7619\n","\n","Epoch 00043: val_acc did not improve from 0.79592\n","Epoch 44/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0298 - acc: 0.9922 - val_loss: 1.0644 - val_acc: 0.7687\n","\n","Epoch 00044: val_acc did not improve from 0.79592\n","Epoch 45/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0218 - acc: 0.9891 - val_loss: 1.1529 - val_acc: 0.7619\n","\n","Epoch 00045: val_acc did not improve from 0.79592\n","Epoch 46/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0898 - acc: 0.9832 - val_loss: 1.3470 - val_acc: 0.7483\n","\n","Epoch 00046: val_acc did not improve from 0.79592\n","Epoch 47/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0908 - acc: 0.9667 - val_loss: 1.2236 - val_acc: 0.7551\n","\n","Epoch 00047: val_acc did not improve from 0.79592\n","Epoch 48/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0644 - acc: 0.9784 - val_loss: 1.1293 - val_acc: 0.7415\n","\n","Epoch 00048: val_acc did not improve from 0.79592\n","Epoch 49/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0192 - acc: 0.9951 - val_loss: 1.1135 - val_acc: 0.7687\n","\n","Epoch 00049: val_acc did not improve from 0.79592\n","Epoch 50/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0135 - acc: 0.9951 - val_loss: 1.1825 - val_acc: 0.7755\n","\n","Epoch 00050: val_acc did not improve from 0.79592\n","Epoch 51/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0217 - acc: 0.9912 - val_loss: 1.2941 - val_acc: 0.7347\n","\n","Epoch 00051: val_acc did not improve from 0.79592\n","Epoch 52/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0147 - acc: 0.9951 - val_loss: 1.2072 - val_acc: 0.7755\n","\n","Epoch 00052: val_acc did not improve from 0.79592\n","Epoch 53/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0197 - acc: 0.9921 - val_loss: 1.2406 - val_acc: 0.7415\n","\n","Epoch 00053: val_acc did not improve from 0.79592\n","Epoch 54/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0235 - acc: 0.9892 - val_loss: 1.3789 - val_acc: 0.7483\n","\n","Epoch 00054: val_acc did not improve from 0.79592\n","Epoch 55/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0185 - acc: 0.9961 - val_loss: 1.1658 - val_acc: 0.7823\n","\n","Epoch 00055: val_acc did not improve from 0.79592\n","Epoch 56/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0223 - acc: 0.9922 - val_loss: 1.2769 - val_acc: 0.7415\n","\n","Epoch 00056: val_acc did not improve from 0.79592\n","Epoch 57/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0251 - acc: 0.9921 - val_loss: 1.3052 - val_acc: 0.7619\n","\n","Epoch 00057: val_acc did not improve from 0.79592\n","Epoch 58/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0076 - acc: 0.9980 - val_loss: 1.2937 - val_acc: 0.7959\n","\n","Epoch 00058: val_acc improved from 0.79592 to 0.79592, saving model to result/all/four/OUR6-9/epoch-58-val-acc-0.7959.hdf5\n","Epoch 59/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0380 - acc: 0.9872 - val_loss: 1.2557 - val_acc: 0.7755\n","\n","Epoch 00059: val_acc did not improve from 0.79592\n","Epoch 60/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0462 - acc: 0.9853 - val_loss: 1.3931 - val_acc: 0.7551\n","\n","Epoch 00060: val_acc did not improve from 0.79592\n","Epoch 61/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0334 - acc: 0.9921 - val_loss: 1.5221 - val_acc: 0.7347\n","\n","Epoch 00061: val_acc did not improve from 0.79592\n","Epoch 62/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0309 - acc: 0.9853 - val_loss: 1.4654 - val_acc: 0.7347\n","\n","Epoch 00062: val_acc did not improve from 0.79592\n","Epoch 63/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0240 - acc: 0.9902 - val_loss: 1.4739 - val_acc: 0.7551\n","\n","Epoch 00063: val_acc did not improve from 0.79592\n","Epoch 64/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0158 - acc: 0.9941 - val_loss: 1.4157 - val_acc: 0.7551\n","\n","Epoch 00064: val_acc did not improve from 0.79592\n","Epoch 65/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0119 - acc: 0.9951 - val_loss: 1.4533 - val_acc: 0.7551\n","\n","Epoch 00065: val_acc did not improve from 0.79592\n","Epoch 66/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0190 - acc: 0.9931 - val_loss: 1.2670 - val_acc: 0.7823\n","\n","Epoch 00066: val_acc did not improve from 0.79592\n","Epoch 67/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0093 - acc: 0.9971 - val_loss: 1.3931 - val_acc: 0.7279\n","\n","Epoch 00067: val_acc did not improve from 0.79592\n","Epoch 68/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0236 - acc: 0.9931 - val_loss: 1.4513 - val_acc: 0.7619\n","\n","Epoch 00068: val_acc did not improve from 0.79592\n","Epoch 69/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0404 - acc: 0.9812 - val_loss: 1.9012 - val_acc: 0.7211\n","\n","Epoch 00069: val_acc did not improve from 0.79592\n","Epoch 70/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.1683 - acc: 0.9530 - val_loss: 1.5749 - val_acc: 0.7211\n","\n","Epoch 00070: val_acc did not improve from 0.79592\n","Epoch 71/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0677 - acc: 0.9744 - val_loss: 1.3876 - val_acc: 0.7143\n","\n","Epoch 00071: val_acc did not improve from 0.79592\n","Epoch 72/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.1053 - acc: 0.9656 - val_loss: 1.2164 - val_acc: 0.7755\n","\n","Epoch 00072: val_acc did not improve from 0.79592\n","Epoch 73/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0735 - acc: 0.9696 - val_loss: 1.2435 - val_acc: 0.7687\n","\n","Epoch 00073: val_acc did not improve from 0.79592\n","Epoch 74/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0969 - acc: 0.9687 - val_loss: 1.3934 - val_acc: 0.7075\n","\n","Epoch 00074: val_acc did not improve from 0.79592\n","Epoch 75/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0501 - acc: 0.9813 - val_loss: 1.4945 - val_acc: 0.7755\n","\n","Epoch 00075: val_acc did not improve from 0.79592\n","Epoch 76/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0627 - acc: 0.9754 - val_loss: 1.6037 - val_acc: 0.7279\n","\n","Epoch 00076: val_acc did not improve from 0.79592\n","Epoch 77/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.1381 - acc: 0.9555 - val_loss: 1.7671 - val_acc: 0.7279\n","\n","Epoch 00077: val_acc did not improve from 0.79592\n","Epoch 78/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0717 - acc: 0.9696 - val_loss: 1.3838 - val_acc: 0.7755\n","\n","Epoch 00078: val_acc did not improve from 0.79592\n","Epoch 79/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0877 - acc: 0.9735 - val_loss: 1.2714 - val_acc: 0.7143\n","\n","Epoch 00079: val_acc did not improve from 0.79592\n","Epoch 80/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0387 - acc: 0.9843 - val_loss: 1.2755 - val_acc: 0.7551\n","\n","Epoch 00080: val_acc did not improve from 0.79592\n","Epoch 81/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0215 - acc: 0.9912 - val_loss: 1.5016 - val_acc: 0.7347\n","\n","Epoch 00081: val_acc did not improve from 0.79592\n","Epoch 82/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0558 - acc: 0.9784 - val_loss: 1.6136 - val_acc: 0.7211\n","\n","Epoch 00082: val_acc did not improve from 0.79592\n","Epoch 83/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0485 - acc: 0.9862 - val_loss: 1.4244 - val_acc: 0.7483\n","\n","Epoch 00083: val_acc did not improve from 0.79592\n","Epoch 84/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0431 - acc: 0.9824 - val_loss: 1.7523 - val_acc: 0.7143\n","\n","Epoch 00084: val_acc did not improve from 0.79592\n","Epoch 85/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.1208 - acc: 0.9754 - val_loss: 1.6978 - val_acc: 0.7143\n","\n","Epoch 00085: val_acc did not improve from 0.79592\n","Epoch 86/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.1297 - acc: 0.9715 - val_loss: 0.9353 - val_acc: 0.8095\n","\n","Epoch 00086: val_acc improved from 0.79592 to 0.80952, saving model to result/all/four/OUR6-9/epoch-86-val-acc-0.8095.hdf5\n","Epoch 87/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0795 - acc: 0.9804 - val_loss: 0.9403 - val_acc: 0.7551\n","\n","Epoch 00087: val_acc did not improve from 0.80952\n","Epoch 88/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0454 - acc: 0.9872 - val_loss: 1.0570 - val_acc: 0.7619\n","\n","Epoch 00088: val_acc did not improve from 0.80952\n","Epoch 89/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0366 - acc: 0.9873 - val_loss: 1.0585 - val_acc: 0.7823\n","\n","Epoch 00089: val_acc did not improve from 0.80952\n","Epoch 90/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0132 - acc: 0.9951 - val_loss: 1.0151 - val_acc: 0.7823\n","\n","Epoch 00090: val_acc did not improve from 0.80952\n","Epoch 91/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0120 - acc: 0.9961 - val_loss: 0.8865 - val_acc: 0.7959\n","\n","Epoch 00091: val_acc did not improve from 0.80952\n","Epoch 92/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0074 - acc: 0.9980 - val_loss: 1.1115 - val_acc: 0.7619\n","\n","Epoch 00092: val_acc did not improve from 0.80952\n","Epoch 93/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0184 - acc: 0.9941 - val_loss: 0.9550 - val_acc: 0.8095\n","\n","Epoch 00093: val_acc did not improve from 0.80952\n","Epoch 94/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0065 - acc: 0.9961 - val_loss: 1.0922 - val_acc: 0.7755\n","\n","Epoch 00094: val_acc did not improve from 0.80952\n","Epoch 95/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0090 - acc: 0.9971 - val_loss: 1.1017 - val_acc: 0.7619\n","\n","Epoch 00095: val_acc did not improve from 0.80952\n","Epoch 96/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0057 - acc: 0.9980 - val_loss: 1.0893 - val_acc: 0.7483\n","\n","Epoch 00096: val_acc did not improve from 0.80952\n","Epoch 97/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0067 - acc: 0.9971 - val_loss: 1.0616 - val_acc: 0.7823\n","\n","Epoch 00097: val_acc did not improve from 0.80952\n","Epoch 98/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.0071 - acc: 0.9980 - val_loss: 1.1701 - val_acc: 0.7347\n","\n","Epoch 00098: val_acc did not improve from 0.80952\n","Epoch 99/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 1.1993 - val_acc: 0.7551\n","\n","Epoch 00099: val_acc did not improve from 0.80952\n","Epoch 100/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0034 - acc: 0.9990 - val_loss: 1.1827 - val_acc: 0.7823\n","\n","Epoch 00100: val_acc did not improve from 0.80952\n","\n","<keras.callbacks.History at 0x7fd7c543f400>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XEeQZrpXJ3rA","colab_type":"code","colab":{}},"cell_type":"code","source":["#our1 moel our 1-1 all four 77 \n","\n","\n","\n","Epoch 1/100\n","16/16 [==============================] - 2s 110ms/step - loss: 1.3785 - acc: 0.2707 - val_loss: 1.3963 - val_acc: 0.2721\n","\n","Epoch 00001: val_acc improved from -inf to 0.27211, saving model to result/all/four/OUR-1-1/epoch-01-val-acc-0.2721.hdf5\n","Epoch 2/100\n","16/16 [==============================] - 1s 52ms/step - loss: 1.3783 - acc: 0.2694 - val_loss: 1.3748 - val_acc: 0.2721\n","\n","Epoch 00002: val_acc did not improve from 0.27211\n","Epoch 3/100\n","16/16 [==============================] - 1s 47ms/step - loss: 1.3602 - acc: 0.3023 - val_loss: 1.3835 - val_acc: 0.3197\n","\n","Epoch 00003: val_acc improved from 0.27211 to 0.31973, saving model to result/all/four/OUR-1-1/epoch-03-val-acc-0.3197.hdf5\n","Epoch 4/100\n","16/16 [==============================] - 1s 52ms/step - loss: 1.3578 - acc: 0.2911 - val_loss: 1.3796 - val_acc: 0.3197\n","\n","Epoch 00004: val_acc did not improve from 0.31973\n","Epoch 5/100\n","16/16 [==============================] - 1s 47ms/step - loss: 1.3662 - acc: 0.3101 - val_loss: 1.3741 - val_acc: 0.3197\n","\n","Epoch 00005: val_acc did not improve from 0.31973\n","Epoch 6/100\n","16/16 [==============================] - 1s 52ms/step - loss: 1.3532 - acc: 0.3270 - val_loss: 1.3833 - val_acc: 0.3197\n","\n","Epoch 00006: val_acc did not improve from 0.31973\n","Epoch 7/100\n","16/16 [==============================] - 1s 52ms/step - loss: 1.3562 - acc: 0.3107 - val_loss: 1.3844 - val_acc: 0.3197\n","\n","Epoch 00007: val_acc did not improve from 0.31973\n","Epoch 8/100\n","16/16 [==============================] - 1s 47ms/step - loss: 1.3627 - acc: 0.3090 - val_loss: 1.3792 - val_acc: 0.3197\n","\n","Epoch 00008: val_acc did not improve from 0.31973\n","Epoch 9/100\n","16/16 [==============================] - 1s 53ms/step - loss: 1.3546 - acc: 0.3079 - val_loss: 1.3838 - val_acc: 0.3197\n","\n","Epoch 00009: val_acc did not improve from 0.31973\n","Epoch 10/100\n","16/16 [==============================] - 1s 47ms/step - loss: 1.3586 - acc: 0.3100 - val_loss: 1.3773 - val_acc: 0.3197\n","\n","Epoch 00010: val_acc did not improve from 0.31973\n","Epoch 11/100\n","16/16 [==============================] - 1s 51ms/step - loss: 1.3586 - acc: 0.3070 - val_loss: 1.3763 - val_acc: 0.3197\n","\n","Epoch 00011: val_acc did not improve from 0.31973\n","Epoch 12/100\n","16/16 [==============================] - 1s 52ms/step - loss: 1.3587 - acc: 0.3058 - val_loss: 1.3843 - val_acc: 0.3197\n","\n","Epoch 00012: val_acc did not improve from 0.31973\n","Epoch 13/100\n","16/16 [==============================] - 1s 47ms/step - loss: 1.3563 - acc: 0.2656 - val_loss: 1.3832 - val_acc: 0.3197\n","\n","Epoch 00013: val_acc did not improve from 0.31973\n","Epoch 14/100\n","16/16 [==============================] - 1s 49ms/step - loss: 1.3543 - acc: 0.3098 - val_loss: 1.3989 - val_acc: 0.3197\n","\n","Epoch 00014: val_acc did not improve from 0.31973\n","Epoch 15/100\n","16/16 [==============================] - 1s 46ms/step - loss: 1.3725 - acc: 0.3139 - val_loss: 1.3782 - val_acc: 0.3197\n","\n","Epoch 00015: val_acc did not improve from 0.31973\n","Epoch 16/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.3591 - acc: 0.2813 - val_loss: 1.3789 - val_acc: 0.3197\n","\n","Epoch 00016: val_acc did not improve from 0.31973\n","Epoch 17/100\n","16/16 [==============================] - 1s 47ms/step - loss: 1.3481 - acc: 0.3178 - val_loss: 1.2565 - val_acc: 0.4966\n","\n","Epoch 00017: val_acc improved from 0.31973 to 0.49660, saving model to result/all/four/OUR-1-1/epoch-17-val-acc-0.4966.hdf5\n","Epoch 18/100\n","16/16 [==============================] - 1s 52ms/step - loss: 1.2763 - acc: 0.4470 - val_loss: 1.3087 - val_acc: 0.4898\n","\n","Epoch 00018: val_acc did not improve from 0.49660\n","Epoch 19/100\n","16/16 [==============================] - 1s 47ms/step - loss: 1.2483 - acc: 0.4202 - val_loss: 1.1533 - val_acc: 0.4966\n","\n","Epoch 00019: val_acc did not improve from 0.49660\n","Epoch 20/100\n","16/16 [==============================] - 1s 47ms/step - loss: 1.1598 - acc: 0.4901 - val_loss: 1.1381 - val_acc: 0.5238\n","\n","Epoch 00020: val_acc improved from 0.49660 to 0.52381, saving model to result/all/four/OUR-1-1/epoch-20-val-acc-0.5238.hdf5\n","Epoch 21/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.1076 - acc: 0.4960 - val_loss: 1.0900 - val_acc: 0.5374\n","\n","Epoch 00021: val_acc improved from 0.52381 to 0.53741, saving model to result/all/four/OUR-1-1/epoch-21-val-acc-0.5374.hdf5\n","Epoch 22/100\n","16/16 [==============================] - 1s 52ms/step - loss: 1.0678 - acc: 0.5373 - val_loss: 1.0434 - val_acc: 0.5578\n","\n","Epoch 00022: val_acc improved from 0.53741 to 0.55782, saving model to result/all/four/OUR-1-1/epoch-22-val-acc-0.5578.hdf5\n","Epoch 23/100\n","16/16 [==============================] - 1s 49ms/step - loss: 1.0431 - acc: 0.5690 - val_loss: 1.1266 - val_acc: 0.4762\n","\n","Epoch 00023: val_acc did not improve from 0.55782\n","Epoch 24/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.9794 - acc: 0.5774 - val_loss: 1.0397 - val_acc: 0.5918\n","\n","Epoch 00024: val_acc improved from 0.55782 to 0.59184, saving model to result/all/four/OUR-1-1/epoch-24-val-acc-0.5918.hdf5\n","Epoch 25/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.8024 - acc: 0.6802 - val_loss: 0.9974 - val_acc: 0.5510\n","\n","Epoch 00025: val_acc did not improve from 0.59184\n","Epoch 26/100\n","16/16 [==============================] - 1s 47ms/step - loss: 0.7298 - acc: 0.6928 - val_loss: 1.0483 - val_acc: 0.5918\n","\n","Epoch 00026: val_acc did not improve from 0.59184\n","Epoch 27/100\n","16/16 [==============================] - 1s 51ms/step - loss: 0.6871 - acc: 0.7206 - val_loss: 1.0047 - val_acc: 0.5986\n","\n","Epoch 00027: val_acc improved from 0.59184 to 0.59864, saving model to result/all/four/OUR-1-1/epoch-27-val-acc-0.5986.hdf5\n","Epoch 28/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.5835 - acc: 0.7776 - val_loss: 0.9835 - val_acc: 0.6395\n","\n","Epoch 00028: val_acc improved from 0.59864 to 0.63946, saving model to result/all/four/OUR-1-1/epoch-28-val-acc-0.6395.hdf5\n","Epoch 29/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.4662 - acc: 0.8069 - val_loss: 0.9010 - val_acc: 0.7007\n","\n","Epoch 00029: val_acc improved from 0.63946 to 0.70068, saving model to result/all/four/OUR-1-1/epoch-29-val-acc-0.7007.hdf5\n","Epoch 30/100\n","16/16 [==============================] - 1s 49ms/step - loss: 0.4169 - acc: 0.8266 - val_loss: 0.9495 - val_acc: 0.6667\n","\n","Epoch 00030: val_acc did not improve from 0.70068\n","Epoch 31/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.2151 - acc: 0.9216 - val_loss: 0.8463 - val_acc: 0.7143\n","\n","Epoch 00031: val_acc improved from 0.70068 to 0.71429, saving model to result/all/four/OUR-1-1/epoch-31-val-acc-0.7143.hdf5\n","Epoch 32/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.2099 - acc: 0.9203 - val_loss: 1.2665 - val_acc: 0.6599\n","\n","Epoch 00032: val_acc did not improve from 0.71429\n","Epoch 33/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.2217 - acc: 0.9076 - val_loss: 1.0776 - val_acc: 0.7483\n","\n","Epoch 00033: val_acc improved from 0.71429 to 0.74830, saving model to result/all/four/OUR-1-1/epoch-33-val-acc-0.7483.hdf5\n","Epoch 34/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.1121 - acc: 0.9618 - val_loss: 1.2288 - val_acc: 0.7347\n","\n","Epoch 00034: val_acc did not improve from 0.74830\n","Epoch 35/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.3177 - acc: 0.9084 - val_loss: 1.2563 - val_acc: 0.6939\n","\n","Epoch 00035: val_acc did not improve from 0.74830\n","Epoch 36/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.3676 - acc: 0.8568 - val_loss: 0.9880 - val_acc: 0.6599\n","\n","Epoch 00036: val_acc did not improve from 0.74830\n","Epoch 37/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.2129 - acc: 0.9312 - val_loss: 1.0331 - val_acc: 0.7143\n","\n","Epoch 00037: val_acc did not improve from 0.74830\n","Epoch 38/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.0810 - acc: 0.9803 - val_loss: 1.3356 - val_acc: 0.7347\n","\n","Epoch 00038: val_acc did not improve from 0.74830\n","Epoch 39/100\n","16/16 [==============================] - 1s 48ms/step - loss: 0.0313 - acc: 0.9902 - val_loss: 1.3581 - val_acc: 0.7415\n","\n","Epoch 00039: val_acc did not improve from 0.74830\n","Epoch 40/100\n","16/16 [==============================] - 1s 46ms/step - loss: 0.0125 - acc: 0.9971 - val_loss: 1.4110 - val_acc: 0.7347\n","\n","Epoch 00040: val_acc did not improve from 0.74830\n","Epoch 41/100\n","16/16 [==============================] - 1s 46ms/step - loss: 0.0079 - acc: 0.9980 - val_loss: 1.4799 - val_acc: 0.7755\n","\n","Epoch 00041: val_acc improved from 0.74830 to 0.77551, saving model to result/all/four/OUR-1-1/epoch-41-val-acc-0.7755.hdf5\n","Epoch 42/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 1.5044 - val_acc: 0.7551\n","\n","Epoch 00042: val_acc did not improve from 0.77551\n","Epoch 43/100\n","16/16 [==============================] - 1s 50ms/step - loss: 0.0036 - acc: 0.9990 - val_loss: 1.5159 - val_acc: 0.7755\n","\n","Epoch 00043: val_acc improved from 0.77551 to 0.77551, saving model to result/all/four/OUR-1-1/epoch-43-val-acc-0.7755.hdf5\n","Epoch 44/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.5778 - val_acc: 0.7687\n","\n","Epoch 00044: val_acc did not improve from 0.77551\n","Epoch 45/100\n","16/16 [==============================] - 1s 47ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.6273 - val_acc: 0.7619\n","\n","Epoch 00045: val_acc did not improve from 0.77551\n","Epoch 46/100\n","16/16 [==============================] - 1s 47ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.6535 - val_acc: 0.7619\n","\n","Epoch 00046: val_acc did not improve from 0.77551\n","Epoch 47/100\n","16/16 [==============================] - 1s 50ms/step - loss: 6.8790e-04 - acc: 1.0000 - val_loss: 1.6726 - val_acc: 0.7619\n","\n","Epoch 00047: val_acc did not improve from 0.77551\n","Epoch 48/100\n","16/16 [==============================] - 1s 47ms/step - loss: 6.6224e-04 - acc: 1.0000 - val_loss: 1.6994 - val_acc: 0.7619\n","\n","Epoch 00048: val_acc did not improve from 0.77551\n","Epoch 49/100\n","16/16 [==============================] - 1s 52ms/step - loss: 6.7143e-04 - acc: 1.0000 - val_loss: 1.7111 - val_acc: 0.7619\n","\n","Epoch 00049: val_acc did not improve from 0.77551\n","Epoch 50/100\n","16/16 [==============================] - 1s 48ms/step - loss: 5.8883e-04 - acc: 1.0000 - val_loss: 1.7244 - val_acc: 0.7619\n","\n","Epoch 00050: val_acc did not improve from 0.77551\n","Epoch 51/100\n","16/16 [==============================] - 1s 52ms/step - loss: 4.8121e-04 - acc: 1.0000 - val_loss: 1.7349 - val_acc: 0.7619\n","\n","Epoch 00051: val_acc did not improve from 0.77551\n","Epoch 52/100\n","16/16 [==============================] - 1s 51ms/step - loss: 3.0628e-04 - acc: 1.0000 - val_loss: 1.7528 - val_acc: 0.7619\n","\n","Epoch 00052: val_acc did not improve from 0.77551\n","Epoch 53/100\n","16/16 [==============================] - 1s 48ms/step - loss: 3.0631e-04 - acc: 1.0000 - val_loss: 1.7536 - val_acc: 0.7755\n","\n","Epoch 00053: val_acc did not improve from 0.77551\n","Epoch 54/100\n","16/16 [==============================] - 1s 52ms/step - loss: 2.1322e-04 - acc: 1.0000 - val_loss: 1.7575 - val_acc: 0.7755\n","\n","Epoch 00054: val_acc did not improve from 0.77551\n","Epoch 55/100\n","16/16 [==============================] - 1s 49ms/step - loss: 2.3172e-04 - acc: 1.0000 - val_loss: 1.7660 - val_acc: 0.7755\n","\n","Epoch 00055: val_acc did not improve from 0.77551\n","Epoch 56/100\n","16/16 [==============================] - 1s 50ms/step - loss: 2.1053e-04 - acc: 1.0000 - val_loss: 1.7739 - val_acc: 0.7755\n","\n","Epoch 00056: val_acc did not improve from 0.77551\n","Epoch 57/100\n","16/16 [==============================] - 1s 51ms/step - loss: 1.4063e-04 - acc: 1.0000 - val_loss: 1.7750 - val_acc: 0.7687\n","\n","Epoch 00057: val_acc did not improve from 0.77551\n","Epoch 58/100\n","16/16 [==============================] - 1s 48ms/step - loss: 1.6582e-04 - acc: 1.0000 - val_loss: 1.8122 - val_acc: 0.7687\n","\n","Epoch 00058: val_acc did not improve from 0.77551\n","Epoch 59/100\n","16/16 [==============================] - 1s 52ms/step - loss: 1.4537e-04 - acc: 1.0000 - val_loss: 1.8386 - val_acc: 0.7619\n","\n","Epoch 00059: val_acc did not improve from 0.77551\n","Epoch 60/100\n","16/16 [==============================] - 1s 47ms/step - loss: 8.6915e-05 - acc: 1.0000 - val_loss: 1.8690 - val_acc: 0.7551\n","\n","Epoch 00060: val_acc did not improve from 0.77551\n","Epoch 61/100\n","16/16 [==============================] - 1s 51ms/step - loss: 7.1312e-05 - acc: 1.0000 - val_loss: 1.8633 - val_acc: 0.7483\n","\n","Epoch 00061: val_acc did not improve from 0.77551\n","Epoch 62/100\n","16/16 [==============================] - 1s 51ms/step - loss: 1.0022e-04 - acc: 1.0000 - val_loss: 1.8802 - val_acc: 0.7619\n","\n","Epoch 00062: val_acc did not improve from 0.77551\n","Epoch 63/100\n","16/16 [==============================] - 1s 49ms/step - loss: 5.8293e-05 - acc: 1.0000 - val_loss: 1.9234 - val_acc: 0.7551\n","\n","Epoch 00063: val_acc did not improve from 0.77551\n","Epoch 64/100\n","16/16 [==============================] - 1s 46ms/step - loss: 6.1868e-05 - acc: 1.0000 - val_loss: 1.9211 - val_acc: 0.7483\n","\n","Epoch 00064: val_acc did not improve from 0.77551\n","Epoch 65/100\n","16/16 [==============================] - 1s 47ms/step - loss: 5.9978e-05 - acc: 1.0000 - val_loss: 1.8959 - val_acc: 0.7755\n","\n","Epoch 00065: val_acc did not improve from 0.77551\n","Epoch 66/100\n","16/16 [==============================] - 1s 51ms/step - loss: 5.2704e-05 - acc: 1.0000 - val_loss: 1.9317 - val_acc: 0.7551\n","\n","Epoch 00066: val_acc did not improve from 0.77551\n","Epoch 67/100\n","16/16 [==============================] - 1s 50ms/step - loss: 4.6729e-05 - acc: 1.0000 - val_loss: 1.9547 - val_acc: 0.7551\n","\n","Epoch 00067: val_acc did not improve from 0.77551\n","Epoch 68/100\n","16/16 [==============================] - 1s 47ms/step - loss: 3.2608e-05 - acc: 1.0000 - val_loss: 1.9640 - val_acc: 0.7619\n","\n","Epoch 00068: val_acc did not improve from 0.77551\n","Epoch 69/100\n","16/16 [==============================] - 1s 53ms/step - loss: 2.6942e-05 - acc: 1.0000 - val_loss: 1.9696 - val_acc: 0.7551\n","\n","Epoch 00069: val_acc did not improve from 0.77551\n","Epoch 70/100\n","16/16 [==============================] - 1s 47ms/step - loss: 3.4871e-05 - acc: 1.0000 - val_loss: 1.9885 - val_acc: 0.7619\n","\n","Epoch 00070: val_acc did not improve from 0.77551\n","Epoch 71/100\n","16/16 [==============================] - 1s 49ms/step - loss: 2.4169e-05 - acc: 1.0000 - val_loss: 1.9955 - val_acc: 0.7619\n","\n","Epoch 00071: val_acc did not improve from 0.77551\n","Epoch 72/100\n","16/16 [==============================] - 1s 49ms/step - loss: 2.7285e-05 - acc: 1.0000 - val_loss: 2.0010 - val_acc: 0.7619\n","\n","Epoch 00072: val_acc did not improve from 0.77551\n","Epoch 73/100\n","16/16 [==============================] - 1s 48ms/step - loss: 1.9991e-05 - acc: 1.0000 - val_loss: 2.0205 - val_acc: 0.7551\n","\n","Epoch 00073: val_acc did not improve from 0.77551\n","Epoch 74/100\n","16/16 [==============================] - 1s 52ms/step - loss: 2.9965e-05 - acc: 1.0000 - val_loss: 2.0188 - val_acc: 0.7619\n","\n","Epoch 00074: val_acc did not improve from 0.77551\n","Epoch 75/100\n","16/16 [==============================] - 1s 47ms/step - loss: 1.6231e-05 - acc: 1.0000 - val_loss: 2.0331 - val_acc: 0.7687\n","\n","Epoch 00075: val_acc did not improve from 0.77551\n","Epoch 76/100\n","16/16 [==============================] - 1s 51ms/step - loss: 2.0316e-05 - acc: 1.0000 - val_loss: 2.0390 - val_acc: 0.7619\n","\n","Epoch 00076: val_acc did not improve from 0.77551\n","Epoch 77/100\n","16/16 [==============================] - 1s 52ms/step - loss: 1.4439e-05 - acc: 1.0000 - val_loss: 2.0416 - val_acc: 0.7687\n","\n","Epoch 00077: val_acc did not improve from 0.77551\n","Epoch 78/100\n","16/16 [==============================] - 1s 49ms/step - loss: 1.4337e-05 - acc: 1.0000 - val_loss: 2.0595 - val_acc: 0.7619\n","\n","Epoch 00078: val_acc did not improve from 0.77551\n","Epoch 79/100\n","16/16 [==============================] - 1s 47ms/step - loss: 2.1895e-05 - acc: 1.0000 - val_loss: 2.0593 - val_acc: 0.7687\n","\n","Epoch 00079: val_acc did not improve from 0.77551\n","Epoch 80/100\n","16/16 [==============================] - 1s 47ms/step - loss: 1.1014e-05 - acc: 1.0000 - val_loss: 2.0798 - val_acc: 0.7551\n","\n","Epoch 00080: val_acc did not improve from 0.77551\n","Epoch 81/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.4640e-05 - acc: 1.0000 - val_loss: 2.0667 - val_acc: 0.7687\n","\n","Epoch 00081: val_acc did not improve from 0.77551\n","Epoch 82/100\n","16/16 [==============================] - 1s 50ms/step - loss: 1.1210e-05 - acc: 1.0000 - val_loss: 2.0856 - val_acc: 0.7551\n","\n","Epoch 00082: val_acc did not improve from 0.77551\n","Epoch 83/100\n","16/16 [==============================] - 1s 47ms/step - loss: 9.7966e-06 - acc: 1.0000 - val_loss: 2.0939 - val_acc: 0.7551\n","\n","Epoch 00083: val_acc did not improve from 0.77551\n","Epoch 84/100\n","16/16 [==============================] - 1s 52ms/step - loss: 1.0325e-05 - acc: 1.0000 - val_loss: 2.0966 - val_acc: 0.7483\n","\n","Epoch 00084: val_acc did not improve from 0.77551\n","Epoch 85/100\n","16/16 [==============================] - 1s 49ms/step - loss: 6.4252e-06 - acc: 1.0000 - val_loss: 2.1030 - val_acc: 0.7415\n","\n","Epoch 00085: val_acc did not improve from 0.77551\n","Epoch 86/100\n","16/16 [==============================] - 1s 49ms/step - loss: 7.6403e-06 - acc: 1.0000 - val_loss: 2.1171 - val_acc: 0.7415\n","\n","Epoch 00086: val_acc did not improve from 0.77551\n","Epoch 87/100\n","16/16 [==============================] - 1s 53ms/step - loss: 8.0207e-06 - acc: 1.0000 - val_loss: 2.1263 - val_acc: 0.7415\n","\n","Epoch 00087: val_acc did not improve from 0.77551\n","Epoch 88/100\n","16/16 [==============================] - 1s 47ms/step - loss: 5.8025e-06 - acc: 1.0000 - val_loss: 2.1383 - val_acc: 0.7415\n","\n","Epoch 00088: val_acc did not improve from 0.77551\n","Epoch 89/100\n","16/16 [==============================] - 1s 53ms/step - loss: 7.0028e-06 - acc: 1.0000 - val_loss: 2.1534 - val_acc: 0.7415\n","\n","Epoch 00089: val_acc did not improve from 0.77551\n","Epoch 90/100\n","16/16 [==============================] - 1s 47ms/step - loss: 5.7587e-06 - acc: 1.0000 - val_loss: 2.1570 - val_acc: 0.7415\n","\n","Epoch 00090: val_acc did not improve from 0.77551\n","Epoch 91/100\n","16/16 [==============================] - 1s 46ms/step - loss: 5.0604e-06 - acc: 1.0000 - val_loss: 2.1586 - val_acc: 0.7415\n","\n","Epoch 00091: val_acc did not improve from 0.77551\n","Epoch 92/100\n","16/16 [==============================] - 1s 50ms/step - loss: 4.3548e-06 - acc: 1.0000 - val_loss: 2.1686 - val_acc: 0.7415\n","\n","Epoch 00092: val_acc did not improve from 0.77551\n","Epoch 93/100\n","16/16 [==============================] - 1s 47ms/step - loss: 4.6540e-06 - acc: 1.0000 - val_loss: 2.1841 - val_acc: 0.7415\n","\n","Epoch 00093: val_acc did not improve from 0.77551\n","Epoch 94/100\n","16/16 [==============================] - 1s 53ms/step - loss: 3.5165e-06 - acc: 1.0000 - val_loss: 2.1927 - val_acc: 0.7415\n","\n","Epoch 00094: val_acc did not improve from 0.77551\n","Epoch 95/100\n","16/16 [==============================] - 1s 46ms/step - loss: 3.5502e-06 - acc: 1.0000 - val_loss: 2.2023 - val_acc: 0.7415\n","\n","Epoch 00095: val_acc did not improve from 0.77551\n","Epoch 96/100\n","16/16 [==============================] - 1s 48ms/step - loss: 3.3306e-06 - acc: 1.0000 - val_loss: 2.2184 - val_acc: 0.7415\n","\n","Epoch 00096: val_acc did not improve from 0.77551\n","Epoch 97/100\n","16/16 [==============================] - 1s 47ms/step - loss: 2.6112e-06 - acc: 1.0000 - val_loss: 2.2264 - val_acc: 0.7415\n","\n","Epoch 00097: val_acc did not improve from 0.77551\n","Epoch 98/100\n","16/16 [==============================] - 1s 48ms/step - loss: 2.9151e-06 - acc: 1.0000 - val_loss: 2.2304 - val_acc: 0.7415\n","\n","Epoch 00098: val_acc did not improve from 0.77551\n","Epoch 99/100\n","16/16 [==============================] - 1s 53ms/step - loss: 2.3167e-06 - acc: 1.0000 - val_loss: 2.2354 - val_acc: 0.7415\n","\n","Epoch 00099: val_acc did not improve from 0.77551\n","Epoch 100/100\n","16/16 [==============================] - 1s 47ms/step - loss: 2.7694e-06 - acc: 1.0000 - val_loss: 2.2427 - val_acc: 0.7415\n","\n","Epoch 00100: val_acc did not improve from 0.77551\n","\n","<keras.callbacks.History at 0x7fd7f996aa58>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SjQMDh4F7Wmq","colab_type":"code","colab":{}},"cell_type":"code","source":["model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\n","                    steps_per_epoch=len(X_train) / 32, epochs=100)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-GPYJVLUSbL8","colab_type":"code","colab":{}},"cell_type":"code","source":["#our 6 inter for leeft right 85 our6-22\n","\n","\n","\n","Epoch 1/100\n","16/16 [==============================] - 1s 91ms/step - loss: 1.0619 - acc: 0.4700 - val_loss: 1.0688 - val_acc: 0.4889\n","\n","Epoch 00001: val_acc improved from -inf to 0.48889, saving model to result/left-right/OUR6-22/epoch-01-val-acc-0.4889.hdf5\n","Epoch 2/100\n","16/16 [==============================] - 1s 60ms/step - loss: 1.0200 - acc: 0.5295 - val_loss: 1.0600 - val_acc: 0.4889\n","\n","Epoch 00002: val_acc did not improve from 0.48889\n","Epoch 3/100\n","16/16 [==============================] - 1s 55ms/step - loss: 1.0308 - acc: 0.5124 - val_loss: 1.0338 - val_acc: 0.4889\n","\n","Epoch 00003: val_acc did not improve from 0.48889\n","Epoch 4/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.9667 - acc: 0.5551 - val_loss: 1.0432 - val_acc: 0.5444\n","\n","Epoch 00004: val_acc improved from 0.48889 to 0.54444, saving model to result/left-right/OUR6-22/epoch-04-val-acc-0.5444.hdf5\n","Epoch 5/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.9434 - acc: 0.5851 - val_loss: 0.9169 - val_acc: 0.5333\n","\n","Epoch 00005: val_acc did not improve from 0.54444\n","Epoch 6/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.8152 - acc: 0.6425 - val_loss: 0.9343 - val_acc: 0.5889\n","\n","Epoch 00006: val_acc improved from 0.54444 to 0.58889, saving model to result/left-right/OUR6-22/epoch-06-val-acc-0.5889.hdf5\n","Epoch 7/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.6934 - acc: 0.6894 - val_loss: 0.6813 - val_acc: 0.6889\n","\n","Epoch 00007: val_acc improved from 0.58889 to 0.68889, saving model to result/left-right/OUR6-22/epoch-07-val-acc-0.6889.hdf5\n","Epoch 8/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.5608 - acc: 0.7667 - val_loss: 0.6437 - val_acc: 0.7444\n","\n","Epoch 00008: val_acc improved from 0.68889 to 0.74444, saving model to result/left-right/OUR6-22/epoch-08-val-acc-0.7444.hdf5\n","Epoch 9/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.4672 - acc: 0.8302 - val_loss: 0.5601 - val_acc: 0.7667\n","\n","Epoch 00009: val_acc improved from 0.74444 to 0.76667, saving model to result/left-right/OUR6-22/epoch-09-val-acc-0.7667.hdf5\n","Epoch 10/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.3340 - acc: 0.8803 - val_loss: 0.6090 - val_acc: 0.8111\n","\n","Epoch 00010: val_acc improved from 0.76667 to 0.81111, saving model to result/left-right/OUR6-22/epoch-10-val-acc-0.8111.hdf5\n","Epoch 11/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.2331 - acc: 0.9121 - val_loss: 0.6472 - val_acc: 0.7889\n","\n","Epoch 00011: val_acc did not improve from 0.81111\n","Epoch 12/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.1999 - acc: 0.9279 - val_loss: 0.5297 - val_acc: 0.8111\n","\n","Epoch 00012: val_acc did not improve from 0.81111\n","Epoch 13/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.1088 - acc: 0.9600 - val_loss: 0.7826 - val_acc: 0.8000\n","\n","Epoch 00013: val_acc did not improve from 0.81111\n","Epoch 14/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.1015 - acc: 0.9616 - val_loss: 0.6614 - val_acc: 0.7778\n","\n","Epoch 00014: val_acc did not improve from 0.81111\n","Epoch 15/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0729 - acc: 0.9681 - val_loss: 0.6842 - val_acc: 0.7889\n","\n","Epoch 00015: val_acc did not improve from 0.81111\n","Epoch 16/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0707 - acc: 0.9768 - val_loss: 0.7861 - val_acc: 0.8111\n","\n","Epoch 00016: val_acc improved from 0.81111 to 0.81111, saving model to result/left-right/OUR6-22/epoch-16-val-acc-0.8111.hdf5\n","Epoch 17/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0669 - acc: 0.9785 - val_loss: 0.7138 - val_acc: 0.8000\n","\n","Epoch 00017: val_acc did not improve from 0.81111\n","Epoch 18/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0681 - acc: 0.9794 - val_loss: 0.8558 - val_acc: 0.8111\n","\n","Epoch 00018: val_acc did not improve from 0.81111\n","Epoch 19/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0497 - acc: 0.9857 - val_loss: 0.8666 - val_acc: 0.8111\n","\n","Epoch 00019: val_acc did not improve from 0.81111\n","Epoch 20/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0226 - acc: 0.9910 - val_loss: 0.9391 - val_acc: 0.8222\n","\n","Epoch 00020: val_acc improved from 0.81111 to 0.82222, saving model to result/left-right/OUR6-22/epoch-20-val-acc-0.8222.hdf5\n","Epoch 21/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0374 - acc: 0.9857 - val_loss: 1.0365 - val_acc: 0.8111\n","\n","Epoch 00021: val_acc did not improve from 0.82222\n","Epoch 22/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0598 - acc: 0.9808 - val_loss: 0.9728 - val_acc: 0.7778\n","\n","Epoch 00022: val_acc did not improve from 0.82222\n","Epoch 23/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0471 - acc: 0.9822 - val_loss: 0.7574 - val_acc: 0.8111\n","\n","Epoch 00023: val_acc did not improve from 0.82222\n","Epoch 24/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0265 - acc: 0.9936 - val_loss: 1.0754 - val_acc: 0.8111\n","\n","Epoch 00024: val_acc did not improve from 0.82222\n","Epoch 25/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0371 - acc: 0.9871 - val_loss: 0.8088 - val_acc: 0.8111\n","\n","Epoch 00025: val_acc did not improve from 0.82222\n","Epoch 26/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0164 - acc: 0.9941 - val_loss: 1.0378 - val_acc: 0.8222\n","\n","Epoch 00026: val_acc improved from 0.82222 to 0.82222, saving model to result/left-right/OUR6-22/epoch-26-val-acc-0.8222.hdf5\n","Epoch 27/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0163 - acc: 0.9946 - val_loss: 0.9813 - val_acc: 0.8444\n","\n","Epoch 00027: val_acc improved from 0.82222 to 0.84444, saving model to result/left-right/OUR6-22/epoch-27-val-acc-0.8444.hdf5\n","Epoch 28/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0227 - acc: 0.9940 - val_loss: 1.0502 - val_acc: 0.8556\n","\n","Epoch 00028: val_acc improved from 0.84444 to 0.85556, saving model to result/left-right/OUR6-22/epoch-28-val-acc-0.8556.hdf5\n","Epoch 29/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0170 - acc: 0.9936 - val_loss: 1.0467 - val_acc: 0.8222\n","\n","Epoch 00029: val_acc did not improve from 0.85556\n","Epoch 30/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0250 - acc: 0.9936 - val_loss: 1.2400 - val_acc: 0.8000\n","\n","Epoch 00030: val_acc did not improve from 0.85556\n","Epoch 31/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0332 - acc: 0.9866 - val_loss: 1.0993 - val_acc: 0.8333\n","\n","Epoch 00031: val_acc did not improve from 0.85556\n","Epoch 32/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0510 - acc: 0.9821 - val_loss: 0.9032 - val_acc: 0.7889\n","\n","Epoch 00032: val_acc did not improve from 0.85556\n","Epoch 33/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0635 - acc: 0.9797 - val_loss: 1.1540 - val_acc: 0.7667\n","\n","Epoch 00033: val_acc did not improve from 0.85556\n","Epoch 34/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0381 - acc: 0.9862 - val_loss: 1.2319 - val_acc: 0.7667\n","\n","Epoch 00034: val_acc did not improve from 0.85556\n","Epoch 35/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0866 - acc: 0.9716 - val_loss: 1.1968 - val_acc: 0.8000\n","\n","Epoch 00035: val_acc did not improve from 0.85556\n","Epoch 36/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0919 - acc: 0.9659 - val_loss: 1.3658 - val_acc: 0.7444\n","\n","Epoch 00036: val_acc did not improve from 0.85556\n","Epoch 37/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.1075 - acc: 0.9695 - val_loss: 1.0104 - val_acc: 0.7556\n","\n","Epoch 00037: val_acc did not improve from 0.85556\n","Epoch 38/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0398 - acc: 0.9843 - val_loss: 0.9408 - val_acc: 0.8000\n","\n","Epoch 00038: val_acc did not improve from 0.85556\n","Epoch 39/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0350 - acc: 0.9891 - val_loss: 1.0968 - val_acc: 0.8111\n","\n","Epoch 00039: val_acc did not improve from 0.85556\n","Epoch 40/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0184 - acc: 0.9926 - val_loss: 1.1530 - val_acc: 0.7889\n","\n","Epoch 00040: val_acc did not improve from 0.85556\n","Epoch 41/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0322 - acc: 0.9887 - val_loss: 1.1017 - val_acc: 0.7889\n","\n","Epoch 00041: val_acc did not improve from 0.85556\n","Epoch 42/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0184 - acc: 0.9916 - val_loss: 0.9695 - val_acc: 0.8111\n","\n","Epoch 00042: val_acc did not improve from 0.85556\n","Epoch 43/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0122 - acc: 0.9961 - val_loss: 1.1051 - val_acc: 0.7889\n","\n","Epoch 00043: val_acc did not improve from 0.85556\n","Epoch 44/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0050 - acc: 0.9990 - val_loss: 1.2030 - val_acc: 0.7667\n","\n","Epoch 00044: val_acc did not improve from 0.85556\n","Epoch 45/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0104 - acc: 0.9930 - val_loss: 1.3077 - val_acc: 0.7778\n","\n","Epoch 00045: val_acc did not improve from 0.85556\n","Epoch 46/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 1.2448 - val_acc: 0.7667\n","\n","Epoch 00046: val_acc did not improve from 0.85556\n","Epoch 47/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0051 - acc: 0.9980 - val_loss: 1.2234 - val_acc: 0.7667\n","\n","Epoch 00047: val_acc did not improve from 0.85556\n","Epoch 48/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 1.3447 - val_acc: 0.7667\n","\n","Epoch 00048: val_acc did not improve from 0.85556\n","Epoch 49/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0192 - acc: 0.9945 - val_loss: 1.2852 - val_acc: 0.7778\n","\n","Epoch 00049: val_acc did not improve from 0.85556\n","Epoch 50/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0057 - acc: 0.9980 - val_loss: 0.9919 - val_acc: 0.8000\n","\n","Epoch 00050: val_acc did not improve from 0.85556\n","Epoch 51/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0083 - acc: 0.9980 - val_loss: 1.0867 - val_acc: 0.7556\n","\n","Epoch 00051: val_acc did not improve from 0.85556\n","Epoch 52/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0044 - acc: 0.9980 - val_loss: 0.9960 - val_acc: 0.7778\n","\n","Epoch 00052: val_acc did not improve from 0.85556\n","Epoch 53/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0125 - acc: 0.9951 - val_loss: 1.0591 - val_acc: 0.7889\n","\n","Epoch 00053: val_acc did not improve from 0.85556\n","Epoch 54/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0187 - acc: 0.9965 - val_loss: 1.0858 - val_acc: 0.7889\n","\n","Epoch 00054: val_acc did not improve from 0.85556\n","Epoch 55/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0158 - acc: 0.9961 - val_loss: 1.2258 - val_acc: 0.7778\n","\n","Epoch 00055: val_acc did not improve from 0.85556\n","Epoch 56/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.8752 - val_acc: 0.8222\n","\n","Epoch 00056: val_acc did not improve from 0.85556\n","Epoch 57/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 1.1096 - val_acc: 0.8000\n","\n","Epoch 00057: val_acc did not improve from 0.85556\n","Epoch 58/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0032 - acc: 0.9980 - val_loss: 1.1080 - val_acc: 0.8222\n","\n","Epoch 00058: val_acc did not improve from 0.85556\n","Epoch 59/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0089 - acc: 0.9965 - val_loss: 1.1823 - val_acc: 0.8000\n","\n","Epoch 00059: val_acc did not improve from 0.85556\n","Epoch 60/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0137 - acc: 0.9980 - val_loss: 1.1714 - val_acc: 0.7556\n","\n","Epoch 00060: val_acc did not improve from 0.85556\n","Epoch 61/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0035 - acc: 0.9990 - val_loss: 1.1705 - val_acc: 0.8111\n","\n","Epoch 00061: val_acc did not improve from 0.85556\n","Epoch 62/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0025 - acc: 0.9985 - val_loss: 1.2906 - val_acc: 0.8111\n","\n","Epoch 00062: val_acc did not improve from 0.85556\n","Epoch 63/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.3356 - val_acc: 0.8111\n","\n","Epoch 00063: val_acc did not improve from 0.85556\n","Epoch 64/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0090 - acc: 0.9971 - val_loss: 1.3117 - val_acc: 0.7667\n","\n","Epoch 00064: val_acc did not improve from 0.85556\n","Epoch 65/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0049 - acc: 0.9975 - val_loss: 1.1892 - val_acc: 0.7556\n","\n","Epoch 00065: val_acc did not improve from 0.85556\n","Epoch 66/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0113 - acc: 0.9965 - val_loss: 0.9739 - val_acc: 0.7889\n","\n","Epoch 00066: val_acc did not improve from 0.85556\n","Epoch 67/100\n","16/16 [==============================] - 1s 59ms/step - loss: 0.0173 - acc: 0.9922 - val_loss: 1.0692 - val_acc: 0.8333\n","\n","Epoch 00067: val_acc did not improve from 0.85556\n","Epoch 68/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0178 - acc: 0.9936 - val_loss: 1.4708 - val_acc: 0.7889\n","\n","Epoch 00068: val_acc did not improve from 0.85556\n","Epoch 69/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0221 - acc: 0.9915 - val_loss: 1.2032 - val_acc: 0.8222\n","\n","Epoch 00069: val_acc did not improve from 0.85556\n","Epoch 70/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0297 - acc: 0.9906 - val_loss: 1.3190 - val_acc: 0.7889\n","\n","Epoch 00070: val_acc did not improve from 0.85556\n","Epoch 71/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0145 - acc: 0.9951 - val_loss: 1.4783 - val_acc: 0.8111\n","\n","Epoch 00071: val_acc did not improve from 0.85556\n","Epoch 72/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0094 - acc: 0.9955 - val_loss: 1.6096 - val_acc: 0.7778\n","\n","Epoch 00072: val_acc did not improve from 0.85556\n","Epoch 73/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0061 - acc: 0.9980 - val_loss: 1.6708 - val_acc: 0.7667\n","\n","Epoch 00073: val_acc did not improve from 0.85556\n","Epoch 74/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0184 - acc: 0.9959 - val_loss: 1.5725 - val_acc: 0.7778\n","\n","Epoch 00074: val_acc did not improve from 0.85556\n","Epoch 75/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0162 - acc: 0.9941 - val_loss: 1.3212 - val_acc: 0.8000\n","\n","Epoch 00075: val_acc did not improve from 0.85556\n","Epoch 76/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0261 - acc: 0.9941 - val_loss: 1.1960 - val_acc: 0.8111\n","\n","Epoch 00076: val_acc did not improve from 0.85556\n","Epoch 77/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0165 - acc: 0.9951 - val_loss: 1.6496 - val_acc: 0.7333\n","\n","Epoch 00077: val_acc did not improve from 0.85556\n","Epoch 78/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0181 - acc: 0.9931 - val_loss: 1.2417 - val_acc: 0.8000\n","\n","Epoch 00078: val_acc did not improve from 0.85556\n","Epoch 79/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0381 - acc: 0.9877 - val_loss: 1.3895 - val_acc: 0.7667\n","\n","Epoch 00079: val_acc did not improve from 0.85556\n","Epoch 80/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0274 - acc: 0.9916 - val_loss: 1.2556 - val_acc: 0.8111\n","\n","Epoch 00080: val_acc did not improve from 0.85556\n","Epoch 81/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0295 - acc: 0.9901 - val_loss: 1.2205 - val_acc: 0.8000\n","\n","Epoch 00081: val_acc did not improve from 0.85556\n","Epoch 82/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0196 - acc: 0.9951 - val_loss: 1.2145 - val_acc: 0.8111\n","\n","Epoch 00082: val_acc did not improve from 0.85556\n","Epoch 83/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0255 - acc: 0.9961 - val_loss: 1.3781 - val_acc: 0.7667\n","\n","Epoch 00083: val_acc did not improve from 0.85556\n","Epoch 84/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0059 - acc: 0.9980 - val_loss: 1.1764 - val_acc: 0.8000\n","\n","Epoch 00084: val_acc did not improve from 0.85556\n","Epoch 85/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0041 - acc: 0.9990 - val_loss: 1.4923 - val_acc: 0.8000\n","\n","Epoch 00085: val_acc did not improve from 0.85556\n","Epoch 86/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0075 - acc: 0.9980 - val_loss: 1.1686 - val_acc: 0.8111\n","\n","Epoch 00086: val_acc did not improve from 0.85556\n","Epoch 87/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.1258 - val_acc: 0.8222\n","\n","Epoch 00087: val_acc did not improve from 0.85556\n","Epoch 88/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0047 - acc: 0.9985 - val_loss: 1.0052 - val_acc: 0.8000\n","\n","Epoch 00088: val_acc did not improve from 0.85556\n","Epoch 89/100\n","16/16 [==============================] - 1s 59ms/step - loss: 0.0040 - acc: 0.9990 - val_loss: 1.1846 - val_acc: 0.7889\n","\n","Epoch 00089: val_acc did not improve from 0.85556\n","Epoch 90/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0042 - acc: 0.9990 - val_loss: 1.1476 - val_acc: 0.7556\n","\n","Epoch 00090: val_acc did not improve from 0.85556\n","Epoch 91/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0080 - acc: 0.9971 - val_loss: 1.2760 - val_acc: 0.7556\n","\n","Epoch 00091: val_acc did not improve from 0.85556\n","Epoch 92/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0096 - acc: 0.9961 - val_loss: 1.0236 - val_acc: 0.8111\n","\n","Epoch 00092: val_acc did not improve from 0.85556\n","Epoch 93/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0081 - acc: 0.9971 - val_loss: 0.9617 - val_acc: 0.8222\n","\n","Epoch 00093: val_acc did not improve from 0.85556\n","Epoch 94/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0075 - acc: 0.9980 - val_loss: 1.1570 - val_acc: 0.7889\n","\n","Epoch 00094: val_acc did not improve from 0.85556\n","Epoch 95/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0116 - acc: 0.9990 - val_loss: 1.3353 - val_acc: 0.7333\n","\n","Epoch 00095: val_acc did not improve from 0.85556\n","Epoch 96/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0080 - acc: 0.9965 - val_loss: 1.3435 - val_acc: 0.7444\n","\n","Epoch 00096: val_acc did not improve from 0.85556\n","Epoch 97/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0211 - acc: 0.9955 - val_loss: 1.1619 - val_acc: 0.7667\n","\n","Epoch 00097: val_acc did not improve from 0.85556\n","Epoch 98/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0094 - acc: 0.9941 - val_loss: 1.3173 - val_acc: 0.8111\n","\n","Epoch 00098: val_acc did not improve from 0.85556\n","Epoch 99/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0066 - acc: 0.9980 - val_loss: 1.4496 - val_acc: 0.8000\n","\n","Epoch 00099: val_acc did not improve from 0.85556\n","Epoch 100/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0018 - acc: 0.9990 - val_loss: 1.4568 - val_acc: 0.7889\n","\n","Epoch 00100: val_acc did not improve from 0.85556\n","\n","<keras.callbacks.History at 0x7ff6852f6f60>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LWIUhStWQe1Z","colab_type":"code","colab":{}},"cell_type":"code","source":["#left-right 84 our 6 20\n","\n","\n","\n","Epoch 1/100\n","16/16 [==============================] - 1s 91ms/step - loss: 1.0537 - acc: 0.4881 - val_loss: 1.0389 - val_acc: 0.4889\n","\n","Epoch 00001: val_acc improved from -inf to 0.48889, saving model to result/left-right/OUR6-20/epoch-01-val-acc-0.4889.hdf5\n","Epoch 2/100\n","16/16 [==============================] - 1s 60ms/step - loss: 1.0414 - acc: 0.5081 - val_loss: 1.0584 - val_acc: 0.4889\n","\n","Epoch 00002: val_acc did not improve from 0.48889\n","Epoch 3/100\n","16/16 [==============================] - 1s 56ms/step - loss: 1.0394 - acc: 0.5184 - val_loss: 1.0758 - val_acc: 0.4889\n","\n","Epoch 00003: val_acc did not improve from 0.48889\n","Epoch 4/100\n","16/16 [==============================] - 1s 55ms/step - loss: 1.0282 - acc: 0.5219 - val_loss: 1.0412 - val_acc: 0.5222\n","\n","Epoch 00004: val_acc improved from 0.48889 to 0.52222, saving model to result/left-right/OUR6-20/epoch-04-val-acc-0.5222.hdf5\n","Epoch 5/100\n","16/16 [==============================] - 1s 55ms/step - loss: 1.0357 - acc: 0.5102 - val_loss: 1.0468 - val_acc: 0.4889\n","\n","Epoch 00005: val_acc did not improve from 0.52222\n","Epoch 6/100\n","16/16 [==============================] - 1s 55ms/step - loss: 1.0261 - acc: 0.5287 - val_loss: 1.0325 - val_acc: 0.5333\n","\n","Epoch 00006: val_acc improved from 0.52222 to 0.53333, saving model to result/left-right/OUR6-20/epoch-06-val-acc-0.5333.hdf5\n","Epoch 7/100\n","16/16 [==============================] - 1s 53ms/step - loss: 1.0090 - acc: 0.5207 - val_loss: 1.0197 - val_acc: 0.5000\n","\n","Epoch 00007: val_acc did not improve from 0.53333\n","Epoch 8/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.9506 - acc: 0.5604 - val_loss: 0.8902 - val_acc: 0.6111\n","\n","Epoch 00008: val_acc improved from 0.53333 to 0.61111, saving model to result/left-right/OUR6-20/epoch-08-val-acc-0.6111.hdf5\n","Epoch 9/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.8168 - acc: 0.6493 - val_loss: 0.7135 - val_acc: 0.6778\n","\n","Epoch 00009: val_acc improved from 0.61111 to 0.67778, saving model to result/left-right/OUR6-20/epoch-09-val-acc-0.6778.hdf5\n","Epoch 10/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.6484 - acc: 0.7410 - val_loss: 0.6342 - val_acc: 0.7222\n","\n","Epoch 00010: val_acc improved from 0.67778 to 0.72222, saving model to result/left-right/OUR6-20/epoch-10-val-acc-0.7222.hdf5\n","Epoch 11/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.5574 - acc: 0.7599 - val_loss: 0.5192 - val_acc: 0.7889\n","\n","Epoch 00011: val_acc improved from 0.72222 to 0.78889, saving model to result/left-right/OUR6-20/epoch-11-val-acc-0.7889.hdf5\n","Epoch 12/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.4059 - acc: 0.8374 - val_loss: 0.5088 - val_acc: 0.8111\n","\n","Epoch 00012: val_acc improved from 0.78889 to 0.81111, saving model to result/left-right/OUR6-20/epoch-12-val-acc-0.8111.hdf5\n","Epoch 13/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.2916 - acc: 0.8929 - val_loss: 0.6453 - val_acc: 0.7222\n","\n","Epoch 00013: val_acc did not improve from 0.81111\n","Epoch 14/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.1962 - acc: 0.9301 - val_loss: 0.6409 - val_acc: 0.8000\n","\n","Epoch 00014: val_acc did not improve from 0.81111\n","Epoch 15/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.1745 - acc: 0.9389 - val_loss: 0.6962 - val_acc: 0.7667\n","\n","Epoch 00015: val_acc did not improve from 0.81111\n","Epoch 16/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.1350 - acc: 0.9506 - val_loss: 0.5333 - val_acc: 0.8111\n","\n","Epoch 00016: val_acc did not improve from 0.81111\n","Epoch 17/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.1005 - acc: 0.9665 - val_loss: 0.5192 - val_acc: 0.8111\n","\n","Epoch 00017: val_acc improved from 0.81111 to 0.81111, saving model to result/left-right/OUR6-20/epoch-17-val-acc-0.8111.hdf5\n","Epoch 18/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0963 - acc: 0.9642 - val_loss: 0.7006 - val_acc: 0.8111\n","\n","Epoch 00018: val_acc did not improve from 0.81111\n","Epoch 19/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.1121 - acc: 0.9693 - val_loss: 0.5860 - val_acc: 0.8222\n","\n","Epoch 00019: val_acc improved from 0.81111 to 0.82222, saving model to result/left-right/OUR6-20/epoch-19-val-acc-0.8222.hdf5\n","Epoch 20/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0780 - acc: 0.9718 - val_loss: 0.5352 - val_acc: 0.8444\n","\n","Epoch 00020: val_acc improved from 0.82222 to 0.84444, saving model to result/left-right/OUR6-20/epoch-20-val-acc-0.8444.hdf5\n","Epoch 21/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0662 - acc: 0.9712 - val_loss: 0.5746 - val_acc: 0.8333\n","\n","Epoch 00021: val_acc did not improve from 0.84444\n","Epoch 22/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0568 - acc: 0.9764 - val_loss: 0.5790 - val_acc: 0.8444\n","\n","Epoch 00022: val_acc improved from 0.84444 to 0.84444, saving model to result/left-right/OUR6-20/epoch-22-val-acc-0.8444.hdf5\n","Epoch 23/100\n","16/16 [==============================] - 1s 59ms/step - loss: 0.0485 - acc: 0.9807 - val_loss: 0.5811 - val_acc: 0.8333\n","\n","Epoch 00023: val_acc did not improve from 0.84444\n","Epoch 24/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0522 - acc: 0.9827 - val_loss: 0.8048 - val_acc: 0.7556\n","\n","Epoch 00024: val_acc did not improve from 0.84444\n","Epoch 25/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0426 - acc: 0.9843 - val_loss: 0.8630 - val_acc: 0.7778\n","\n","Epoch 00025: val_acc did not improve from 0.84444\n","Epoch 26/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0249 - acc: 0.9936 - val_loss: 0.8605 - val_acc: 0.8000\n","\n","Epoch 00026: val_acc did not improve from 0.84444\n","Epoch 27/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0400 - acc: 0.9852 - val_loss: 0.8646 - val_acc: 0.8111\n","\n","Epoch 00027: val_acc did not improve from 0.84444\n","Epoch 28/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0218 - acc: 0.9926 - val_loss: 0.8813 - val_acc: 0.7889\n","\n","Epoch 00028: val_acc did not improve from 0.84444\n","Epoch 29/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0364 - acc: 0.9906 - val_loss: 0.7885 - val_acc: 0.8000\n","\n","Epoch 00029: val_acc did not improve from 0.84444\n","Epoch 30/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0175 - acc: 0.9922 - val_loss: 0.9383 - val_acc: 0.8222\n","\n","Epoch 00030: val_acc did not improve from 0.84444\n","Epoch 31/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0215 - acc: 0.9946 - val_loss: 0.9043 - val_acc: 0.7889\n","\n","Epoch 00031: val_acc did not improve from 0.84444\n","Epoch 32/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0242 - acc: 0.9916 - val_loss: 0.8223 - val_acc: 0.8222\n","\n","Epoch 00032: val_acc did not improve from 0.84444\n","Epoch 33/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0127 - acc: 0.9971 - val_loss: 1.0185 - val_acc: 0.7778\n","\n","Epoch 00033: val_acc did not improve from 0.84444\n","Epoch 34/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0085 - acc: 0.9975 - val_loss: 1.0239 - val_acc: 0.8111\n","\n","Epoch 00034: val_acc did not improve from 0.84444\n","Epoch 35/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0327 - acc: 0.9881 - val_loss: 1.1622 - val_acc: 0.7556\n","\n","Epoch 00035: val_acc did not improve from 0.84444\n","Epoch 36/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0270 - acc: 0.9912 - val_loss: 0.8657 - val_acc: 0.7889\n","\n","Epoch 00036: val_acc did not improve from 0.84444\n","Epoch 37/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0412 - acc: 0.9916 - val_loss: 0.9424 - val_acc: 0.7778\n","\n","Epoch 00037: val_acc did not improve from 0.84444\n","Epoch 38/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0132 - acc: 0.9961 - val_loss: 0.7965 - val_acc: 0.8222\n","\n","Epoch 00038: val_acc did not improve from 0.84444\n","Epoch 39/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0091 - acc: 0.9971 - val_loss: 0.8689 - val_acc: 0.8333\n","\n","Epoch 00039: val_acc did not improve from 0.84444\n","Epoch 40/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0071 - acc: 0.9990 - val_loss: 0.9672 - val_acc: 0.8000\n","\n","Epoch 00040: val_acc did not improve from 0.84444\n","Epoch 41/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0069 - acc: 0.9971 - val_loss: 0.9939 - val_acc: 0.7778\n","\n","Epoch 00041: val_acc did not improve from 0.84444\n","Epoch 42/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0097 - acc: 0.9961 - val_loss: 0.8825 - val_acc: 0.8000\n","\n","Epoch 00042: val_acc did not improve from 0.84444\n","Epoch 43/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0166 - acc: 0.9941 - val_loss: 1.0638 - val_acc: 0.8000\n","\n","Epoch 00043: val_acc did not improve from 0.84444\n","Epoch 44/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0085 - acc: 0.9961 - val_loss: 0.8310 - val_acc: 0.8333\n","\n","Epoch 00044: val_acc did not improve from 0.84444\n","Epoch 45/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0249 - acc: 0.9945 - val_loss: 0.8723 - val_acc: 0.8222\n","\n","Epoch 00045: val_acc did not improve from 0.84444\n","Epoch 46/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0270 - acc: 0.9945 - val_loss: 0.7010 - val_acc: 0.8222\n","\n","Epoch 00046: val_acc did not improve from 0.84444\n","Epoch 47/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0198 - acc: 0.9961 - val_loss: 0.6970 - val_acc: 0.8444\n","\n","Epoch 00047: val_acc did not improve from 0.84444\n","Epoch 48/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0105 - acc: 0.9961 - val_loss: 0.7673 - val_acc: 0.8333\n","\n","Epoch 00048: val_acc did not improve from 0.84444\n","Epoch 49/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0115 - acc: 0.9971 - val_loss: 1.0023 - val_acc: 0.8000\n","\n","Epoch 00049: val_acc did not improve from 0.84444\n","Epoch 50/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.1139 - val_acc: 0.7778\n","\n","Epoch 00050: val_acc did not improve from 0.84444\n","Epoch 51/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0084 - acc: 0.9971 - val_loss: 1.0744 - val_acc: 0.8000\n","\n","Epoch 00051: val_acc did not improve from 0.84444\n","Epoch 52/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0119 - acc: 0.9955 - val_loss: 0.9592 - val_acc: 0.8111\n","\n","Epoch 00052: val_acc did not improve from 0.84444\n","Epoch 53/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0095 - acc: 0.9955 - val_loss: 1.0308 - val_acc: 0.8111\n","\n","Epoch 00053: val_acc did not improve from 0.84444\n","Epoch 54/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0056 - acc: 0.9980 - val_loss: 1.0915 - val_acc: 0.7889\n","\n","Epoch 00054: val_acc did not improve from 0.84444\n","Epoch 55/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.1532 - val_acc: 0.8000\n","\n","Epoch 00055: val_acc did not improve from 0.84444\n","Epoch 56/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0079 - acc: 0.9980 - val_loss: 1.1290 - val_acc: 0.7778\n","\n","Epoch 00056: val_acc did not improve from 0.84444\n","Epoch 57/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0100 - acc: 0.9960 - val_loss: 1.1765 - val_acc: 0.7778\n","\n","Epoch 00057: val_acc did not improve from 0.84444\n","Epoch 58/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0092 - acc: 0.9980 - val_loss: 1.4036 - val_acc: 0.7667\n","\n","Epoch 00058: val_acc did not improve from 0.84444\n","Epoch 59/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0121 - acc: 0.9971 - val_loss: 0.9747 - val_acc: 0.8222\n","\n","Epoch 00059: val_acc did not improve from 0.84444\n","Epoch 60/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0075 - acc: 0.9971 - val_loss: 1.0312 - val_acc: 0.7667\n","\n","Epoch 00060: val_acc did not improve from 0.84444\n","Epoch 61/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0211 - acc: 0.9951 - val_loss: 0.9117 - val_acc: 0.8222\n","\n","Epoch 00061: val_acc did not improve from 0.84444\n","Epoch 62/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0358 - acc: 0.9916 - val_loss: 1.3492 - val_acc: 0.7556\n","\n","Epoch 00062: val_acc did not improve from 0.84444\n","Epoch 63/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0300 - acc: 0.9873 - val_loss: 0.9008 - val_acc: 0.8222\n","\n","Epoch 00063: val_acc did not improve from 0.84444\n","Epoch 64/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0426 - acc: 0.9867 - val_loss: 1.0171 - val_acc: 0.8111\n","\n","Epoch 00064: val_acc did not improve from 0.84444\n","Epoch 65/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0184 - acc: 0.9936 - val_loss: 0.9868 - val_acc: 0.7889\n","\n","Epoch 00065: val_acc did not improve from 0.84444\n","Epoch 66/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0216 - acc: 0.9905 - val_loss: 1.3199 - val_acc: 0.7667\n","\n","Epoch 00066: val_acc did not improve from 0.84444\n","Epoch 67/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0369 - acc: 0.9887 - val_loss: 1.2013 - val_acc: 0.7778\n","\n","Epoch 00067: val_acc did not improve from 0.84444\n","Epoch 68/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0212 - acc: 0.9906 - val_loss: 1.0541 - val_acc: 0.7667\n","\n","Epoch 00068: val_acc did not improve from 0.84444\n","Epoch 69/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0151 - acc: 0.9941 - val_loss: 1.4534 - val_acc: 0.7889\n","\n","Epoch 00069: val_acc did not improve from 0.84444\n","Epoch 70/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0451 - acc: 0.9866 - val_loss: 1.3364 - val_acc: 0.8000\n","\n","Epoch 00070: val_acc did not improve from 0.84444\n","Epoch 71/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0484 - acc: 0.9876 - val_loss: 0.9796 - val_acc: 0.7667\n","\n","Epoch 00071: val_acc did not improve from 0.84444\n","Epoch 72/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0843 - acc: 0.9747 - val_loss: 1.0997 - val_acc: 0.7778\n","\n","Epoch 00072: val_acc did not improve from 0.84444\n","Epoch 73/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0252 - acc: 0.9896 - val_loss: 0.9927 - val_acc: 0.8111\n","\n","Epoch 00073: val_acc did not improve from 0.84444\n","Epoch 74/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0443 - acc: 0.9836 - val_loss: 0.7330 - val_acc: 0.8444\n","\n","Epoch 00074: val_acc improved from 0.84444 to 0.84444, saving model to result/left-right/OUR6-20/epoch-74-val-acc-0.8444.hdf5\n","Epoch 75/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0354 - acc: 0.9867 - val_loss: 1.0844 - val_acc: 0.7667\n","\n","Epoch 00075: val_acc did not improve from 0.84444\n","Epoch 76/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0414 - acc: 0.9877 - val_loss: 1.1447 - val_acc: 0.7778\n","\n","Epoch 00076: val_acc did not improve from 0.84444\n","Epoch 77/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0172 - acc: 0.9951 - val_loss: 0.9843 - val_acc: 0.8222\n","\n","Epoch 00077: val_acc did not improve from 0.84444\n","Epoch 78/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0149 - acc: 0.9926 - val_loss: 1.1378 - val_acc: 0.8111\n","\n","Epoch 00078: val_acc did not improve from 0.84444\n","Epoch 79/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0167 - acc: 0.9971 - val_loss: 1.5426 - val_acc: 0.7444\n","\n","Epoch 00079: val_acc did not improve from 0.84444\n","Epoch 80/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0145 - acc: 0.9965 - val_loss: 1.2331 - val_acc: 0.8000\n","\n","Epoch 00080: val_acc did not improve from 0.84444\n","Epoch 81/100\n","16/16 [==============================] - 1s 52ms/step - loss: 0.0022 - acc: 0.9990 - val_loss: 1.2030 - val_acc: 0.8111\n","\n","Epoch 00081: val_acc did not improve from 0.84444\n","Epoch 82/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0039 - acc: 0.9990 - val_loss: 1.1815 - val_acc: 0.8222\n","\n","Epoch 00082: val_acc did not improve from 0.84444\n","Epoch 83/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0021 - acc: 0.9990 - val_loss: 1.1316 - val_acc: 0.8111\n","\n","Epoch 00083: val_acc did not improve from 0.84444\n","Epoch 84/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0020 - acc: 0.9990 - val_loss: 1.1840 - val_acc: 0.8111\n","\n","Epoch 00084: val_acc did not improve from 0.84444\n","Epoch 85/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0022 - acc: 0.9990 - val_loss: 1.1005 - val_acc: 0.8111\n","\n","Epoch 00085: val_acc did not improve from 0.84444\n","Epoch 86/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0131 - acc: 0.9940 - val_loss: 1.4519 - val_acc: 0.7889\n","\n","Epoch 00086: val_acc did not improve from 0.84444\n","Epoch 87/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0107 - acc: 0.9980 - val_loss: 1.2893 - val_acc: 0.7556\n","\n","Epoch 00087: val_acc did not improve from 0.84444\n","Epoch 88/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0128 - acc: 0.9955 - val_loss: 1.1286 - val_acc: 0.7889\n","\n","Epoch 00088: val_acc did not improve from 0.84444\n","Epoch 89/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0099 - acc: 0.9961 - val_loss: 1.0129 - val_acc: 0.7778\n","\n","Epoch 00089: val_acc did not improve from 0.84444\n","Epoch 90/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0027 - acc: 0.9990 - val_loss: 1.1322 - val_acc: 0.7778\n","\n","Epoch 00090: val_acc did not improve from 0.84444\n","Epoch 91/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0078 - acc: 0.9971 - val_loss: 1.1660 - val_acc: 0.7889\n","\n","Epoch 00091: val_acc did not improve from 0.84444\n","Epoch 92/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0062 - acc: 0.9990 - val_loss: 1.2861 - val_acc: 0.7889\n","\n","Epoch 00092: val_acc did not improve from 0.84444\n","Epoch 93/100\n","16/16 [==============================] - 1s 53ms/step - loss: 0.0088 - acc: 0.9971 - val_loss: 1.3518 - val_acc: 0.7778\n","\n","Epoch 00093: val_acc did not improve from 0.84444\n","Epoch 94/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0212 - acc: 0.9941 - val_loss: 1.0378 - val_acc: 0.7889\n","\n","Epoch 00094: val_acc did not improve from 0.84444\n","Epoch 95/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 1.1022 - val_acc: 0.8000\n","\n","Epoch 00095: val_acc did not improve from 0.84444\n","Epoch 96/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.1078 - val_acc: 0.7778\n","\n","Epoch 00096: val_acc did not improve from 0.84444\n","Epoch 97/100\n","16/16 [==============================] - 1s 57ms/step - loss: 8.7397e-04 - acc: 1.0000 - val_loss: 1.0546 - val_acc: 0.8111\n","\n","Epoch 00097: val_acc did not improve from 0.84444\n","Epoch 98/100\n","16/16 [==============================] - 1s 55ms/step - loss: 4.1946e-04 - acc: 1.0000 - val_loss: 1.0246 - val_acc: 0.8222\n","\n","Epoch 00098: val_acc did not improve from 0.84444\n","Epoch 99/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0132 - acc: 0.9990 - val_loss: 1.1318 - val_acc: 0.8000\n","\n","Epoch 00099: val_acc did not improve from 0.84444\n","Epoch 100/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0065 - acc: 0.9971 - val_loss: 1.1461 - val_acc: 0.8111\n","\n","Epoch 00100: val_acc did not improve from 0.84444\n","\n","<keras.callbacks.History at 0x7ff69db99be0>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VcYuT0uPVvQU","colab_type":"code","cellView":"code","colab":{}},"cell_type":"code","source":["#@title Default title text\n","#left-right 82 our3-12\n","\n","\n","\n","Epoch 1/100\n","16/16 [==============================] - 2s 99ms/step - loss: 1.0666 - acc: 0.4336 - val_loss: 1.0860 - val_acc: 0.4889\n","\n","Epoch 00001: val_acc improved from -inf to 0.48889, saving model to result/left-right/OUR-3-12/epoch-01-val-acc-0.4889.hdf5\n","Epoch 2/100\n","16/16 [==============================] - 1s 75ms/step - loss: 1.0243 - acc: 0.5204 - val_loss: 1.0806 - val_acc: 0.4889\n","\n","Epoch 00002: val_acc did not improve from 0.48889\n","Epoch 3/100\n","16/16 [==============================] - 1s 68ms/step - loss: 1.0321 - acc: 0.5172 - val_loss: 1.0873 - val_acc: 0.4889\n","\n","Epoch 00003: val_acc did not improve from 0.48889\n","Epoch 4/100\n","16/16 [==============================] - 1s 67ms/step - loss: 1.0236 - acc: 0.5207 - val_loss: 1.0620 - val_acc: 0.4889\n","\n","Epoch 00004: val_acc did not improve from 0.48889\n","Epoch 5/100\n","16/16 [==============================] - 1s 71ms/step - loss: 1.0290 - acc: 0.5139 - val_loss: 1.0523 - val_acc: 0.4889\n","\n","Epoch 00005: val_acc did not improve from 0.48889\n","Epoch 6/100\n","16/16 [==============================] - 1s 68ms/step - loss: 1.0241 - acc: 0.5236 - val_loss: 1.0657 - val_acc: 0.4889\n","\n","Epoch 00006: val_acc did not improve from 0.48889\n","Epoch 7/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.0190 - acc: 0.5239 - val_loss: 1.0686 - val_acc: 0.4889\n","\n","Epoch 00007: val_acc did not improve from 0.48889\n","Epoch 8/100\n","16/16 [==============================] - 1s 67ms/step - loss: 1.0185 - acc: 0.5189 - val_loss: 1.1001 - val_acc: 0.4889\n","\n","Epoch 00008: val_acc did not improve from 0.48889\n","Epoch 9/100\n","16/16 [==============================] - 1s 68ms/step - loss: 1.0003 - acc: 0.5301 - val_loss: 0.9015 - val_acc: 0.5667\n","\n","Epoch 00009: val_acc improved from 0.48889 to 0.56667, saving model to result/left-right/OUR-3-12/epoch-09-val-acc-0.5667.hdf5\n","Epoch 10/100\n","16/16 [==============================] - 1s 68ms/step - loss: 0.8884 - acc: 0.5950 - val_loss: 0.8607 - val_acc: 0.5778\n","\n","Epoch 00010: val_acc improved from 0.56667 to 0.57778, saving model to result/left-right/OUR-3-12/epoch-10-val-acc-0.5778.hdf5\n","Epoch 11/100\n","16/16 [==============================] - 1s 68ms/step - loss: 0.8196 - acc: 0.6491 - val_loss: 0.7617 - val_acc: 0.6444\n","\n","Epoch 00011: val_acc improved from 0.57778 to 0.64444, saving model to result/left-right/OUR-3-12/epoch-11-val-acc-0.6444.hdf5\n","Epoch 12/100\n","16/16 [==============================] - 1s 70ms/step - loss: 0.7234 - acc: 0.6840 - val_loss: 0.7914 - val_acc: 0.6000\n","\n","Epoch 00012: val_acc did not improve from 0.64444\n","Epoch 13/100\n","16/16 [==============================] - 1s 68ms/step - loss: 0.5967 - acc: 0.7515 - val_loss: 0.7671 - val_acc: 0.6667\n","\n","Epoch 00013: val_acc improved from 0.64444 to 0.66667, saving model to result/left-right/OUR-3-12/epoch-13-val-acc-0.6667.hdf5\n","Epoch 14/100\n","16/16 [==============================] - 1s 68ms/step - loss: 0.4023 - acc: 0.8448 - val_loss: 0.5869 - val_acc: 0.7778\n","\n","Epoch 00014: val_acc improved from 0.66667 to 0.77778, saving model to result/left-right/OUR-3-12/epoch-14-val-acc-0.7778.hdf5\n","Epoch 15/100\n","16/16 [==============================] - 1s 66ms/step - loss: 0.3469 - acc: 0.8621 - val_loss: 0.7368 - val_acc: 0.7222\n","\n","Epoch 00015: val_acc did not improve from 0.77778\n","Epoch 16/100\n","16/16 [==============================] - 1s 66ms/step - loss: 0.2658 - acc: 0.8997 - val_loss: 0.6877 - val_acc: 0.8111\n","\n","Epoch 00016: val_acc improved from 0.77778 to 0.81111, saving model to result/left-right/OUR-3-12/epoch-16-val-acc-0.8111.hdf5\n","Epoch 17/100\n","16/16 [==============================] - 1s 68ms/step - loss: 0.0954 - acc: 0.9706 - val_loss: 1.0589 - val_acc: 0.8000\n","\n","Epoch 00017: val_acc did not improve from 0.81111\n","Epoch 18/100\n","16/16 [==============================] - 1s 67ms/step - loss: 0.0322 - acc: 0.9857 - val_loss: 1.3574 - val_acc: 0.7889\n","\n","Epoch 00018: val_acc did not improve from 0.81111\n","Epoch 19/100\n","16/16 [==============================] - 1s 66ms/step - loss: 0.0062 - acc: 0.9990 - val_loss: 1.6128 - val_acc: 0.7778\n","\n","Epoch 00019: val_acc did not improve from 0.81111\n","Epoch 20/100\n","16/16 [==============================] - 1s 68ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.6233 - val_acc: 0.8000\n","\n","Epoch 00020: val_acc did not improve from 0.81111\n","Epoch 21/100\n","16/16 [==============================] - 1s 66ms/step - loss: 2.2410e-04 - acc: 1.0000 - val_loss: 1.6711 - val_acc: 0.8000\n","\n","Epoch 00021: val_acc did not improve from 0.81111\n","Epoch 22/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.3153e-04 - acc: 1.0000 - val_loss: 1.7035 - val_acc: 0.8000\n","\n","Epoch 00022: val_acc did not improve from 0.81111\n","Epoch 23/100\n","16/16 [==============================] - 1s 68ms/step - loss: 1.0096e-04 - acc: 1.0000 - val_loss: 1.7287 - val_acc: 0.8111\n","\n","Epoch 00023: val_acc improved from 0.81111 to 0.81111, saving model to result/left-right/OUR-3-12/epoch-23-val-acc-0.8111.hdf5\n","Epoch 24/100\n","16/16 [==============================] - 1s 71ms/step - loss: 7.9998e-05 - acc: 1.0000 - val_loss: 1.7506 - val_acc: 0.8111\n","\n","Epoch 00024: val_acc did not improve from 0.81111\n","Epoch 25/100\n","16/16 [==============================] - 1s 69ms/step - loss: 6.9880e-05 - acc: 1.0000 - val_loss: 1.7676 - val_acc: 0.8111\n","\n","Epoch 00025: val_acc did not improve from 0.81111\n","Epoch 26/100\n","16/16 [==============================] - 1s 66ms/step - loss: 6.1108e-05 - acc: 1.0000 - val_loss: 1.7806 - val_acc: 0.8222\n","\n","Epoch 00026: val_acc improved from 0.81111 to 0.82222, saving model to result/left-right/OUR-3-12/epoch-26-val-acc-0.8222.hdf5\n","Epoch 27/100\n","16/16 [==============================] - 1s 74ms/step - loss: 5.4355e-05 - acc: 1.0000 - val_loss: 1.7914 - val_acc: 0.8222\n","\n","Epoch 00027: val_acc did not improve from 0.82222\n","Epoch 28/100\n","16/16 [==============================] - 1s 69ms/step - loss: 4.9568e-05 - acc: 1.0000 - val_loss: 1.8007 - val_acc: 0.8222\n","\n","Epoch 00028: val_acc did not improve from 0.82222\n","Epoch 29/100\n","16/16 [==============================] - 1s 69ms/step - loss: 4.5942e-05 - acc: 1.0000 - val_loss: 1.8089 - val_acc: 0.8222\n","\n","Epoch 00029: val_acc did not improve from 0.82222\n","Epoch 30/100\n","16/16 [==============================] - 1s 67ms/step - loss: 4.3745e-05 - acc: 1.0000 - val_loss: 1.8164 - val_acc: 0.8222\n","\n","Epoch 00030: val_acc did not improve from 0.82222\n","Epoch 31/100\n","16/16 [==============================] - 1s 67ms/step - loss: 3.7142e-05 - acc: 1.0000 - val_loss: 1.8237 - val_acc: 0.8222\n","\n","Epoch 00031: val_acc did not improve from 0.82222\n","Epoch 32/100\n","16/16 [==============================] - 1s 71ms/step - loss: 3.9658e-05 - acc: 1.0000 - val_loss: 1.8308 - val_acc: 0.8222\n","\n","Epoch 00032: val_acc did not improve from 0.82222\n","Epoch 33/100\n","16/16 [==============================] - 1s 68ms/step - loss: 3.1804e-05 - acc: 1.0000 - val_loss: 1.8369 - val_acc: 0.8222\n","\n","Epoch 00033: val_acc did not improve from 0.82222\n","Epoch 34/100\n","16/16 [==============================] - 1s 66ms/step - loss: 3.1339e-05 - acc: 1.0000 - val_loss: 1.8422 - val_acc: 0.8222\n","\n","Epoch 00034: val_acc did not improve from 0.82222\n","Epoch 35/100\n","16/16 [==============================] - 1s 67ms/step - loss: 2.9944e-05 - acc: 1.0000 - val_loss: 1.8468 - val_acc: 0.8222\n","\n","Epoch 00035: val_acc did not improve from 0.82222\n","Epoch 36/100\n","16/16 [==============================] - 1s 68ms/step - loss: 2.6904e-05 - acc: 1.0000 - val_loss: 1.8511 - val_acc: 0.8222\n","\n","Epoch 00036: val_acc did not improve from 0.82222\n","Epoch 37/100\n","16/16 [==============================] - 1s 70ms/step - loss: 2.5867e-05 - acc: 1.0000 - val_loss: 1.8550 - val_acc: 0.8222\n","\n","Epoch 00037: val_acc did not improve from 0.82222\n","Epoch 38/100\n","16/16 [==============================] - 1s 68ms/step - loss: 2.4618e-05 - acc: 1.0000 - val_loss: 1.8588 - val_acc: 0.8222\n","\n","Epoch 00038: val_acc did not improve from 0.82222\n","Epoch 39/100\n","16/16 [==============================] - 1s 71ms/step - loss: 2.2075e-05 - acc: 1.0000 - val_loss: 1.8626 - val_acc: 0.8222\n","\n","Epoch 00039: val_acc did not improve from 0.82222\n","Epoch 40/100\n","16/16 [==============================] - 1s 68ms/step - loss: 2.0638e-05 - acc: 1.0000 - val_loss: 1.8667 - val_acc: 0.8222\n","\n","Epoch 00040: val_acc did not improve from 0.82222\n","Epoch 41/100\n","16/16 [==============================] - 1s 66ms/step - loss: 2.1354e-05 - acc: 1.0000 - val_loss: 1.8701 - val_acc: 0.8222\n","\n","Epoch 00041: val_acc did not improve from 0.82222\n","Epoch 42/100\n","16/16 [==============================] - 1s 68ms/step - loss: 2.0088e-05 - acc: 1.0000 - val_loss: 1.8734 - val_acc: 0.8222\n","\n","Epoch 00042: val_acc did not improve from 0.82222\n","Epoch 43/100\n","16/16 [==============================] - 1s 71ms/step - loss: 1.9537e-05 - acc: 1.0000 - val_loss: 1.8767 - val_acc: 0.8222\n","\n","Epoch 00043: val_acc did not improve from 0.82222\n","Epoch 44/100\n","16/16 [==============================] - 1s 67ms/step - loss: 1.7608e-05 - acc: 1.0000 - val_loss: 1.8798 - val_acc: 0.8222\n","\n","Epoch 00044: val_acc did not improve from 0.82222\n","Epoch 45/100\n","16/16 [==============================] - 1s 67ms/step - loss: 1.6438e-05 - acc: 1.0000 - val_loss: 1.8830 - val_acc: 0.8222\n","\n","Epoch 00045: val_acc did not improve from 0.82222\n","Epoch 46/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.5691e-05 - acc: 1.0000 - val_loss: 1.8865 - val_acc: 0.8222\n","\n","Epoch 00046: val_acc did not improve from 0.82222\n","Epoch 47/100\n","16/16 [==============================] - 1s 68ms/step - loss: 1.6759e-05 - acc: 1.0000 - val_loss: 1.8897 - val_acc: 0.8222\n","\n","Epoch 00047: val_acc did not improve from 0.82222\n","Epoch 48/100\n","16/16 [==============================] - 1s 68ms/step - loss: 1.5046e-05 - acc: 1.0000 - val_loss: 1.8924 - val_acc: 0.8222\n","\n","Epoch 00048: val_acc did not improve from 0.82222\n","Epoch 49/100\n","16/16 [==============================] - 1s 67ms/step - loss: 1.4255e-05 - acc: 1.0000 - val_loss: 1.8952 - val_acc: 0.8222\n","\n","Epoch 00049: val_acc did not improve from 0.82222\n","Epoch 50/100\n","16/16 [==============================] - 1s 72ms/step - loss: 1.3437e-05 - acc: 1.0000 - val_loss: 1.8978 - val_acc: 0.8222\n","\n","Epoch 00050: val_acc did not improve from 0.82222\n","Epoch 51/100\n","16/16 [==============================] - 1s 67ms/step - loss: 1.3220e-05 - acc: 1.0000 - val_loss: 1.9003 - val_acc: 0.8222\n","\n","Epoch 00051: val_acc did not improve from 0.82222\n","Epoch 52/100\n","16/16 [==============================] - 1s 67ms/step - loss: 1.3058e-05 - acc: 1.0000 - val_loss: 1.9024 - val_acc: 0.8222\n","\n","Epoch 00052: val_acc did not improve from 0.82222\n","Epoch 53/100\n","16/16 [==============================] - 1s 70ms/step - loss: 1.2630e-05 - acc: 1.0000 - val_loss: 1.9050 - val_acc: 0.8222\n","\n","Epoch 00053: val_acc did not improve from 0.82222\n","Epoch 54/100\n","16/16 [==============================] - 1s 68ms/step - loss: 1.1689e-05 - acc: 1.0000 - val_loss: 1.9073 - val_acc: 0.8222\n","\n","Epoch 00054: val_acc did not improve from 0.82222\n","Epoch 55/100\n","16/16 [==============================] - 1s 68ms/step - loss: 1.2070e-05 - acc: 1.0000 - val_loss: 1.9097 - val_acc: 0.8222\n","\n","Epoch 00055: val_acc did not improve from 0.82222\n","Epoch 56/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.0351e-05 - acc: 1.0000 - val_loss: 1.9126 - val_acc: 0.8222\n","\n","Epoch 00056: val_acc did not improve from 0.82222\n","Epoch 57/100\n","16/16 [==============================] - 1s 68ms/step - loss: 1.1040e-05 - acc: 1.0000 - val_loss: 1.9150 - val_acc: 0.8222\n","\n","Epoch 00057: val_acc did not improve from 0.82222\n","Epoch 58/100\n","16/16 [==============================] - 1s 71ms/step - loss: 1.0809e-05 - acc: 1.0000 - val_loss: 1.9175 - val_acc: 0.8222\n","\n","Epoch 00058: val_acc did not improve from 0.82222\n","Epoch 59/100\n","16/16 [==============================] - 1s 67ms/step - loss: 9.7239e-06 - acc: 1.0000 - val_loss: 1.9195 - val_acc: 0.8222\n","\n","Epoch 00059: val_acc did not improve from 0.82222\n","Epoch 60/100\n","16/16 [==============================] - 1s 68ms/step - loss: 9.9035e-06 - acc: 1.0000 - val_loss: 1.9215 - val_acc: 0.8222\n","\n","Epoch 00060: val_acc did not improve from 0.82222\n","Epoch 61/100\n","16/16 [==============================] - 1s 67ms/step - loss: 9.2394e-06 - acc: 1.0000 - val_loss: 1.9239 - val_acc: 0.8222\n","\n","Epoch 00061: val_acc did not improve from 0.82222\n","Epoch 62/100\n","16/16 [==============================] - 1s 70ms/step - loss: 9.8375e-06 - acc: 1.0000 - val_loss: 1.9252 - val_acc: 0.8222\n","\n","Epoch 00062: val_acc did not improve from 0.82222\n","Epoch 63/100\n","16/16 [==============================] - 1s 67ms/step - loss: 8.7219e-06 - acc: 1.0000 - val_loss: 1.9266 - val_acc: 0.8222\n","\n","Epoch 00063: val_acc did not improve from 0.82222\n","Epoch 64/100\n","16/16 [==============================] - 1s 68ms/step - loss: 8.7755e-06 - acc: 1.0000 - val_loss: 1.9281 - val_acc: 0.8222\n","\n","Epoch 00064: val_acc did not improve from 0.82222\n","Epoch 65/100\n","16/16 [==============================] - 1s 66ms/step - loss: 7.7059e-06 - acc: 1.0000 - val_loss: 1.9294 - val_acc: 0.8222\n","\n","Epoch 00065: val_acc did not improve from 0.82222\n","Epoch 66/100\n","16/16 [==============================] - 1s 67ms/step - loss: 8.0310e-06 - acc: 1.0000 - val_loss: 1.9308 - val_acc: 0.8222\n","\n","Epoch 00066: val_acc did not improve from 0.82222\n","Epoch 67/100\n","16/16 [==============================] - 1s 66ms/step - loss: 7.8442e-06 - acc: 1.0000 - val_loss: 1.9322 - val_acc: 0.8222\n","\n","Epoch 00067: val_acc did not improve from 0.82222\n","Epoch 68/100\n","16/16 [==============================] - 1s 72ms/step - loss: 7.7437e-06 - acc: 1.0000 - val_loss: 1.9336 - val_acc: 0.8222\n","\n","Epoch 00068: val_acc did not improve from 0.82222\n","Epoch 69/100\n","16/16 [==============================] - 1s 67ms/step - loss: 7.3611e-06 - acc: 1.0000 - val_loss: 1.9352 - val_acc: 0.8222\n","\n","Epoch 00069: val_acc did not improve from 0.82222\n","Epoch 70/100\n","16/16 [==============================] - 1s 66ms/step - loss: 7.1797e-06 - acc: 1.0000 - val_loss: 1.9365 - val_acc: 0.8222\n","\n","Epoch 00070: val_acc did not improve from 0.82222\n","Epoch 71/100\n","16/16 [==============================] - 1s 67ms/step - loss: 6.7172e-06 - acc: 1.0000 - val_loss: 1.9379 - val_acc: 0.8222\n","\n","Epoch 00071: val_acc did not improve from 0.82222\n","Epoch 72/100\n","16/16 [==============================] - 1s 68ms/step - loss: 6.8058e-06 - acc: 1.0000 - val_loss: 1.9393 - val_acc: 0.8222\n","\n","Epoch 00072: val_acc did not improve from 0.82222\n","Epoch 73/100\n","16/16 [==============================] - 1s 66ms/step - loss: 6.7327e-06 - acc: 1.0000 - val_loss: 1.9403 - val_acc: 0.8222\n","\n","Epoch 00073: val_acc did not improve from 0.82222\n","Epoch 74/100\n","16/16 [==============================] - 1s 68ms/step - loss: 6.3917e-06 - acc: 1.0000 - val_loss: 1.9416 - val_acc: 0.8222\n","\n","Epoch 00074: val_acc did not improve from 0.82222\n","Epoch 75/100\n","16/16 [==============================] - 1s 70ms/step - loss: 6.3240e-06 - acc: 1.0000 - val_loss: 1.9430 - val_acc: 0.8222\n","\n","Epoch 00075: val_acc did not improve from 0.82222\n","Epoch 76/100\n","16/16 [==============================] - 1s 67ms/step - loss: 6.1524e-06 - acc: 1.0000 - val_loss: 1.9447 - val_acc: 0.8222\n","\n","Epoch 00076: val_acc did not improve from 0.82222\n","Epoch 77/100\n","16/16 [==============================] - 1s 69ms/step - loss: 6.0622e-06 - acc: 1.0000 - val_loss: 1.9462 - val_acc: 0.8222\n","\n","Epoch 00077: val_acc did not improve from 0.82222\n","Epoch 78/100\n","16/16 [==============================] - 1s 66ms/step - loss: 5.8470e-06 - acc: 1.0000 - val_loss: 1.9479 - val_acc: 0.8222\n","\n","Epoch 00078: val_acc did not improve from 0.82222\n","Epoch 79/100\n","16/16 [==============================] - 1s 66ms/step - loss: 5.5030e-06 - acc: 1.0000 - val_loss: 1.9492 - val_acc: 0.8222\n","\n","Epoch 00079: val_acc did not improve from 0.82222\n","Epoch 80/100\n","16/16 [==============================] - 1s 68ms/step - loss: 5.5806e-06 - acc: 1.0000 - val_loss: 1.9506 - val_acc: 0.8222\n","\n","Epoch 00080: val_acc did not improve from 0.82222\n","Epoch 81/100\n","16/16 [==============================] - 1s 71ms/step - loss: 5.4198e-06 - acc: 1.0000 - val_loss: 1.9518 - val_acc: 0.8222\n","\n","Epoch 00081: val_acc did not improve from 0.82222\n","Epoch 82/100\n","16/16 [==============================] - 1s 70ms/step - loss: 4.9302e-06 - acc: 1.0000 - val_loss: 1.9531 - val_acc: 0.8222\n","\n","Epoch 00082: val_acc did not improve from 0.82222\n","Epoch 83/100\n","16/16 [==============================] - 1s 68ms/step - loss: 5.2803e-06 - acc: 1.0000 - val_loss: 1.9546 - val_acc: 0.8222\n","\n","Epoch 00083: val_acc did not improve from 0.82222\n","Epoch 84/100\n","16/16 [==============================] - 1s 67ms/step - loss: 5.1521e-06 - acc: 1.0000 - val_loss: 1.9560 - val_acc: 0.8222\n","\n","Epoch 00084: val_acc did not improve from 0.82222\n","Epoch 85/100\n","16/16 [==============================] - 1s 66ms/step - loss: 4.8189e-06 - acc: 1.0000 - val_loss: 1.9571 - val_acc: 0.8222\n","\n","Epoch 00085: val_acc did not improve from 0.82222\n","Epoch 86/100\n","16/16 [==============================] - 1s 68ms/step - loss: 4.6788e-06 - acc: 1.0000 - val_loss: 1.9586 - val_acc: 0.8222\n","\n","Epoch 00086: val_acc did not improve from 0.82222\n","Epoch 87/100\n","16/16 [==============================] - 1s 67ms/step - loss: 4.7131e-06 - acc: 1.0000 - val_loss: 1.9598 - val_acc: 0.8222\n","\n","Epoch 00087: val_acc did not improve from 0.82222\n","Epoch 88/100\n","16/16 [==============================] - 1s 69ms/step - loss: 4.6479e-06 - acc: 1.0000 - val_loss: 1.9607 - val_acc: 0.8222\n","\n","Epoch 00088: val_acc did not improve from 0.82222\n","Epoch 89/100\n","16/16 [==============================] - 1s 68ms/step - loss: 4.2968e-06 - acc: 1.0000 - val_loss: 1.9618 - val_acc: 0.8222\n","\n","Epoch 00089: val_acc did not improve from 0.82222\n","Epoch 90/100\n","16/16 [==============================] - 1s 71ms/step - loss: 4.3115e-06 - acc: 1.0000 - val_loss: 1.9630 - val_acc: 0.8222\n","\n","Epoch 00090: val_acc did not improve from 0.82222\n","Epoch 91/100\n","16/16 [==============================] - 1s 69ms/step - loss: 4.1736e-06 - acc: 1.0000 - val_loss: 1.9639 - val_acc: 0.8222\n","\n","Epoch 00091: val_acc did not improve from 0.82222\n","Epoch 92/100\n","16/16 [==============================] - 1s 66ms/step - loss: 4.0720e-06 - acc: 1.0000 - val_loss: 1.9649 - val_acc: 0.8222\n","\n","Epoch 00092: val_acc did not improve from 0.82222\n","Epoch 93/100\n","16/16 [==============================] - 1s 68ms/step - loss: 4.0870e-06 - acc: 1.0000 - val_loss: 1.9660 - val_acc: 0.8222\n","\n","Epoch 00093: val_acc did not improve from 0.82222\n","Epoch 94/100\n","16/16 [==============================] - 1s 66ms/step - loss: 3.8672e-06 - acc: 1.0000 - val_loss: 1.9674 - val_acc: 0.8222\n","\n","Epoch 00094: val_acc did not improve from 0.82222\n","Epoch 95/100\n","16/16 [==============================] - 1s 72ms/step - loss: 3.7916e-06 - acc: 1.0000 - val_loss: 1.9682 - val_acc: 0.8222\n","\n","Epoch 00095: val_acc did not improve from 0.82222\n","Epoch 96/100\n","16/16 [==============================] - 1s 66ms/step - loss: 3.8758e-06 - acc: 1.0000 - val_loss: 1.9692 - val_acc: 0.8222\n","\n","Epoch 00096: val_acc did not improve from 0.82222\n","Epoch 97/100\n","16/16 [==============================] - 1s 68ms/step - loss: 3.6710e-06 - acc: 1.0000 - val_loss: 1.9704 - val_acc: 0.8222\n","\n","Epoch 00097: val_acc did not improve from 0.82222\n","Epoch 98/100\n","16/16 [==============================] - 1s 65ms/step - loss: 3.7984e-06 - acc: 1.0000 - val_loss: 1.9717 - val_acc: 0.8222\n","\n","Epoch 00098: val_acc did not improve from 0.82222\n","Epoch 99/100\n","16/16 [==============================] - 1s 68ms/step - loss: 3.3778e-06 - acc: 1.0000 - val_loss: 1.9728 - val_acc: 0.8222\n","\n","Epoch 00099: val_acc did not improve from 0.82222\n","Epoch 100/100\n","16/16 [==============================] - 1s 66ms/step - loss: 3.5118e-06 - acc: 1.0000 - val_loss: 1.9740 - val_acc: 0.8222\n","\n","Epoch 00100: val_acc did not improve from 0.82222\n","\n","<keras.callbacks.History at 0x7feae2f6bd68>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dkeA_EXPqhXo","colab_type":"code","colab":{}},"cell_type":"code","source":["#crosswalk 93 OUR6-17\n","\n","Epoch 1/100\n","16/16 [==============================] - 2s 125ms/step - loss: 0.7809 - acc: 0.5947 - val_loss: 0.5781 - val_acc: 0.7333\n","\n","Epoch 00001: val_acc improved from -inf to 0.73333, saving model to result/crosswalk/OUR6-17/epoch-01-val-acc-0.7333.hdf5\n","Epoch 2/100\n","16/16 [==============================] - 1s 71ms/step - loss: 0.6606 - acc: 0.6367 - val_loss: 0.5970 - val_acc: 0.7667\n","\n","Epoch 00002: val_acc improved from 0.73333 to 0.76667, saving model to result/crosswalk/OUR6-17/epoch-02-val-acc-0.7667.hdf5\n","Epoch 3/100\n","16/16 [==============================] - 1s 64ms/step - loss: 0.6328 - acc: 0.6737 - val_loss: 0.6900 - val_acc: 0.5833\n","\n","Epoch 00003: val_acc did not improve from 0.76667\n","Epoch 4/100\n","16/16 [==============================] - 1s 66ms/step - loss: 0.6398 - acc: 0.6705 - val_loss: 0.6650 - val_acc: 0.6167\n","\n","Epoch 00004: val_acc did not improve from 0.76667\n","Epoch 5/100\n","16/16 [==============================] - 1s 65ms/step - loss: 0.5786 - acc: 0.6806 - val_loss: 0.5333 - val_acc: 0.7500\n","\n","Epoch 00005: val_acc did not improve from 0.76667\n","Epoch 6/100\n","16/16 [==============================] - 1s 67ms/step - loss: 0.4878 - acc: 0.7659 - val_loss: 0.5036 - val_acc: 0.7167\n","\n","Epoch 00006: val_acc did not improve from 0.76667\n","Epoch 7/100\n","16/16 [==============================] - 1s 66ms/step - loss: 0.3593 - acc: 0.8443 - val_loss: 0.3790 - val_acc: 0.8000\n","\n","Epoch 00007: val_acc improved from 0.76667 to 0.80000, saving model to result/crosswalk/OUR6-17/epoch-07-val-acc-0.8000.hdf5\n","Epoch 8/100\n","16/16 [==============================] - 1s 65ms/step - loss: 0.3334 - acc: 0.8563 - val_loss: 0.3565 - val_acc: 0.8000\n","\n","Epoch 00008: val_acc did not improve from 0.80000\n","Epoch 9/100\n","16/16 [==============================] - 1s 65ms/step - loss: 0.1704 - acc: 0.9425 - val_loss: 0.3105 - val_acc: 0.8333\n","\n","Epoch 00009: val_acc improved from 0.80000 to 0.83333, saving model to result/crosswalk/OUR6-17/epoch-09-val-acc-0.8333.hdf5\n","Epoch 10/100\n","16/16 [==============================] - 1s 64ms/step - loss: 0.0901 - acc: 0.9645 - val_loss: 0.2466 - val_acc: 0.8833\n","\n","Epoch 00010: val_acc improved from 0.83333 to 0.88333, saving model to result/crosswalk/OUR6-17/epoch-10-val-acc-0.8833.hdf5\n","Epoch 11/100\n","16/16 [==============================] - 1s 65ms/step - loss: 0.0352 - acc: 0.9924 - val_loss: 0.2288 - val_acc: 0.9000\n","\n","Epoch 00011: val_acc improved from 0.88333 to 0.90000, saving model to result/crosswalk/OUR6-17/epoch-11-val-acc-0.9000.hdf5\n","Epoch 12/100\n","16/16 [==============================] - 1s 65ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.3170 - val_acc: 0.9000\n","\n","Epoch 00012: val_acc did not improve from 0.90000\n","Epoch 13/100\n","16/16 [==============================] - 1s 66ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.3249 - val_acc: 0.9000\n","\n","Epoch 00013: val_acc did not improve from 0.90000\n","Epoch 14/100\n","16/16 [==============================] - 1s 66ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.3743 - val_acc: 0.9000\n","\n","Epoch 00014: val_acc did not improve from 0.90000\n","Epoch 15/100\n","16/16 [==============================] - 1s 66ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.3639 - val_acc: 0.9000\n","\n","Epoch 00015: val_acc did not improve from 0.90000\n","Epoch 16/100\n","16/16 [==============================] - 1s 67ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.3754 - val_acc: 0.9000\n","\n","Epoch 00016: val_acc improved from 0.90000 to 0.90000, saving model to result/crosswalk/OUR6-17/epoch-16-val-acc-0.9000.hdf5\n","Epoch 17/100\n","16/16 [==============================] - 1s 64ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.4058 - val_acc: 0.9000\n","\n","Epoch 00017: val_acc did not improve from 0.90000\n","Epoch 18/100\n","16/16 [==============================] - 1s 66ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.4310 - val_acc: 0.9000\n","\n","Epoch 00018: val_acc did not improve from 0.90000\n","Epoch 19/100\n","16/16 [==============================] - 1s 66ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.4156 - val_acc: 0.9000\n","\n","Epoch 00019: val_acc did not improve from 0.90000\n","Epoch 20/100\n","16/16 [==============================] - 1s 66ms/step - loss: 4.8526e-04 - acc: 1.0000 - val_loss: 0.4025 - val_acc: 0.9333\n","\n","Epoch 00020: val_acc improved from 0.90000 to 0.93333, saving model to result/crosswalk/OUR6-17/epoch-20-val-acc-0.9333.hdf5\n","Epoch 21/100\n","16/16 [==============================] - 1s 64ms/step - loss: 6.9098e-04 - acc: 1.0000 - val_loss: 0.4387 - val_acc: 0.9333\n","\n","Epoch 00021: val_acc did not improve from 0.93333\n","Epoch 22/100\n","16/16 [==============================] - 1s 66ms/step - loss: 5.6420e-04 - acc: 1.0000 - val_loss: 0.4181 - val_acc: 0.9333\n","\n","Epoch 00022: val_acc did not improve from 0.93333\n","Epoch 23/100\n","16/16 [==============================] - 1s 66ms/step - loss: 3.4949e-04 - acc: 1.0000 - val_loss: 0.4474 - val_acc: 0.9167\n","\n","Epoch 00023: val_acc did not improve from 0.93333\n","Epoch 24/100\n","16/16 [==============================] - 1s 66ms/step - loss: 3.2260e-04 - acc: 1.0000 - val_loss: 0.4362 - val_acc: 0.9167\n","\n","Epoch 00024: val_acc did not improve from 0.93333\n","Epoch 25/100\n","16/16 [==============================] - 1s 65ms/step - loss: 4.3375e-04 - acc: 1.0000 - val_loss: 0.4304 - val_acc: 0.9333\n","\n","Epoch 00025: val_acc did not improve from 0.93333\n","Epoch 26/100\n","16/16 [==============================] - 1s 66ms/step - loss: 2.3119e-04 - acc: 1.0000 - val_loss: 0.4302 - val_acc: 0.9333\n","\n","Epoch 00026: val_acc did not improve from 0.93333\n","Epoch 27/100\n","16/16 [==============================] - 1s 66ms/step - loss: 2.0694e-04 - acc: 1.0000 - val_loss: 0.4524 - val_acc: 0.9167\n","\n","Epoch 00027: val_acc did not improve from 0.93333\n","Epoch 28/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.9424e-04 - acc: 1.0000 - val_loss: 0.4652 - val_acc: 0.9167\n","\n","Epoch 00028: val_acc did not improve from 0.93333\n","Epoch 29/100\n","16/16 [==============================] - 1s 65ms/step - loss: 1.8058e-04 - acc: 1.0000 - val_loss: 0.4904 - val_acc: 0.9167\n","\n","Epoch 00029: val_acc did not improve from 0.93333\n","Epoch 30/100\n","16/16 [==============================] - 1s 66ms/step - loss: 2.0417e-04 - acc: 1.0000 - val_loss: 0.4908 - val_acc: 0.9167\n","\n","Epoch 00030: val_acc did not improve from 0.93333\n","Epoch 31/100\n","16/16 [==============================] - 1s 67ms/step - loss: 1.6411e-04 - acc: 1.0000 - val_loss: 0.4723 - val_acc: 0.9333\n","\n","Epoch 00031: val_acc did not improve from 0.93333\n","Epoch 32/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.9240e-04 - acc: 1.0000 - val_loss: 0.5145 - val_acc: 0.9167\n","\n","Epoch 00032: val_acc did not improve from 0.93333\n","Epoch 33/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.5521e-04 - acc: 1.0000 - val_loss: 0.4984 - val_acc: 0.9167\n","\n","Epoch 00033: val_acc did not improve from 0.93333\n","Epoch 34/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.6548e-04 - acc: 1.0000 - val_loss: 0.4961 - val_acc: 0.9167\n","\n","Epoch 00034: val_acc did not improve from 0.93333\n","Epoch 35/100\n","16/16 [==============================] - 1s 66ms/step - loss: 9.9806e-05 - acc: 1.0000 - val_loss: 0.5084 - val_acc: 0.9167\n","\n","Epoch 00035: val_acc did not improve from 0.93333\n","Epoch 36/100\n","16/16 [==============================] - 1s 65ms/step - loss: 1.0906e-04 - acc: 1.0000 - val_loss: 0.4985 - val_acc: 0.9167\n","\n","Epoch 00036: val_acc did not improve from 0.93333\n","Epoch 37/100\n","16/16 [==============================] - 1s 67ms/step - loss: 9.0889e-05 - acc: 1.0000 - val_loss: 0.5007 - val_acc: 0.9167\n","\n","Epoch 00037: val_acc did not improve from 0.93333\n","Epoch 38/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.1125e-04 - acc: 1.0000 - val_loss: 0.5036 - val_acc: 0.9167\n","\n","Epoch 00038: val_acc did not improve from 0.93333\n","Epoch 39/100\n","16/16 [==============================] - 1s 65ms/step - loss: 1.2633e-04 - acc: 1.0000 - val_loss: 0.4818 - val_acc: 0.9333\n","\n","Epoch 00039: val_acc did not improve from 0.93333\n","Epoch 40/100\n","16/16 [==============================] - 1s 67ms/step - loss: 1.2010e-04 - acc: 1.0000 - val_loss: 0.5131 - val_acc: 0.9167\n","\n","Epoch 00040: val_acc did not improve from 0.93333\n","Epoch 41/100\n","16/16 [==============================] - 1s 66ms/step - loss: 9.8250e-05 - acc: 1.0000 - val_loss: 0.5106 - val_acc: 0.9167\n","\n","Epoch 00041: val_acc did not improve from 0.93333\n","Epoch 42/100\n","16/16 [==============================] - 1s 65ms/step - loss: 9.0243e-05 - acc: 1.0000 - val_loss: 0.5088 - val_acc: 0.9167\n","\n","Epoch 00042: val_acc did not improve from 0.93333\n","Epoch 43/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.5517e-04 - acc: 1.0000 - val_loss: 0.5328 - val_acc: 0.9167\n","\n","Epoch 00043: val_acc did not improve from 0.93333\n","Epoch 44/100\n","16/16 [==============================] - 1s 65ms/step - loss: 1.7671e-04 - acc: 1.0000 - val_loss: 0.5921 - val_acc: 0.9167\n","\n","Epoch 00044: val_acc did not improve from 0.93333\n","Epoch 45/100\n","16/16 [==============================] - 1s 64ms/step - loss: 6.4301e-05 - acc: 1.0000 - val_loss: 0.5856 - val_acc: 0.9167\n","\n","Epoch 00045: val_acc did not improve from 0.93333\n","Epoch 46/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.2325e-04 - acc: 1.0000 - val_loss: 0.5605 - val_acc: 0.9167\n","\n","Epoch 00046: val_acc did not improve from 0.93333\n","Epoch 47/100\n","16/16 [==============================] - 1s 66ms/step - loss: 7.2149e-05 - acc: 1.0000 - val_loss: 0.5720 - val_acc: 0.9167\n","\n","Epoch 00047: val_acc did not improve from 0.93333\n","Epoch 48/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.1132e-04 - acc: 1.0000 - val_loss: 0.5269 - val_acc: 0.9333\n","\n","Epoch 00048: val_acc did not improve from 0.93333\n","Epoch 49/100\n","16/16 [==============================] - 1s 66ms/step - loss: 9.8195e-05 - acc: 1.0000 - val_loss: 0.5198 - val_acc: 0.9167\n","\n","Epoch 00049: val_acc did not improve from 0.93333\n","Epoch 50/100\n","16/16 [==============================] - 1s 65ms/step - loss: 6.6927e-05 - acc: 1.0000 - val_loss: 0.5279 - val_acc: 0.9167\n","\n","Epoch 00050: val_acc did not improve from 0.93333\n","Epoch 51/100\n","16/16 [==============================] - 1s 67ms/step - loss: 5.2075e-05 - acc: 1.0000 - val_loss: 0.5329 - val_acc: 0.9167\n","\n","Epoch 00051: val_acc did not improve from 0.93333\n","Epoch 52/100\n","16/16 [==============================] - 1s 65ms/step - loss: 6.3727e-05 - acc: 1.0000 - val_loss: 0.5362 - val_acc: 0.9167\n","\n","Epoch 00052: val_acc did not improve from 0.93333\n","Epoch 53/100\n","16/16 [==============================] - 1s 64ms/step - loss: 5.5222e-05 - acc: 1.0000 - val_loss: 0.5317 - val_acc: 0.9167\n","\n","Epoch 00053: val_acc did not improve from 0.93333\n","Epoch 54/100\n","16/16 [==============================] - 1s 65ms/step - loss: 4.0563e-05 - acc: 1.0000 - val_loss: 0.5365 - val_acc: 0.9167\n","\n","Epoch 00054: val_acc did not improve from 0.93333\n","Epoch 55/100\n","16/16 [==============================] - 1s 65ms/step - loss: 6.8647e-05 - acc: 1.0000 - val_loss: 0.5895 - val_acc: 0.9333\n","\n","Epoch 00055: val_acc did not improve from 0.93333\n","Epoch 56/100\n","16/16 [==============================] - 1s 65ms/step - loss: 4.8342e-05 - acc: 1.0000 - val_loss: 0.5633 - val_acc: 0.9167\n","\n","Epoch 00056: val_acc did not improve from 0.93333\n","Epoch 57/100\n","16/16 [==============================] - 1s 67ms/step - loss: 6.8750e-05 - acc: 1.0000 - val_loss: 0.5480 - val_acc: 0.9167\n","\n","Epoch 00057: val_acc did not improve from 0.93333\n","Epoch 58/100\n","16/16 [==============================] - 1s 64ms/step - loss: 4.7265e-05 - acc: 1.0000 - val_loss: 0.5459 - val_acc: 0.9167\n","\n","Epoch 00058: val_acc did not improve from 0.93333\n","Epoch 59/100\n","16/16 [==============================] - 1s 66ms/step - loss: 4.2072e-05 - acc: 1.0000 - val_loss: 0.5399 - val_acc: 0.9167\n","\n","Epoch 00059: val_acc did not improve from 0.93333\n","Epoch 60/100\n","16/16 [==============================] - 1s 63ms/step - loss: 2.8919e-05 - acc: 1.0000 - val_loss: 0.5438 - val_acc: 0.9167\n","\n","Epoch 00060: val_acc did not improve from 0.93333\n","Epoch 61/100\n","16/16 [==============================] - 1s 63ms/step - loss: 4.1540e-05 - acc: 1.0000 - val_loss: 0.5520 - val_acc: 0.9167\n","\n","Epoch 00061: val_acc did not improve from 0.93333\n","Epoch 62/100\n","16/16 [==============================] - 1s 66ms/step - loss: 3.9517e-05 - acc: 1.0000 - val_loss: 0.5354 - val_acc: 0.9333\n","\n","Epoch 00062: val_acc did not improve from 0.93333\n","Epoch 63/100\n","16/16 [==============================] - 1s 66ms/step - loss: 4.1779e-05 - acc: 1.0000 - val_loss: 0.5409 - val_acc: 0.9167\n","\n","Epoch 00063: val_acc did not improve from 0.93333\n","Epoch 64/100\n","16/16 [==============================] - 1s 64ms/step - loss: 3.7450e-05 - acc: 1.0000 - val_loss: 0.5318 - val_acc: 0.9333\n","\n","Epoch 00064: val_acc did not improve from 0.93333\n","Epoch 65/100\n","16/16 [==============================] - 1s 65ms/step - loss: 2.7509e-05 - acc: 1.0000 - val_loss: 0.5324 - val_acc: 0.9333\n","\n","Epoch 00065: val_acc did not improve from 0.93333\n","Epoch 66/100\n","16/16 [==============================] - 1s 66ms/step - loss: 3.0939e-05 - acc: 1.0000 - val_loss: 0.5469 - val_acc: 0.9167\n","\n","Epoch 00066: val_acc did not improve from 0.93333\n","Epoch 67/100\n","16/16 [==============================] - 1s 65ms/step - loss: 2.7586e-05 - acc: 1.0000 - val_loss: 0.5530 - val_acc: 0.9167\n","\n","Epoch 00067: val_acc did not improve from 0.93333\n","Epoch 68/100\n","16/16 [==============================] - 1s 66ms/step - loss: 4.8708e-05 - acc: 1.0000 - val_loss: 0.5603 - val_acc: 0.9333\n","\n","Epoch 00068: val_acc did not improve from 0.93333\n","Epoch 69/100\n","16/16 [==============================] - 1s 66ms/step - loss: 5.0870e-05 - acc: 1.0000 - val_loss: 0.5875 - val_acc: 0.9167\n","\n","Epoch 00069: val_acc did not improve from 0.93333\n","Epoch 70/100\n","16/16 [==============================] - 1s 67ms/step - loss: 5.3515e-05 - acc: 1.0000 - val_loss: 0.5675 - val_acc: 0.9333\n","\n","Epoch 00070: val_acc did not improve from 0.93333\n","Epoch 71/100\n","16/16 [==============================] - 1s 64ms/step - loss: 3.2317e-05 - acc: 1.0000 - val_loss: 0.5829 - val_acc: 0.9167\n","\n","Epoch 00071: val_acc did not improve from 0.93333\n","Epoch 72/100\n","16/16 [==============================] - 1s 65ms/step - loss: 3.4115e-05 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.9333\n","\n","Epoch 00072: val_acc did not improve from 0.93333\n","Epoch 73/100\n","16/16 [==============================] - 1s 67ms/step - loss: 2.8578e-05 - acc: 1.0000 - val_loss: 0.6016 - val_acc: 0.9167\n","\n","Epoch 00073: val_acc did not improve from 0.93333\n","Epoch 74/100\n","16/16 [==============================] - 1s 64ms/step - loss: 2.2427e-05 - acc: 1.0000 - val_loss: 0.6008 - val_acc: 0.9167\n","\n","Epoch 00074: val_acc did not improve from 0.93333\n","Epoch 75/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.9870e-05 - acc: 1.0000 - val_loss: 0.6013 - val_acc: 0.9167\n","\n","Epoch 00075: val_acc did not improve from 0.93333\n","Epoch 76/100\n","16/16 [==============================] - 1s 66ms/step - loss: 2.0730e-05 - acc: 1.0000 - val_loss: 0.6016 - val_acc: 0.9167\n","\n","Epoch 00076: val_acc did not improve from 0.93333\n","Epoch 77/100\n","16/16 [==============================] - 1s 65ms/step - loss: 1.7521e-05 - acc: 1.0000 - val_loss: 0.6041 - val_acc: 0.9167\n","\n","Epoch 00077: val_acc did not improve from 0.93333\n","Epoch 78/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.3297e-05 - acc: 1.0000 - val_loss: 0.6046 - val_acc: 0.9167\n","\n","Epoch 00078: val_acc did not improve from 0.93333\n","Epoch 79/100\n","16/16 [==============================] - 1s 64ms/step - loss: 1.1328e-05 - acc: 1.0000 - val_loss: 0.6018 - val_acc: 0.9167\n","\n","Epoch 00079: val_acc did not improve from 0.93333\n","Epoch 80/100\n","16/16 [==============================] - 1s 64ms/step - loss: 1.8708e-05 - acc: 1.0000 - val_loss: 0.6043 - val_acc: 0.9167\n","\n","Epoch 00080: val_acc did not improve from 0.93333\n","Epoch 81/100\n","16/16 [==============================] - 1s 65ms/step - loss: 2.0743e-05 - acc: 1.0000 - val_loss: 0.6058 - val_acc: 0.9167\n","\n","Epoch 00081: val_acc did not improve from 0.93333\n","Epoch 82/100\n","16/16 [==============================] - 1s 68ms/step - loss: 2.6550e-05 - acc: 1.0000 - val_loss: 0.6053 - val_acc: 0.9333\n","\n","Epoch 00082: val_acc did not improve from 0.93333\n","Epoch 83/100\n","16/16 [==============================] - 1s 67ms/step - loss: 1.4129e-05 - acc: 1.0000 - val_loss: 0.6154 - val_acc: 0.9333\n","\n","Epoch 00083: val_acc did not improve from 0.93333\n","Epoch 84/100\n","16/16 [==============================] - 1s 63ms/step - loss: 1.7032e-05 - acc: 1.0000 - val_loss: 0.6254 - val_acc: 0.9167\n","\n","Epoch 00084: val_acc did not improve from 0.93333\n","Epoch 85/100\n","16/16 [==============================] - 1s 70ms/step - loss: 2.8646e-05 - acc: 1.0000 - val_loss: 0.6099 - val_acc: 0.9167\n","\n","Epoch 00085: val_acc did not improve from 0.93333\n","Epoch 86/100\n","16/16 [==============================] - 1s 63ms/step - loss: 1.7117e-05 - acc: 1.0000 - val_loss: 0.5879 - val_acc: 0.9333\n","\n","Epoch 00086: val_acc did not improve from 0.93333\n","Epoch 87/100\n","16/16 [==============================] - 1s 63ms/step - loss: 2.2634e-05 - acc: 1.0000 - val_loss: 0.5923 - val_acc: 0.9333\n","\n","Epoch 00087: val_acc did not improve from 0.93333\n","Epoch 88/100\n","16/16 [==============================] - 1s 63ms/step - loss: 1.7492e-05 - acc: 1.0000 - val_loss: 0.5971 - val_acc: 0.9333\n","\n","Epoch 00088: val_acc did not improve from 0.93333\n","Epoch 89/100\n","16/16 [==============================] - 1s 67ms/step - loss: 1.6988e-05 - acc: 1.0000 - val_loss: 0.6021 - val_acc: 0.9167\n","\n","Epoch 00089: val_acc did not improve from 0.93333\n","Epoch 90/100\n","16/16 [==============================] - 1s 64ms/step - loss: 1.6811e-05 - acc: 1.0000 - val_loss: 0.6062 - val_acc: 0.9167\n","\n","Epoch 00090: val_acc did not improve from 0.93333\n","Epoch 91/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.5996e-05 - acc: 1.0000 - val_loss: 0.6114 - val_acc: 0.9167\n","\n","Epoch 00091: val_acc did not improve from 0.93333\n","Epoch 92/100\n","16/16 [==============================] - 1s 63ms/step - loss: 1.7710e-05 - acc: 1.0000 - val_loss: 0.6213 - val_acc: 0.9167\n","\n","Epoch 00092: val_acc did not improve from 0.93333\n","Epoch 93/100\n","16/16 [==============================] - 1s 63ms/step - loss: 1.4063e-05 - acc: 1.0000 - val_loss: 0.6237 - val_acc: 0.9167\n","\n","Epoch 00093: val_acc did not improve from 0.93333\n","Epoch 94/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.1074e-05 - acc: 1.0000 - val_loss: 0.6233 - val_acc: 0.9167\n","\n","Epoch 00094: val_acc did not improve from 0.93333\n","Epoch 95/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.3690e-05 - acc: 1.0000 - val_loss: 0.6203 - val_acc: 0.9167\n","\n","Epoch 00095: val_acc did not improve from 0.93333\n","Epoch 96/100\n","16/16 [==============================] - 1s 65ms/step - loss: 1.4293e-05 - acc: 1.0000 - val_loss: 0.6320 - val_acc: 0.9167\n","\n","Epoch 00096: val_acc did not improve from 0.93333\n","Epoch 97/100\n","16/16 [==============================] - 1s 64ms/step - loss: 1.5153e-05 - acc: 1.0000 - val_loss: 0.6317 - val_acc: 0.9167\n","\n","Epoch 00097: val_acc did not improve from 0.93333\n","Epoch 98/100\n","16/16 [==============================] - 1s 66ms/step - loss: 1.9061e-05 - acc: 1.0000 - val_loss: 0.6171 - val_acc: 0.9333\n","\n","Epoch 00098: val_acc did not improve from 0.93333\n","Epoch 99/100\n","16/16 [==============================] - 1s 64ms/step - loss: 1.3922e-05 - acc: 1.0000 - val_loss: 0.6103 - val_acc: 0.9333\n","\n","Epoch 00099: val_acc did not improve from 0.93333\n","Epoch 100/100\n","16/16 [==============================] - 1s 65ms/step - loss: 1.2882e-05 - acc: 1.0000 - val_loss: 0.6119 - val_acc: 0.9333\n","\n","Epoch 00100: val_acc did not improve from 0.93333\n","\n","<keras.callbacks.History at 0x7f969905d320>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pN4zxkafljl0","colab_type":"code","colab":{}},"cell_type":"code","source":["#our6-36 results output INTERSECTION\n","\n","Epoch 1/100\n","16/16 [==============================] - 2s 116ms/step - loss: 0.6658 - acc: 0.6334 - val_loss: 0.6671 - val_acc: 0.6271\n","\n","Epoch 00001: val_acc improved from -inf to 0.62712, saving model to result/intersection/OUR6-36/epoch-01-val-acc-0.6271.hdf5\n","Epoch 2/100\n","16/16 [==============================] - 1s 65ms/step - loss: 0.6367 - acc: 0.6528 - val_loss: 0.6803 - val_acc: 0.5424\n","\n","Epoch 00002: val_acc did not improve from 0.62712\n","Epoch 3/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.6421 - acc: 0.6427 - val_loss: 0.6439 - val_acc: 0.6271\n","\n","Epoch 00003: val_acc did not improve from 0.62712\n","Epoch 4/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.5139 - acc: 0.7269 - val_loss: 1.1238 - val_acc: 0.5085\n","\n","Epoch 00004: val_acc did not improve from 0.62712\n","Epoch 5/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.3377 - acc: 0.8425 - val_loss: 0.5322 - val_acc: 0.7627\n","\n","Epoch 00005: val_acc improved from 0.62712 to 0.76271, saving model to result/intersection/OUR6-36/epoch-05-val-acc-0.7627.hdf5\n","Epoch 6/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.2026 - acc: 0.9186 - val_loss: 0.4826 - val_acc: 0.8305\n","\n","Epoch 00006: val_acc improved from 0.76271 to 0.83051, saving model to result/intersection/OUR6-36/epoch-06-val-acc-0.8305.hdf5\n","Epoch 7/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.1985 - acc: 0.9264 - val_loss: 0.4795 - val_acc: 0.7966\n","\n","Epoch 00007: val_acc did not improve from 0.83051\n","Epoch 8/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0874 - acc: 0.9653 - val_loss: 0.5132 - val_acc: 0.8305\n","\n","Epoch 00008: val_acc did not improve from 0.83051\n","Epoch 9/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0419 - acc: 0.9872 - val_loss: 0.5724 - val_acc: 0.8644\n","\n","Epoch 00009: val_acc improved from 0.83051 to 0.86441, saving model to result/intersection/OUR6-36/epoch-09-val-acc-0.8644.hdf5\n","Epoch 10/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0168 - acc: 0.9946 - val_loss: 0.8321 - val_acc: 0.8475\n","\n","Epoch 00010: val_acc did not improve from 0.86441\n","Epoch 11/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0170 - acc: 0.9937 - val_loss: 0.7717 - val_acc: 0.8644\n","\n","Epoch 00011: val_acc did not improve from 0.86441\n","Epoch 12/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0176 - acc: 0.9921 - val_loss: 0.8827 - val_acc: 0.8136\n","\n","Epoch 00012: val_acc did not improve from 0.86441\n","Epoch 13/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0201 - acc: 0.9937 - val_loss: 0.7744 - val_acc: 0.8814\n","\n","Epoch 00013: val_acc improved from 0.86441 to 0.88136, saving model to result/intersection/OUR6-36/epoch-13-val-acc-0.8814.hdf5\n","Epoch 14/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0112 - acc: 0.9961 - val_loss: 0.7683 - val_acc: 0.8475\n","\n","Epoch 00014: val_acc did not improve from 0.88136\n","Epoch 15/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0087 - acc: 0.9961 - val_loss: 0.9060 - val_acc: 0.8305\n","\n","Epoch 00015: val_acc did not improve from 0.88136\n","Epoch 16/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0103 - acc: 0.9961 - val_loss: 1.0218 - val_acc: 0.7797\n","\n","Epoch 00016: val_acc did not improve from 0.88136\n","Epoch 17/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0111 - acc: 0.9961 - val_loss: 0.9319 - val_acc: 0.8475\n","\n","Epoch 00017: val_acc did not improve from 0.88136\n","Epoch 18/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0060 - acc: 0.9986 - val_loss: 1.0299 - val_acc: 0.8475\n","\n","Epoch 00018: val_acc did not improve from 0.88136\n","Epoch 19/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0303 - acc: 0.9912 - val_loss: 0.9676 - val_acc: 0.8475\n","\n","Epoch 00019: val_acc did not improve from 0.88136\n","Epoch 20/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0139 - acc: 0.9937 - val_loss: 0.9392 - val_acc: 0.8136\n","\n","Epoch 00020: val_acc did not improve from 0.88136\n","Epoch 21/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.8453 - val_acc: 0.8305\n","\n","Epoch 00021: val_acc did not improve from 0.88136\n","Epoch 22/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0038 - acc: 0.9990 - val_loss: 0.9315 - val_acc: 0.8475\n","\n","Epoch 00022: val_acc did not improve from 0.88136\n","Epoch 23/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.8673 - val_acc: 0.8814\n","\n","Epoch 00023: val_acc did not improve from 0.88136\n","Epoch 24/100\n","16/16 [==============================] - 1s 57ms/step - loss: 6.5690e-04 - acc: 1.0000 - val_loss: 1.1900 - val_acc: 0.8475\n","\n","Epoch 00024: val_acc did not improve from 0.88136\n","Epoch 25/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0065 - acc: 0.9961 - val_loss: 1.1393 - val_acc: 0.8475\n","\n","Epoch 00025: val_acc did not improve from 0.88136\n","Epoch 26/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0191 - acc: 0.9912 - val_loss: 1.0933 - val_acc: 0.8475\n","\n","Epoch 00026: val_acc did not improve from 0.88136\n","Epoch 27/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0292 - acc: 0.9946 - val_loss: 0.9256 - val_acc: 0.8305\n","\n","Epoch 00027: val_acc did not improve from 0.88136\n","Epoch 28/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.7956 - val_acc: 0.8305\n","\n","Epoch 00028: val_acc did not improve from 0.88136\n","Epoch 29/100\n","16/16 [==============================] - 1s 57ms/step - loss: 8.2028e-04 - acc: 1.0000 - val_loss: 0.8035 - val_acc: 0.8475\n","\n","Epoch 00029: val_acc did not improve from 0.88136\n","Epoch 30/100\n","16/16 [==============================] - 1s 56ms/step - loss: 4.7136e-04 - acc: 1.0000 - val_loss: 0.8852 - val_acc: 0.8475\n","\n","Epoch 00030: val_acc did not improve from 0.88136\n","Epoch 31/100\n","16/16 [==============================] - 1s 57ms/step - loss: 6.4560e-04 - acc: 1.0000 - val_loss: 0.8100 - val_acc: 0.8475\n","\n","Epoch 00031: val_acc did not improve from 0.88136\n","Epoch 32/100\n","16/16 [==============================] - 1s 60ms/step - loss: 0.0043 - acc: 0.9980 - val_loss: 1.2794 - val_acc: 0.7797\n","\n","Epoch 00032: val_acc did not improve from 0.88136\n","Epoch 33/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.1334 - val_acc: 0.8305\n","\n","Epoch 00033: val_acc did not improve from 0.88136\n","Epoch 34/100\n","16/16 [==============================] - 1s 55ms/step - loss: 7.8979e-04 - acc: 1.0000 - val_loss: 1.1940 - val_acc: 0.8305\n","\n","Epoch 00034: val_acc did not improve from 0.88136\n","Epoch 35/100\n","16/16 [==============================] - 1s 54ms/step - loss: 1.2616e-04 - acc: 1.0000 - val_loss: 1.1563 - val_acc: 0.8475\n","\n","Epoch 00035: val_acc did not improve from 0.88136\n","Epoch 36/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0027 - acc: 0.9990 - val_loss: 0.9146 - val_acc: 0.8814\n","\n","Epoch 00036: val_acc did not improve from 0.88136\n","Epoch 37/100\n","16/16 [==============================] - 1s 58ms/step - loss: 0.0119 - acc: 0.9946 - val_loss: 1.0137 - val_acc: 0.8644\n","\n","Epoch 00037: val_acc did not improve from 0.88136\n","Epoch 38/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0034 - acc: 0.9966 - val_loss: 0.9208 - val_acc: 0.9153\n","\n","Epoch 00038: val_acc improved from 0.88136 to 0.91525, saving model to result/intersection/OUR6-36/epoch-38-val-acc-0.9153.hdf5\n","Epoch 39/100\n","16/16 [==============================] - 1s 54ms/step - loss: 0.0053 - acc: 0.9980 - val_loss: 0.8825 - val_acc: 0.8983\n","\n","Epoch 00039: val_acc did not improve from 0.91525\n","Epoch 40/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0027 - acc: 0.9990 - val_loss: 1.1995 - val_acc: 0.8136\n","\n","Epoch 00040: val_acc did not improve from 0.91525\n","Epoch 41/100\n","16/16 [==============================] - 1s 56ms/step - loss: 7.8383e-04 - acc: 1.0000 - val_loss: 1.3344 - val_acc: 0.8305\n","\n","Epoch 00041: val_acc did not improve from 0.91525\n","Epoch 42/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0048 - acc: 0.9971 - val_loss: 0.9914 - val_acc: 0.8644\n","\n","Epoch 00042: val_acc did not improve from 0.91525\n","Epoch 43/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0160 - acc: 0.9956 - val_loss: 0.7489 - val_acc: 0.9322\n","\n","Epoch 00043: val_acc improved from 0.91525 to 0.93220, saving model to result/intersection/OUR6-36/epoch-43-val-acc-0.9322.hdf5\n","Epoch 44/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0313 - acc: 0.9868 - val_loss: 1.7550 - val_acc: 0.7966\n","\n","Epoch 00044: val_acc did not improve from 0.93220\n","Epoch 45/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0350 - acc: 0.9869 - val_loss: 0.9243 - val_acc: 0.8136\n","\n","Epoch 00045: val_acc did not improve from 0.93220\n","Epoch 46/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0071 - acc: 0.9966 - val_loss: 0.7760 - val_acc: 0.8814\n","\n","Epoch 00046: val_acc did not improve from 0.93220\n","Epoch 47/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0052 - acc: 0.9976 - val_loss: 1.1363 - val_acc: 0.8475\n","\n","Epoch 00047: val_acc did not improve from 0.93220\n","Epoch 48/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0027 - acc: 0.9986 - val_loss: 0.6548 - val_acc: 0.8983\n","\n","Epoch 00048: val_acc did not improve from 0.93220\n","Epoch 49/100\n","16/16 [==============================] - 1s 58ms/step - loss: 9.7109e-04 - acc: 1.0000 - val_loss: 0.7498 - val_acc: 0.9153\n","\n","Epoch 00049: val_acc did not improve from 0.93220\n","Epoch 50/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0050 - acc: 0.9971 - val_loss: 0.8196 - val_acc: 0.8814\n","\n","Epoch 00050: val_acc did not improve from 0.93220\n","Epoch 51/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0168 - acc: 0.9976 - val_loss: 1.2137 - val_acc: 0.8644\n","\n","Epoch 00051: val_acc did not improve from 0.93220\n","Epoch 52/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0174 - acc: 0.9907 - val_loss: 1.0454 - val_acc: 0.8644\n","\n","Epoch 00052: val_acc did not improve from 0.93220\n","Epoch 53/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0043 - acc: 0.9980 - val_loss: 0.9791 - val_acc: 0.8305\n","\n","Epoch 00053: val_acc did not improve from 0.93220\n","Epoch 54/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.2437 - val_acc: 0.8475\n","\n","Epoch 00054: val_acc did not improve from 0.93220\n","Epoch 55/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0015 - acc: 0.9990 - val_loss: 1.0693 - val_acc: 0.8475\n","\n","Epoch 00055: val_acc did not improve from 0.93220\n","Epoch 56/100\n","16/16 [==============================] - 1s 56ms/step - loss: 4.6532e-04 - acc: 1.0000 - val_loss: 1.0707 - val_acc: 0.8983\n","\n","Epoch 00056: val_acc did not improve from 0.93220\n","Epoch 57/100\n","16/16 [==============================] - 1s 60ms/step - loss: 2.2577e-04 - acc: 1.0000 - val_loss: 1.1964 - val_acc: 0.8475\n","\n","Epoch 00057: val_acc did not improve from 0.93220\n","Epoch 58/100\n","16/16 [==============================] - 1s 58ms/step - loss: 1.5766e-04 - acc: 1.0000 - val_loss: 1.3484 - val_acc: 0.8136\n","\n","Epoch 00058: val_acc did not improve from 0.93220\n","Epoch 59/100\n","16/16 [==============================] - 1s 56ms/step - loss: 8.1481e-05 - acc: 1.0000 - val_loss: 1.2265 - val_acc: 0.8305\n","\n","Epoch 00059: val_acc did not improve from 0.93220\n","Epoch 60/100\n","16/16 [==============================] - 1s 57ms/step - loss: 1.5972e-05 - acc: 1.0000 - val_loss: 1.1950 - val_acc: 0.8305\n","\n","Epoch 00060: val_acc did not improve from 0.93220\n","Epoch 61/100\n","16/16 [==============================] - 1s 57ms/step - loss: 2.0998e-05 - acc: 1.0000 - val_loss: 1.1884 - val_acc: 0.8305\n","\n","Epoch 00061: val_acc did not improve from 0.93220\n","Epoch 62/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0098 - acc: 0.9980 - val_loss: 1.0436 - val_acc: 0.8644\n","\n","Epoch 00062: val_acc did not improve from 0.93220\n","Epoch 63/100\n","16/16 [==============================] - 1s 55ms/step - loss: 3.9623e-04 - acc: 1.0000 - val_loss: 1.0411 - val_acc: 0.8475\n","\n","Epoch 00063: val_acc did not improve from 0.93220\n","Epoch 64/100\n","16/16 [==============================] - 1s 57ms/step - loss: 2.4926e-04 - acc: 1.0000 - val_loss: 1.0435 - val_acc: 0.8475\n","\n","Epoch 00064: val_acc did not improve from 0.93220\n","Epoch 65/100\n","16/16 [==============================] - 1s 57ms/step - loss: 3.3051e-04 - acc: 1.0000 - val_loss: 1.0831 - val_acc: 0.8305\n","\n","Epoch 00065: val_acc did not improve from 0.93220\n","Epoch 66/100\n","16/16 [==============================] - 1s 56ms/step - loss: 1.6040e-04 - acc: 1.0000 - val_loss: 1.0978 - val_acc: 0.8305\n","\n","Epoch 00066: val_acc did not improve from 0.93220\n","Epoch 67/100\n","16/16 [==============================] - 1s 56ms/step - loss: 1.2278e-04 - acc: 1.0000 - val_loss: 1.1092 - val_acc: 0.8305\n","\n","Epoch 00067: val_acc did not improve from 0.93220\n","Epoch 68/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0037 - acc: 0.9980 - val_loss: 1.2196 - val_acc: 0.8475\n","\n","Epoch 00068: val_acc did not improve from 0.93220\n","Epoch 69/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.2850 - val_acc: 0.8305\n","\n","Epoch 00069: val_acc did not improve from 0.93220\n","Epoch 70/100\n","16/16 [==============================] - 1s 61ms/step - loss: 4.2156e-04 - acc: 1.0000 - val_loss: 1.3997 - val_acc: 0.8305\n","\n","Epoch 00070: val_acc did not improve from 0.93220\n","Epoch 71/100\n","16/16 [==============================] - 1s 57ms/step - loss: 4.4871e-05 - acc: 1.0000 - val_loss: 1.3375 - val_acc: 0.8305\n","\n","Epoch 00071: val_acc did not improve from 0.93220\n","Epoch 72/100\n","16/16 [==============================] - 1s 57ms/step - loss: 5.1620e-05 - acc: 1.0000 - val_loss: 1.3683 - val_acc: 0.8305\n","\n","Epoch 00072: val_acc did not improve from 0.93220\n","Epoch 73/100\n","16/16 [==============================] - 1s 58ms/step - loss: 3.1161e-05 - acc: 1.0000 - val_loss: 1.4001 - val_acc: 0.8305\n","\n","Epoch 00073: val_acc did not improve from 0.93220\n","Epoch 74/100\n","16/16 [==============================] - 1s 57ms/step - loss: 1.8189e-05 - acc: 1.0000 - val_loss: 1.4226 - val_acc: 0.8305\n","\n","Epoch 00074: val_acc did not improve from 0.93220\n","Epoch 75/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0015 - acc: 0.9990 - val_loss: 1.2827 - val_acc: 0.8305\n","\n","Epoch 00075: val_acc did not improve from 0.93220\n","Epoch 76/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.2924 - val_acc: 0.8136\n","\n","Epoch 00076: val_acc did not improve from 0.93220\n","Epoch 77/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0014 - acc: 0.9990 - val_loss: 1.8972 - val_acc: 0.8136\n","\n","Epoch 00077: val_acc did not improve from 0.93220\n","Epoch 78/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.2476 - val_acc: 0.8475\n","\n","Epoch 00078: val_acc did not improve from 0.93220\n","Epoch 79/100\n","16/16 [==============================] - 1s 57ms/step - loss: 2.2340e-04 - acc: 1.0000 - val_loss: 1.5490 - val_acc: 0.8644\n","\n","Epoch 00079: val_acc did not improve from 0.93220\n","Epoch 80/100\n","16/16 [==============================] - 1s 55ms/step - loss: 3.1804e-04 - acc: 1.0000 - val_loss: 1.2837 - val_acc: 0.8475\n","\n","Epoch 00080: val_acc did not improve from 0.93220\n","Epoch 81/100\n","16/16 [==============================] - 1s 57ms/step - loss: 9.0861e-05 - acc: 1.0000 - val_loss: 1.3493 - val_acc: 0.8475\n","\n","Epoch 00081: val_acc did not improve from 0.93220\n","Epoch 82/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0046 - acc: 0.9980 - val_loss: 0.9783 - val_acc: 0.8475\n","\n","Epoch 00082: val_acc did not improve from 0.93220\n","Epoch 83/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.0946 - acc: 0.9812 - val_loss: 0.9915 - val_acc: 0.9153\n","\n","Epoch 00083: val_acc did not improve from 0.93220\n","Epoch 84/100\n","16/16 [==============================] - 1s 57ms/step - loss: 0.1173 - acc: 0.9795 - val_loss: 1.7147 - val_acc: 0.7966\n","\n","Epoch 00084: val_acc did not improve from 0.93220\n","Epoch 85/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.1180 - acc: 0.9806 - val_loss: 0.5502 - val_acc: 0.9492\n","\n","Epoch 00085: val_acc improved from 0.93220 to 0.94915, saving model to result/intersection/OUR6-36/epoch-85-val-acc-0.9492.hdf5\n","Epoch 86/100\n","16/16 [==============================] - 1s 55ms/step - loss: 0.0618 - acc: 0.9868 - val_loss: 1.5186 - val_acc: 0.8136\n","\n","Epoch 00086: val_acc did not improve from 0.94915\n","Epoch 87/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0472 - acc: 0.9893 - val_loss: 0.9074 - val_acc: 0.8644\n","\n","Epoch 00087: val_acc did not improve from 0.94915\n","Epoch 88/100\n","16/16 [==============================] - 1s 56ms/step - loss: 0.0087 - acc: 0.9961 - val_loss: 1.2429 - val_acc: 0.8814\n","\n","Epoch 00088: val_acc did not improve from 0.94915\n","Epoch 89/100\n","16/16 [==============================] - 1s 58ms/step - loss: 6.4167e-04 - acc: 1.0000 - val_loss: 1.5725 - val_acc: 0.8644\n","\n","Epoch 00089: val_acc did not improve from 0.94915\n","Epoch 90/100\n","16/16 [==============================] - 1s 60ms/step - loss: 4.8426e-04 - acc: 1.0000 - val_loss: 1.5594 - val_acc: 0.8814\n","\n","Epoch 00090: val_acc did not improve from 0.94915\n","Epoch 91/100\n","16/16 [==============================] - 1s 57ms/step - loss: 2.5414e-06 - acc: 1.0000 - val_loss: 1.5433 - val_acc: 0.8814\n","\n","Epoch 00091: val_acc did not improve from 0.94915\n","Epoch 92/100\n","16/16 [==============================] - 1s 57ms/step - loss: 2.0146e-06 - acc: 1.0000 - val_loss: 1.5388 - val_acc: 0.8814\n","\n","Epoch 00092: val_acc did not improve from 0.94915\n","Epoch 93/100\n","16/16 [==============================] - 1s 56ms/step - loss: 3.7211e-06 - acc: 1.0000 - val_loss: 1.5394 - val_acc: 0.8814\n","\n","Epoch 00093: val_acc did not improve from 0.94915\n","Epoch 94/100\n","16/16 [==============================] - 1s 58ms/step - loss: 1.6381e-05 - acc: 1.0000 - val_loss: 1.5418 - val_acc: 0.8814\n","\n","Epoch 00094: val_acc did not improve from 0.94915\n","Epoch 95/100\n","16/16 [==============================] - 1s 55ms/step - loss: 1.9050e-07 - acc: 1.0000 - val_loss: 1.5452 - val_acc: 0.8814\n","\n","Epoch 00095: val_acc did not improve from 0.94915\n","Epoch 96/100\n","16/16 [==============================] - 1s 56ms/step - loss: 1.6085e-04 - acc: 1.0000 - val_loss: 1.5480 - val_acc: 0.8814\n","\n","Epoch 00096: val_acc did not improve from 0.94915\n","Epoch 97/100\n","16/16 [==============================] - 1s 56ms/step - loss: 8.4349e-05 - acc: 1.0000 - val_loss: 1.5270 - val_acc: 0.8814\n","\n","Epoch 00097: val_acc did not improve from 0.94915\n","Epoch 98/100\n","16/16 [==============================] - 1s 56ms/step - loss: 4.4622e-05 - acc: 1.0000 - val_loss: 1.5479 - val_acc: 0.8814\n","\n","Epoch 00098: val_acc did not improve from 0.94915\n","Epoch 99/100\n","16/16 [==============================] - 1s 57ms/step - loss: 1.4702e-05 - acc: 1.0000 - val_loss: 1.5531 - val_acc: 0.8814\n","\n","Epoch 00099: val_acc did not improve from 0.94915\n","Epoch 100/100\n","16/16 [==============================] - 1s 57ms/step - loss: 4.2634e-07 - acc: 1.0000 - val_loss: 1.5513 - val_acc: 0.8814\n","\n","Epoch 00100: val_acc did not improve from 0.94915\n","\n","<keras.callbacks.History at 0x7f0bed37e2e8>\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0jOqJpZgGy8v","colab_type":"code","colab":{}},"cell_type":"code","source":["#Our model\n","model=\"\"\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), input_shape=(img_h, img_w, channel_size), padding='SAME'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(32, (3, 3), strides=(2,2)))\n","model.add(Conv2D(32, (3, 3), strides=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Dropout(0.25))\n","\n","# Fully connected layer\n","model.add(Dense(84))\n","BatchNormalization()\n","model.add(Activation('relu'))\n","model.add(Dense(4))\n","\n","model.add(Activation('softmax'))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QrgXuDL4hj57","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import confusion_matrix"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HF_Q5X8qr4uq","colab_type":"code","outputId":"dbb429b8-2694-4f8e-b82e-2c8a5df157bc","executionInfo":{"status":"ok","timestamp":1540234897685,"user_tz":-180,"elapsed":2452,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"cell_type":"code","source":["ds_yol='datasets/all/four/two/'\n","rs_yol='result/all/four/two/OUR6-18/'\n","model.load_weights(rs_yol+\"epoch-32-val-acc-0.8243.hdf5\")\n","\n","x_train=np.load(ds_yol+'x_train.npy')\n","y_train=np.load(ds_yol+'y_train.npy')\n","\n","x_test=np.load(ds_yol+'x_test.npy')\n","y_test=np.load(ds_yol+'y_test.npy')\n","\n","x_val=np.load(ds_yol+'x_val.npy')\n","y_val=np.load(ds_yol+'y_val.npy')\n","\n","print(' Train data num: ', x_train.shape, ' sample \\n', 'Test data num: ', x_test.shape, \n","      ' sample \\n', 'Validation data num: ', x_val.shape, ' sample')"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" Train data num:  (588, 64, 128, 3)  sample \n"," Test data num:  (73, 64, 128, 3)  sample \n"," Validation data num:  (74, 64, 128, 3)  sample\n"],"name":"stdout"}]},{"metadata":{"id":"cQhAIIVUhs27","colab_type":"code","outputId":"05540106-fef2-457c-b35f-c3335171e33e","executionInfo":{"status":"ok","timestamp":1540235620924,"user_tz":-180,"elapsed":1025,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":329}},"cell_type":"code","source":["#Load Data\n","\n","data='datasets/all/four/two/'\n","result='result/all/four/two/OUR6-18/'\n","model.load_weights(result+\"epoch-32-val-acc-0.8243.hdf5\")\n","\n","x_train=np.load(data+'x_train.npy')\n","y_train=np.load(data+'y_train.npy')\n","\n","x_test=np.load(data+'x_test.npy')\n","y_test=np.load(data+'y_test.npy')\n","\n","x_val=np.load(data+'x_val.npy')\n","y_val=np.load(data+'y_val.npy')\n","\n","print('Data:\\n Train data num: ', x_train.shape, ' sample \\n', 'Test data num: ', x_test.shape, \n","      ' sample \\n', 'Validation data num: ', x_val.shape, ' sample\\n')\n","print('========================================================\\n', result, 'Results: \\n')\n","\n","\n","from sklearn.metrics import confusion_matrix\n","\n","\n","\n","y_pred = model.predict(x_test)\n","y_pred = np.argmax(y_pred, axis=1)\n","\n","testPredict = model.predict(x_test)\n","\n","print('Confusion matrix result:\\n', confusion_matrix(np.argmax(y_test,axis=1), y_pred),'\\n')\n","\n","score = model.evaluate(x_test, y_test, batch_size=32, verbose=1)\n","print('\\n', 'Test accuracy:', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Data:\n"," Train data num:  (588, 64, 128, 3)  sample \n"," Test data num:  (73, 64, 128, 3)  sample \n"," Validation data num:  (74, 64, 128, 3)  sample\n","\n","========================================================\n"," result/all/four/two/OUR6-18/ Results: \n","\n","Confusion matrix result:\n"," [[ 9  3  0  1]\n"," [ 0 20  0  1]\n"," [ 2  0 12  3]\n"," [ 0  2  0 20]] \n","\n","73/73 [==============================] - 0s 418us/step\n","\n"," Test accuracy: 0.8356164391726664\n"],"name":"stdout"}]},{"metadata":{"id":"HK0v9NoviGhh","colab_type":"code","colab":{}},"cell_type":"code","source":["testPredict = model.predict(x_val)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-9TzZkMEiJZW","colab_type":"code","outputId":"2898f20e-d310-41c2-bb6d-87b2df2da6a8","executionInfo":{"status":"ok","timestamp":1540234650369,"user_tz":-180,"elapsed":997,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":90}},"cell_type":"code","source":["print(confusion_matrix(np.argmax(y_val,axis=1), y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[ 9  3  0  1]\n"," [ 0 20  0  1]\n"," [ 2  0 12  3]\n"," [ 0  2  0 20]]\n"],"name":"stdout"}]},{"metadata":{"id":"a2cRizGVoVHe","colab_type":"code","outputId":"1ca5c13a-82c1-476f-9ab7-c3b59f82b6f2","executionInfo":{"status":"ok","timestamp":1540234677779,"user_tz":-180,"elapsed":925,"user":{"displayName":"tuğba tümen","photoUrl":"","userId":"04761172934268945573"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"cell_type":"code","source":["#toplam doğru sayısının toplam sayıya bölünmesi ile elde edilir.\n","score = model.evaluate(x_val, y_val, batch_size=32, verbose=1)\n","print('\\n', 'Test accuracy:', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["73/73 [==============================] - 0s 575us/step\n","\n"," Test accuracy: 0.8356164391726664\n"],"name":"stdout"}]},{"metadata":{"id":"arvApjHSRFhU","colab_type":"code","colab":{}},"cell_type":"code","source":["scores = model.evaluate(X_test, y_val[0:73], batch_size=32)\n","print('\\n', 'Test accuracy:', score[1])\n","#print((scores[0],scores[1],scores[2]))"],"execution_count":0,"outputs":[]}]}